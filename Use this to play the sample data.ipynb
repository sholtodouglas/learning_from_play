{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import pandaRL\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import config\n",
    "#env = env = gym.make('pandaPlayJoints1Obj-v0')\n",
    "# env.render(mode='human')\n",
    "# o = env.reset()\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "PYBULLET_DATA_DIR = config.ONEOBJ_PLAY # config.SCRIPTED_PLAY #config.RPL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path, keys):\n",
    "    dataset = {k:[] for k in keys+['sequence_index','sequence_id']}\n",
    "    obs_act_path = os.path.join(path, 'obs_act_etc/')\n",
    "\n",
    "    for demo in os.listdir(obs_act_path):\n",
    "        traj = np.load(obs_act_path+demo+'/data.npz')\n",
    "        for k in keys:\n",
    "            dataset[k].append(traj[k].astype(np.float32))\n",
    "        timesteps = len(traj['obs'])\n",
    "        dataset['sequence_index'].append(np.arange(timesteps, dtype=np.int32).reshape(-1, 1))\n",
    "        dataset['sequence_id'].append(np.full(timesteps, fill_value=int(demo), dtype=np.int32).reshape(-1, 1))\n",
    "\n",
    "    # convert to numpy\n",
    "    for k in keys+['sequence_index','sequence_id']:\n",
    "        dataset[k] = np.vstack(dataset[k])\n",
    "    return dataset\n",
    "\n",
    "keys = ['obs', 'acts', 'achieved_goals', 'joint_poses', 'target_poses', 'acts_rpy', 'acts_rpy_rel',  'velocities', 'rpy_obs']\n",
    "dataset = load_data(PYBULLET_DATA_DIR, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('pandaPlay1Obj-v0')\n",
    "env.render(mode='human')\n",
    "o = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= 33\n",
    "#base_path = 'data_collection/collected_data/play_demos/'\n",
    "base_path = config.ONEOBJ_PLAY\n",
    "data = np.load(base_path+'obs_act_etc/'+str(f)+'/data.npz')\n",
    "potential_start_points = glob.glob(base_path+'/states_and_ims/'+str(f)+'/env_states/*.bullet')\n",
    "actions = data['acts']\n",
    "observations = data['obs']\n",
    "\n",
    "def get_random_start_point(potential_start_points):\n",
    "    idx = np.random.choice(len(potential_start_points))\n",
    "    path = potential_start_points[idx]\n",
    "    if config.OS == 'windows':\n",
    "        tstep = int(path.split('\\\\')[-1].replace('.bullet',''))\n",
    "    else:\n",
    "        tstep = int(path.split(\"/\")[-1].replace('.bullet',''))\n",
    "    return path, tstep\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, start = get_random_start_point(potential_start_points)\n",
    "\n",
    "env.p.restoreState(fileName=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(path)\n",
    "os = []\n",
    "for i in range(start, start+200):\n",
    "    a = actions[i,:]\n",
    "    #a = np.concatenate([a[0:3], env.p.getEulerFromQuaternion(a[3:7]), np.expand_dims(a[-1],0)])\n",
    "    \n",
    "    a = a# + a*(np.random.rand(8)-0.5)*0.02\n",
    "    o, r, _, d = env.step(a )\n",
    "    os.append(o['observation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)\n",
    "os = []\n",
    "for i in range(start, start+400):\n",
    "    #a = np.concatenate([a[0:3], env.p.getEulerFromQuaternion(a[3:7]), np.expand_dims(a[-1],0)])\n",
    "    env.visualise_sub_goal(sub_goals[i,:])\n",
    "    time.sleep(0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.panda.delete_sub_goal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linalg.norm(actions[start:start+200,3:7],axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(actions[start:start+200,3:7], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pybullet as p\n",
    "# keys = ['obs', 'acts', 'achieved_goals', 'joint_poses', 'target_poses', 'acts_rpy', 'acts_rpy_rel',  'velocities']\n",
    "\n",
    "# def load_data(path, keys):\n",
    "#     dataset = {k:[] for k in keys+['sequence_index','sequence_id']}\n",
    "#     obs_act_path = os.path.join(path, 'obs_act_etc/')\n",
    "\n",
    "#     for demo in os.listdir(obs_act_path):\n",
    "#         data_dict = {}\n",
    "        \n",
    "        \n",
    "#         traj = np.load(obs_act_path+demo+'/data.npz')\n",
    "        \n",
    "#         rpy_acts = []\n",
    "#         rpy_obs = []\n",
    "#         for k in traj.keys():\n",
    "#             print(k)\n",
    "\n",
    "            \n",
    "#         for o in list(traj['obs']):\n",
    "#             rpy_obs.append(np.concatenate([o[0:3], p.getEulerFromQuaternion(o[3:7]), o[7:]]))\n",
    "        \n",
    "#         path = obs_act_path+demo+'/data.npz'\n",
    "#         print(path.replace(\".npz\", \"\"))\n",
    "#         np.savez(path.replace(\".npz\", \"\"), acts=traj['acts'], obs=traj['obs'],\n",
    "#                      achieved_goals =traj['achieved_goals'], controllable_achieved_goals =traj['controllable_achieved_goals'], joint_poses=traj['joint_poses'],\n",
    "#                      target_poses=traj['target_poses'],acts_rpy = traj['acts_rpy'],\n",
    "#                      acts_rpy_rel = traj['acts_rpy_rel'],  velocities =traj['velocities'], rpy_obs=np.array(rpy_obs))\n",
    "#     return dataset\n",
    "\n",
    "# dataset = load_data(PYBULLET_DATA_DIR, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset['rpy_obs'][100000:, 3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset['acts_rpy'][56000:57000, 3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env = gym.make('pandaPlay1Obj-v0')\n",
    "env.render(mode='human')\n",
    "o = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_positions = {'left': -0.15, 'middle': 0.0, 'right': 0.15}\n",
    "drawer_positions = {'closed': -0.1, 'middle': 0.0, 'open': 0.1}\n",
    "button_positions = {'open': 0.029, 'closed': 0.0}\n",
    "dial_positions = {'default':0}\n",
    "obj_poses = {'default': [0,0.2,0.0], 'shelf':[0,0.43, 0.27], 'left':[-0.2, 0.2,0.0], 'right':[0.2,0.2,0.0],'closed_drawer': [-0.15, 0.1, -0.09], 'open_drawer':[-0.15, -0.15, -0.09], 'cupboard_left': [-0.2, 0.45, 0.0], 'cupboard_right':[0.2, 0.45, 0.0]}\n",
    "obj_oris = {'upright': [0,0.7,0,0.7], 'default':[0,0,0,1], 'lengthways':[0.0, 0.0, 0.7071, 0.7071]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_suite_reset(env, obj_ori = 'default', obj_pos = 'default', door = 'middle', drawer = 'middle', button = 'open', dial = 'default'):\n",
    "    obj_offset = np.array([0.,0.,0.])\n",
    "    if  obj_ori == 'upright':\n",
    "        obj_offset += np.array([0,0.,0.025])\n",
    "        \n",
    "    positions = [door_positions[door], drawer_positions[drawer], button_positions[button], dial_positions[dial]]\n",
    "             \n",
    "    for idx, j in enumerate(env.panda.joints):\n",
    "        env.panda.bullet_client.resetJointState(j, 0, positions[idx]) # reset drawer, button etc\n",
    "        \n",
    "    env.panda.bullet_client.resetBasePositionAndOrientation(env.panda.objects[0],\n",
    "                                                            np.array(obj_poses[obj_pos])+obj_offset, obj_oris[obj_ori])\n",
    "    \n",
    "    \n",
    "    \n",
    "def define_goal(env,obj_ori = 'default', obj_pos = 'default', door = 'middle', drawer = 'middle', button = 'open', dial = 'default'):\n",
    "    # We know the goal is \n",
    "    # objpos (3), obj_ori(4), door, drawer, button, dial\n",
    "    obj_offset = np.array([0.,0.,0.])\n",
    "    if  obj_ori == 'upright':\n",
    "        obj_offset += np.array([0,0.,0.025])\n",
    "    \n",
    "    goal = list(np.array(obj_poses[obj_pos])+obj_offset)+list(obj_oris[obj_ori])+[door_positions[door],drawer_positions[drawer], button_positions[button],dial_positions[dial]]\n",
    "    return np.array(goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, how to measure success?\n",
    "\n",
    "def door_left(env):\n",
    "    test_suite_reset(env, door = 'right')\n",
    "    return define_goal(env, door = 'left')\n",
    "\n",
    "def door_right(env):\n",
    "    test_suite_reset(env, door = 'left')\n",
    "    return define_goal(env, door = 'right')\n",
    "\n",
    "def open_drawer(env):\n",
    "    test_suite_reset(env, drawer='closed')\n",
    "    return define_goal(env, drawer = 'open')\n",
    "\n",
    "def close_drawer(env):\n",
    "    test_suite_reset(env, drawer='open')\n",
    "    return define_goal(env, drawer = 'closed')\n",
    "\n",
    "def push_left(env):\n",
    "    test_suite_reset(env, obj_ori='lengthways')\n",
    "    return define_goal(env, obj_ori='lengthways', obj_pos='left')\n",
    "\n",
    "def push_right(env):\n",
    "    test_suite_reset(env, obj_ori='lengthways')\n",
    "    return define_goal(env, obj_ori='lengthways', obj_pos='right')\n",
    "\n",
    "def block_in_cupboard_right(env):\n",
    "    test_suite_reset(env, door='left')\n",
    "    return define_goal(env, door = 'left', obj_pos='cupboard_right')\n",
    "\n",
    "def block_in_cupboard_left(env):\n",
    "    test_suite_reset(env, door='right')\n",
    "    return define_goal(env, door = 'right', obj_pos='cupboard_left')\n",
    "\n",
    "def block_in_cupboard_right_upright(env):\n",
    "    test_suite_reset(env, door='left', obj_ori='upright')\n",
    "    return define_goal(env, door = 'left', obj_pos='cupboard_right', obj_ori='upright')\n",
    "\n",
    "def block_in_cupboard_left_upright(env):\n",
    "    test_suite_reset(env, door='right', obj_ori='upright')\n",
    "    return define_goal(env, door = 'right', obj_pos='cupboard_left', obj_ori='upright')\n",
    "\n",
    "def block_default_to_upright(env):\n",
    "    test_suite_reset(env, obj_ori='default')\n",
    "    return define_goal(env, obj_ori='upright')\n",
    "\n",
    "def block_lengthways_to_upright(env):\n",
    "    test_suite_reset(env, obj_ori='lengthways')\n",
    "    return define_goal(env, obj_ori='upright')\n",
    "\n",
    "def block_default_to_lengthways(env):\n",
    "    test_suite_reset(env, obj_ori='default')\n",
    "    return define_goal(env, obj_ori='lengthways')\n",
    "\n",
    "def block_lengthways_to_default(env):\n",
    "    test_suite_reset(env, obj_ori='lengthways')\n",
    "    return define_goal(env, obj_ori='default')\n",
    "\n",
    "def press_button(env):\n",
    "    test_suite_reset(env, door='right')\n",
    "    return define_goal(env, door='right', button='closed')\n",
    "\n",
    "def block_on_shelf(env):\n",
    "    test_suite_reset(env, obj_ori='upright')\n",
    "    return define_goal(env, obj_pos='shelf',obj_ori='upright')\n",
    "\n",
    "def block_in_open_drawer(env):\n",
    "    test_suite_reset(env, drawer='open')\n",
    "    return define_goal(env, drawer='open', obj_pos='open_drawer')\n",
    "\n",
    "def block_in_open_drawer_lengthways(env):\n",
    "    test_suite_reset(env, drawer='open', obj_ori='lengthways')\n",
    "    return define_goal(env, drawer='open', obj_ori='lengthways', obj_pos='open_drawer')\n",
    "\n",
    "# Multi part objectives\n",
    "def press_button_with_door_obstacle(env):\n",
    "    test_suite_reset(env, door='left')\n",
    "    return define_goal(env, door='right', button='closed')\n",
    "\n",
    "def block_in_drawer_and_close(env):\n",
    "    test_suite_reset(env, drawer='open', obj_ori='lengthways')\n",
    "    return define_goal(env, drawer='closed', obj_ori='lengthways', obj_pos='closed_drawer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, how to measure success?\n",
    "\n",
    "tests = [door_left,door_right,open_drawer,close_drawer,push_left,push_right,block_in_cupboard_right,\n",
    "         block_in_cupboard_left,block_in_cupboard_right_upright, block_in_cupboard_left_upright, block_default_to_upright,\n",
    "         block_lengthways_to_upright, block_default_to_lengthways, block_lengthways_to_default, press_button,block_on_shelf,\n",
    "         block_in_open_drawer,block_in_open_drawer_lengthways,\n",
    "         press_button_with_door_obstacle,block_in_drawer_and_close]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tests:\n",
    "    print(f.__name__)\n",
    "    f(env)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suite_reset(env, obj_ori = 'lengthways', obj_pos = 'closed_drawer', door = 'middle', drawer = 'closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "define_goal(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1000):\n",
    "    env.p.stepSimulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.panda.bullet_client.getJointState(env.panda.joints[2], 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.panda.bullet_client.resetJointState(env.panda.joints[0], 0, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sholt\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\users\\sholt\\desktop\\pandarl\\pandaRL\\envs\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "import pandaRL\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "env = gym.make('pandaPlayAbsRPY1Obj-v0')\n",
    "env.render(mode='human')\n",
    "o = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,

   "outputs": [
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for f in range(0,18):\n",
    "    #base_path = 'data_collection/collected_data/play_demos/'\n",
    "    base_path = config.ONEOBJ_PLAY\n",
    "    data = np.load(base_path+'obs_act_etc/'+str(f)+'/data.npz')\n",
    "    potential_start_points = glob.glob(base_path+'/states_and_ims/'+str(f)+'/env_states/*.bullet')\n",
    "    actions = data['acts_rpy']\n",
    "    observations = data['obs']\n",
    "    #joint_targets = data['target_poses']\n",
    "    plt.plot(data['acts_rpy_rel'][:,3:6])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb679575eb8>,\n",
       " <matplotlib.lines.Line2D at 0x7fb679575fd0>,\n",
       " <matplotlib.lines.Line2D at 0x7fb67955a160>,\n",
       " <matplotlib.lines.Line2D at 0x7fb67955a2b0>,\n",
       " <matplotlib.lines.Line2D at 0x7fb67955a400>,\n",
       " <matplotlib.lines.Line2D at 0x7fb67955a550>,\n",
       " <matplotlib.lines.Line2D at 0x7fb67955a6a0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Play some representative sample data\n",
    "\n",
    "\n",
    "\n",
    "f= 12\n",
    "#base_path = 'data_collection/collected_data/play_demos/'\n",
    "base_path = config.Hz30\n",
    "data = np.load(base_path+'obs_act_etc/'+str(f)+'/data.npz')\n",
    "potential_start_points = glob.glob(base_path+'/states_and_ims/'+str(f)+'/env_states/*.bullet')\n",
    "actions = data['acts_rpy']\n",
    "observations = data['obs']\n",
    "joint_targets = data['target_poses']\n",
    "plt.plot(data['acts_rpy_rel'][3471:3550,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4837\n"
     ]
    }
   ],
   "source": [
    "dataset_len = len(actions)\n",
    "print(dataset_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_start_point(potential_start_points):\n",
    "    idx = np.random.choice(len(potential_start_points))\n",
    "    path = potential_start_points[idx]\n",
    "    if config.OS == 'windows':\n",
    "        tstep = int(path.split('\\\\')[-1].replace('.bullet',''))\n",
    "    else:\n",
    "        tstep = int(path.split(\"/\")[-1].replace('.bullet',''))\n",
    "    return path, tstep\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {

   "metadata": {},
   "source": [
    "# Run with absolute position actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start = 3471\n",
    "path = base_path+ f'states_and_ims/{f}/env_states/{start}.bullet'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, start = get_random_start_point(potential_start_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.p.restoreState(fileName=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6800b4b38>,\n",
       " <matplotlib.lines.Line2D at 0x7fb6800b4c50>,\n",
       " <matplotlib.lines.Line2D at 0x7fb6800b4da0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(actions[:,3:6][start:start+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_collection/collected_data/30Hz_one_obj//states_and_ims/12/env_states/480.bullet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env.p.restoreState(fileName=path)\n",
    "print(path)\n",
    "os = []\n",
    "for i in range(start, start+400):\n",
    "    a = actions[i,:]\n",
    "    #a = np.concatenate([a[0:3], env.p.getEulerFromQuaternion(a[3:7]), np.expand_dims(a[-1],0)])\n",
    "    \n",
    "    o, r, _, d = env.step(a )\n",
    "    os.append(o['observation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.random.rand(7)-0.5)*0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = np.array(os)\n",
    "actions_space = t.shape[-1]\n",
    "length = len(t)\n",
    "x = np.linspace(0, length, num=length)\n",
    "for i in range(0,actions_space):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(6,1.0), squeeze=False)\n",
    "    axes[0,0].plot(x,t[:,i],'green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with motor actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, start = get_random_start_point(potential_start_points)\n",
    "env.p.restoreState(fileName=path)\n",
    "\n",
    "for i in range(start, start+400):\n",
    "    targetPoses = joint_targets[i,:]\n",
    "    indexes =  [i for i in range(7)]\n",
    "    env.p.setJointMotorControlArray(env.panda.panda,indexes, env.p.POSITION_CONTROL,\n",
    "                                                         targetPositions=targetPoses ,\n",
    "                                                         forces=[5 * 240.]*len(indexes))\n",
    "    gripper = actions[i,-1]\n",
    "    for i in [9, 10]:\n",
    "        env.p.setJointMotorControl2(env.panda.panda, i, env.p.POSITION_CONTROL, gripper,\n",
    "                                             force=100)\n",
    "\n",
    "    env.panda.runSimulation()\n",
    "    time.sleep(0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below here is just rough working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "o, r ,_,_ = env.step(env.action_space.sample())\n",
    "plt.imshow(o['img'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_collection/collected_data/play_demos/'\n",
    "obs_act_path = path+'obs_act_etc/'\n",
    "\n",
    "for demo in os.listdir(obs_act_path):\n",
    "\n",
    "    traj = np.load(obs_act_path+demo+'/data.npz')\n",
    "    traj = {key:traj[key] for key in keys}\n",
    "    reset_states = []\n",
    "    for i in range(0, len(traj[keys[0]])):\n",
    "        # these are needed for deterministic resetting\n",
    "        reset_states.append(path+'/states_and_ims/'+demo+'/env_states/'+str(i)+'.bullet')\n",
    "    traj['reset_states'] = reset_states\n",
    "    traj['reset_idx'] = int(demo)\n",
    "    dataset.append(traj)\n",
    "\n",
    "    cnt[len(traj[keys[0]])]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "path = 'data_collection/collected_data/play_demos/'\n",
    "obs_act_path = path+'obs_act_etc/'\n",
    "l = os.listdir(obs_act_path)\n",
    "l.sort(key=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in l:\n",
    "    npz_length = np.load(obs_act_path + i +'/data.npz')['obs'].shape[0]\n",
    "    states_len = len(os.listdir(path + 'states_and_ims/'+i+'/env_states/'))\n",
    "    print(i, npz_length, states_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "import subprocess\n",
    "import shlex\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "############## Everything from here for pybullet style #################################\n",
    "def load_data(path, keys):\n",
    "    cnt = Counter()\n",
    "    dataset = []\n",
    "    obs_act_path = os.path.join(path, 'obs_act_etc/')\n",
    "\n",
    "    for demo in os.listdir(obs_act_path):\n",
    "        \n",
    "        traj = np.load(obs_act_path+demo+'/data.npz')\n",
    "        traj = {key:traj[key] for key in keys}\n",
    "        reset_states = []\n",
    "        for i in range(0, len(traj[keys[0]])):\n",
    "            # these are needed for deterministic resetting\n",
    "            reset_states.append(path+'/states_and_ims/'+demo+'/env_states/'+str(i)+'.bullet')\n",
    "        traj['reset_states'] = reset_states\n",
    "        traj['reset_idx'] = int(demo)\n",
    "        dataset.append(traj)\n",
    "        \n",
    "        cnt[len(traj[keys[0]])]+=1\n",
    "        \n",
    "    return dataset,cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = config.ONEOBJ_PLAY # config.SCRIPTED_PLAY #config.RPL_PATH\n",
    "keys = ['obs', 'acts', 'achieved_goals', 'joint_poses', 'target_poses', 'controllable_achieved_goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_act_path = os.path.join(path, 'obs_act_etc/')\n",
    "for demo in os.listdir(obs_act_path):\n",
    "        \n",
    "        traj = np.load(obs_act_path+demo+'/data.npz')\n",
    "        traj = {key:traj[key] for key in keys}\n",
    "        #Fix the acts and the obs\n",
    "        quat_sign_flip(traj['acts'], [(3,7)])\n",
    "        quat_sign_flip(traj['obs'], [(3,7), (10,14)])\n",
    "        quat_sign_flip(traj['achieved_goals'], [(3,7)])\n",
    "        np.savez(obs_act_path+demo+'/data.npz', acts=traj['acts'], obs=traj['obs'], achieved_goals=traj['achieved_goals'],controllable_achieved_goals=traj['controllable_achieved_goals'], joint_poses=traj['joint_poses'],  target_poses=traj['target_poses'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('test', acts=traj['acts'], obs=traj['obs'], achieved_goals=traj['achieved_goals'],controllable_achieved_goals=traj['controllable_achieved_goals'], joint_poses=traj['joint_poses'],  target_poses=traj['target_poses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = np.load('test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj['achieved_goals'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quat_sign_flip(a, idxs):\n",
    "    for pair in idxs:\n",
    "        for i in range(1,len(a)):\n",
    "            \n",
    "            quat = a[i,pair[0]:pair[1]]\n",
    "            last_quat = a[i-1,pair[0]:pair[1]]\n",
    "            if (np.sign(quat)== -np.sign(last_quat)).all(): # i.e, it is an equivalent quaternion\n",
    "                a[i,pair[0]:pair[1]] = - a[i,pair[0]:pair[1]]\n",
    "    return a \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t =  traj['acts']\n",
    "actions_space = t.shape[-1]\n",
    "length = len(traj['acts'])\n",
    "x = np.linspace(0, length, num=length)\n",
    "for i in range(0,actions_space):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(6,1.0), squeeze=False)\n",
    "    axes[0,0].plot(x,t[:,i],'green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = traj['obs']\n",
    "actions_space = t.shape[-1]\n",
    "length = len(traj['acts'])\n",
    "x = np.linspace(0, length, num=length)\n",
    "for i in range(0,actions_space):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(6,1.0), squeeze=False)\n",
    "    axes[0,0].plot(x,t[:,i],'green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = quat_sign_flip(traj['obs'], [(3,7), (11,14)])\n",
    "actions_space = t.shape[-1]\n",
    "length = len(traj['acts'])\n",
    "x = np.linspace(0, length, num=length)\n",
    "for i in range(0,actions_space):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(6,1.0), squeeze=False)\n",
    "    axes[0,0].plot(x,t[:,i],'green')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 1/240.\n",
    "control_Hz = 20\n",
    "n_steps = 1/control_Hz/timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                       \n",
    "start = 0\n",
    "for i in range(start, dataset_len ):\n",
    "    env.p.restoreState(fileName='data_collection/collected_data/play_demos/'+str(f)+'/env_states/'+str(i)+'.bullet')\n",
    "    time.sleep(0.005)\n",
    "    \n",
    "#env.p.restoreState(fileName='data_collection/collected_data/play_demos/'+str(f)+'/env_states/'+str(start)+'.bullet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0\n",
    "data = np.load('data_collection/collected_data/play_demos/'+str(f)+'/data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 200\n",
    "env.p.restoreState(fileName='data_collection/collected_data/play_demos/'+str(f)+'/env_states/'+str(start)+'.bullet')\n",
    "for i in range(start, start+400):\n",
    "    act = actions[i,:]\n",
    "    act[0:3] = act[0:3] + observations[i,0:3]\n",
    "    POS, ORI, GRIPPER = act[0:3], act[3:7], act[7]\n",
    "    env.panda.goto(POS, ORI, GRIPPER)\n",
    "    env.panda.runSimulation()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = tfd.Logistic(loc=[0], scale=[-0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-dist.log_prob(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 8\n",
    "start = 200\n",
    "env.p.restoreState(fileName='data_collection/collected_data/play_demos/'+str(f)+'/env_states/'+str(start)+'.bullet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(data['joint_poses'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.amin(data['joint_poses'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['joints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env.p.setVRCameraState([0.0, -0.3, -1.5], env.p.getQuaternionFromEuler([0, 0, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o['observation'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1400\n",
    "actions = data['acts']\n",
    "env.p.restoreState(fileName='data_collection/collected_data/play_demos/'+str(f)+'/env_states/'+str(start)+'.bullet')\n",
    "for i in range(start, start+400):\n",
    "    env.step(actions[i,:])\n",
    "    time.sleep(0.005)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1400\n",
    "for i in range(start, start+400):\n",
    "    env.p.restoreState(fileName='data_collection/collected_data/play_demos/'+str(f)+'/env_states/'+str(i)+'.bullet')\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_button(bullet_client, offset = np.array([0,0,0])):\n",
    "    sphereRadius = 0.02\n",
    "    colBoxId = bullet_client.createCollisionShape(bullet_client.GEOM_BOX,\n",
    "                                      halfExtents=[sphereRadius, sphereRadius, sphereRadius/4])\n",
    "\n",
    "    mass = 0\n",
    "    visualShapeId = bullet_client.createVisualShape(bullet_client.GEOM_BOX, halfExtents=[sphereRadius, sphereRadius, sphereRadius/4],\n",
    "                                                 rgbaColor=[1, 0, 0, 1])\n",
    "\n",
    "    link_Masses = [0.1]\n",
    "    linkCollisionShapeIndices = [colBoxId]\n",
    "    linkVisualShapeIndices = [visualShapeId]\n",
    "    linkPositions = [[-0.25,0.45, 0.70]]\n",
    "    linkOrientations = [bullet_client.getQuaternionFromEuler([0,0,0])]\n",
    "    linkInertialFramePositions = [[0, 0, 0]]\n",
    "    linkInertialFrameOrientations = [[0, 0, 0, 1]]\n",
    "    indices = [0]\n",
    "    # jointTypes = [bullet_client.JOINT_REVOLUTE]\n",
    "    jointTypes = [bullet_client.JOINT_PRISMATIC]\n",
    "    axis = [[0, 0, 1]]\n",
    "\n",
    "    basePosition = np.array([0, 0, -0.7])+offset\n",
    "    baseOrientation = [0, 0, 0, 1]\n",
    "\n",
    "    sphereUid = bullet_client.createMultiBody(mass,\n",
    "                                  colBoxId,\n",
    "                                  visualShapeId,\n",
    "                                  basePosition,\n",
    "                                  baseOrientation,\n",
    "                                  linkMasses=link_Masses,\n",
    "                                  linkCollisionShapeIndices=linkCollisionShapeIndices,\n",
    "                                  linkVisualShapeIndices=linkVisualShapeIndices,\n",
    "                                  linkPositions=linkPositions,\n",
    "                                  linkOrientations=linkOrientations,\n",
    "                                  linkInertialFramePositions=linkInertialFramePositions,\n",
    "                                  linkInertialFrameOrientations=linkInertialFrameOrientations,\n",
    "                                  linkParentIndices=indices,\n",
    "                                  linkJointTypes=jointTypes,\n",
    "                                  linkJointAxis=axis)\n",
    "\n",
    "    bullet_client.changeDynamics(sphereUid,\n",
    "                     -1,\n",
    "                     spinningFriction=0.001,\n",
    "                     rollingFriction=0.001,\n",
    "                     linearDamping=0.0)\n",
    "    bullet_client.setJointMotorControl2(sphereUid, 0, bullet_client.POSITION_CONTROL, targetPosition=0.03, force=1)\n",
    "    return sphereUid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bullet_client = env.p\n",
    "button = add_button(env.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_obs(bullet_client, item):\n",
    "    return bullet_client.getJointState(item, 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while(1):\n",
    "    o,r,d,_ = env.step(env.action_space.sample())\n",
    "    #print(get_joint_obs(bullet_client, button))\n",
    "    print(o[:-4])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "side = 0.2\n",
    "\n",
    "\n",
    "\n",
    "# Cabinet sides\n",
    "colcubeId = bullet_client.createCollisionShape(bullet_client.GEOM_BOX, halfExtents=[0.01, 0.065, 0.235])\n",
    "visplaneId = bullet_client.createVisualShape(bullet_client.GEOM_BOX, halfExtents=[0.01, 0.065, 0.235],\n",
    "                                             rgbaColor=[0.75, 0.4 ,0.2,1])\n",
    "block = bullet_client.createMultiBody(0.0, colcubeId, visplaneId, [-0.34, 0.45, -0.00])\n",
    "\n",
    "colcubeId = bullet_client.createCollisionShape(bullet_client.GEOM_BOX, halfExtents=[0.01, 0.065, 0.235])\n",
    "visplaneId = bullet_client.createVisualShape(bullet_client.GEOM_BOX, halfExtents=[0.01, 0.065, 0.235],\n",
    "                                             rgbaColor=[0.75, 0.4 ,0.2,1])\n",
    "block = bullet_client.createMultiBody(0.0, colcubeId, visplaneId, [0.34, 0.45, -0.00])\n",
    "\n",
    "# Cabinet back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_VR = None  \n",
    "import socket\n",
    "import pybullet as p\n",
    "import time\n",
    "import pybullet_data\n",
    "import numpy as np\n",
    "from pickle import dumps\n",
    "import math \n",
    "#p.connect(p.UDP,\"192.168.86.100\")\n",
    "cid = p.connect(p.SHARED_MEMORY)\n",
    "\n",
    "if (cid<0):\n",
    "    p.connect(p.GUI)\n",
    "    USE_VR = False\n",
    "else:\n",
    "    print(\"Connected to shared memory\")\n",
    "    USE_VR = True # Use either GUI or VR to set commands. \n",
    "\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "print(pybullet_data.getDataPath())\n",
    "p.resetSimulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bullet_client = env.p\n",
    "side = 0.2\n",
    "\n",
    "# TableTop\n",
    "colcubeId = bullet_client.createCollisionShape(bullet_client.GEOM_BOX, halfExtents=[0.4, 0.28, 0.005])\n",
    "visplaneId = bullet_client.createVisualShape(bullet_client.GEOM_BOX, halfExtents=[0.4, 0.28, 0.005],\n",
    "                                             rgbaColor=[0.75, 0.4 ,0.2,1])\n",
    "block = bullet_client.createMultiBody(0.0, colcubeId, visplaneId, [0, 0.25, -0.03])\n",
    "\n",
    "# Cabinet back\n",
    "colcubeId = bullet_client.createCollisionShape(bullet_client.GEOM_BOX, halfExtents=[0.4, 0.01, 0.22])\n",
    "visplaneId = bullet_client.createVisualShape(bullet_client.GEOM_BOX, halfExtents=[0.4, 0.01, 0.22],\n",
    "                                             rgbaColor=[0.75, 0.4 ,0.2,1])\n",
    "block = bullet_client.createMultiBody(0.0, colcubeId, visplaneId, [0., 0.52, -0.00])\n",
    "\n",
    "# Cabinet back\n",
    "colcubeId = bullet_client.createCollisionShape(bullet_client.GEOM_BOX, halfExtents=[0.4, 0.065, 0.005])\n",
    "visplaneId = bullet_client.createVisualShape(bullet_client.GEOM_BOX, halfExtents=[0.4, 0.065, 0.005],\n",
    "                                             rgbaColor=[0.75, 0.4 ,0.2,1])\n",
    "block = bullet_client.createMultiBody(0.0, colcubeId, visplaneId, [0., 0.47, 0.22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = data['acts']\n",
    "actions.shape\n",
    "np.mean(data['times'][1:] - data['times'][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import socket\n",
    "import pickle\n",
    "HOST = '127.0.0.1'  # The server's hostname or IP address\n",
    "PORT = 65432        # The port used by the server\n",
    "\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.connect((HOST, PORT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "s.sendall(b'Hello, world')\n",
    "data = s.recv(1024)\n",
    "print('Received', pickle.loads(data)) #repr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adept_envs\n",
    "import gym\n",
    "import glob\n",
    "import os\n",
    "#from parse_mjl import parse_mjl_logs\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"kitchen_relax-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "while(1):\n",
    "    joint_vels = np.zeros(9)\n",
    "    env.step(np.array(joint_vels))\n",
    "    t1 = time.time()\n",
    "    print(t1-t0)\n",
    "    t0=t1\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.env.sim.model.key_qpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dir = os.getcwd() + '/' + \"kitchen_demos_multitask/\"\n",
    "\n",
    "demos = glob.glob(demo_dir + \"/**/*.mjl\", recursive=True)\n",
    "print([d.strip(demo_dir) for d in demos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = demos[1]\n",
    "skip = 20\n",
    "data = parse_mjl_logs(file, skip)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "def histo(x):\n",
    "    hist, bins = np.histogram(x, bins=50)\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.title(\"Trajectory Lengths\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "frames = []\n",
    "timestep = []\n",
    "\n",
    "for file in tqdm(demos):\n",
    "    try:\n",
    "        skip = 1\n",
    "        data = parse_mjl_logs(file, skip)\n",
    "        times.append(data['time'][-1] - data['time'][0])\n",
    "        frames.append(len(data['ctrl']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "histo(times)\n",
    "histo(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['ctrl'].shape, data['qpos'].shape, data['qvel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = demos[np.random.choice(len(demos))]\n",
    "skip = 40 # this is frame skip\n",
    "data = parse_mjl_logs(file, skip)\n",
    "env.reset()\n",
    "for i in range(0,len(data['qpos'])):\n",
    "    env.robot.reset(env, data['qpos'][i], data['qvel'][i])\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The issue!\n",
    "Now, the problem is that cntrl is at the full time frequency of the env - which is really fine. That means if frame skip is anything but 1 then the ctrl labels are wrong. Ideally we want a more reasonable time freq, which means we need to take the difference between the first 9 elements of q_pos, divide it by the time between and then that gives us our desired vel controls. Even better, tonight I'll modify the env for position control. \n",
    "\n",
    "See, the below fails - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playback demos and get data(physics respected)\n",
    "def gather_training_data(env, data, filename='demo_playback.mp4', render=None):\n",
    "    env = env.env\n",
    "    FPS = 30\n",
    "    render_skip = max(1, round(1. / \\\n",
    "        (FPS * env.sim.model.opt.timestep * env.frame_skip)))\n",
    "    t0 = timer.time()\n",
    "\n",
    "    # initialize\n",
    "    env.reset()\n",
    "    init_qpos = data['qpos'][0].copy()\n",
    "    init_qvel = data['qvel'][0].copy()\n",
    "    act_mid = env.act_mid\n",
    "    act_rng = env.act_amp\n",
    "\n",
    "    # prepare env\n",
    "    env.sim.data.qpos[:] = init_qpos\n",
    "    env.sim.data.qvel[:] = init_qvel\n",
    "    env.sim.forward()\n",
    "    #viewer(env, mode='initialize', render=render)\n",
    "\n",
    "    # step the env and gather data\n",
    "    path_obs = None\n",
    "    for i_frame in range(data['ctrl'].shape[0] - 1):\n",
    "        # Reset every time step\n",
    "        # if i_frame % 1 == 0:\n",
    "        #     qp = data['qpos'][i_frame].copy()\n",
    "        #     qv = data['qvel'][i_frame].copy()\n",
    "        #     env.sim.data.qpos[:] = qp\n",
    "        #     env.sim.data.qvel[:] = qv\n",
    "        #     env.sim.forward()\n",
    "\n",
    "        obs = env._get_obs()\n",
    "\n",
    "        # Construct the action\n",
    "        # ctrl = (data['qpos'][i_frame + 1][:9] - obs[:9]) / (env.skip * env.model.opt.timestep)\n",
    "        ctrl = (data['ctrl'][i_frame] - obs[:9])/(env.skip*env.model.opt.timestep)\n",
    "        act = (ctrl - act_mid) / act_rng\n",
    "        act = np.clip(act, -0.999, 0.999)\n",
    "        next_obs, reward, done, env_info = env.step(act)\n",
    "        if path_obs is None:\n",
    "            path_obs = obs\n",
    "            path_act = act\n",
    "        else:\n",
    "            path_obs = np.vstack((path_obs, obs))\n",
    "            path_act = np.vstack((path_act, act))\n",
    "\n",
    "        # render when needed to maintain FPS\n",
    "        if i_frame % render_skip == 0:\n",
    "            #viewer(env, mode='render', render=render)\n",
    "            print(i_frame, end=', ', flush=True)\n",
    "            env.render()\n",
    "#     # finalize\n",
    "#     if render:\n",
    "#         viewer(env, mode='save', filename=filename, render=render)\n",
    "\n",
    "    t1 = timer.time()\n",
    "    print(\"time taken = %f\" % (t1 - t0))\n",
    "\n",
    "    # note that <init_qpos, init_qvel> are one step away from <path_obs[0], path_act[0]>\n",
    "    return path_obs, path_act, init_qpos, init_qvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time as timer\n",
    "file = demos[np.random.choice(len(demos))]\n",
    "skip = 40 # this is frame skip\n",
    "data = parse_mjl_logs(file, skip)\n",
    "render = True\n",
    "obs, act,init_qpos, init_qvel = gather_training_data(env, data,\\\n",
    "                filename=data['logName'][:-4]+'_playback.mp4', render=render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(obs))\n",
    "env.robot.reset(env, init_qpos, init_qvel)\n",
    "for i in range(0,len(act)):\n",
    "    #rel_vector = data['qpos'][i+1][:9]-data['qpos'][i][:9]\n",
    "    #vel = rel_vector / 0.08\n",
    "    \n",
    "    #env.robot.reset(env, data['qpos'][i], data['qvel'][i])\n",
    "    env.step(act[i]) # the key change\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('./kitchen_demos_multitask/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import subprocess\n",
    "import shlex\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import glob\n",
    "def call_proc(cmd):\n",
    "    \"\"\" This runs in a separate thread. \"\"\"\n",
    "    p = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out, err = p.communicate()\n",
    "    return (out, err)\n",
    "\n",
    "pool = ThreadPool(multiprocessing.cpu_count()//2)\n",
    "results = []\n",
    "for path in glob.glob('./kitchen_demos_multitask/*'):\n",
    "    cmd = f'python3 relay-policy-learning/adept_envs/adept_envs/utils/parse_demos.py --env \"kitchen_relax-v1\" -d \"{path}/\" -s \"40\" -v \"playback\" -r \"offscreen\"'\n",
    "    results.append(pool.apply_async(call_proc, (cmd,)))\n",
    "# Close the pool and wait for each running task to complete\n",
    "pool.close()\n",
    "pool.join()\n",
    "for result in results:\n",
    "    out, err = result.get()\n",
    "    print(f\"out: {out.decode()}\")\n",
    "    print(f\"err: {err.decode()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Info \n",
    "\n",
    "## Action Space\n",
    "\n",
    "Action space is 9 dimensional, commanded via velocity. In franka robot.py, the function cntrl_velocity_limits bounds the desired velocity step, then returns a next desired positon (prevpos + cntrl_vel*step_size), so really rather than absolute position it is commanding desired pos, using a relative offset commanded via velocity assuming a constant timestep (0.08). This means it'd be easy to adapt to commanding via relative positon, or velocity. \n",
    "\n",
    "## Obs Space\n",
    "\n",
    "60 Dimensional. 9 for self, 21 for obs, 30 for goal. Self is unused in reward computation, only the following indices are \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_ELEMENT_INDICES = {\n",
    "    'bottom burner': np.array([11, 12]),\n",
    "    'top burner': np.array([15, 16]),\n",
    "    'light switch': np.array([17, 18]),\n",
    "    'slide cabinet': np.array([19]),\n",
    "    'hinge cabinet': np.array([20, 21]),\n",
    "    'microwave': np.array([22]),\n",
    "    'kettle': np.array([23, 24, 25, 26, 27, 28, 29]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reset it to any qpos,qvel self.robot.reset(self, reset_pos, reset_vel) (sizes 30, 29). qvel is actually returned as 30 dimensional internally (but never used so its not an issue. This off by one issue comes from the sim not returning the vel of one of the object elements I think, can't find out which one though. Not a big issue, vel isn't part of the obs state so clearly not that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_usage = 200000 # TWH\n",
    "coal_energy_per_ton = 0.00000000029 * 0.001 # Coal energy per ton in Terwatt hours\n",
    "carbon_produced = 60 # GT\n",
    "c02_emitted_per_ton = 9.2668921e-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_usage/coal_energy_per_ton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_produced/c02_emitted_per_ton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
