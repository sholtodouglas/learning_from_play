{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Process data into pickles with skip 40\n",
    "2. Load this in to df dataloader\n",
    "3. Train simple MLP map o -> a, observe it being okay\n",
    "4. Get play subsequences, do goal conditioned BC, not just BC\n",
    "5. LFP planner/encoder\n",
    "6. Label a couple subsequences w/ language, and map that to the z space!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Clean old data\n",
    "# import glob\n",
    "# import os\n",
    "# demo_dir = os.getcwd() + '/' + \"kitchen_demos_multitask/\"\n",
    "# old = glob.glob(demo_dir + \"/**/*.pkl\", recursive=True)\n",
    "# movies = glob.glob(demo_dir + \"/**/*.mp4\", recursive=True)\n",
    "# for i in old + movies:\n",
    "#     print(i)\n",
    "#     os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Colab\n",
    "COLAB = False\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "if COLAB:\n",
    "    class config(object):\n",
    "        pass\n",
    "\n",
    "    config = config()\n",
    "    config.PYBULLET_PLAY = 'play_data/'\n",
    "    config.DEVICE = 'TPU'\n",
    "\n",
    "    %cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import config\n",
    "import random\n",
    "\n",
    "dataset_path  = config.ONEOBJ_PLAY # config.SCRIPTED_PLAY #config.RPL_PATH\n",
    "keys = ['obs', 'acts', 'achieved_goals', 'joint_poses', 'target_poses']\n",
    "physical_devices = tf.config.list_physical_devices(config.DEVICE)\n",
    "if config.DEVICE is 'GPU':\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "RELATIVE_JOINTS = True # use relative joiints instead of absolute angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset, cnt = data.create_single_dataset(dataset_path)\n",
    "\n",
    "\n",
    "dataset, cnt = data.load_data(dataset_path, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of sequence lengths\n",
    "plt.bar(cnt.keys(), cnt.values(), width=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 57452 frames of data, which is 47.876666666666665 minutes.\n"
     ]
    }
   ],
   "source": [
    "total_frames = sum([x[0]*x[1] for x in cnt.items()])\n",
    "print(f\"We have {total_frames} frames of data, which is {total_frames/20/60} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PyBulletRobotSeqDataset():\n",
    "    def __init__(self, dataset, batch_size=64, seq_len=50, overlap=1.0, \n",
    "                 prefetch_size=None, train_test_split=0.8, seed=42, relative_joints=False):\n",
    "        self.N_TRAJS = len(dataset)\n",
    "\n",
    "        # Split into train and validation datasets\n",
    "        # List of trajectory dicts\n",
    "        if train_test_split == 'last': # just use the last set of demos as validation\n",
    "            self._train_data = dataset[:-1] # raw data - private\n",
    "            self._valid_data = dataset[-1:]\n",
    "        else:\n",
    "            self._train_data = dataset[:int(self.N_TRAJS*train_test_split)] # raw data - private\n",
    "            self._valid_data = dataset[int(self.N_TRAJS*train_test_split):]\n",
    "        self.train_data = []\n",
    "        self.valid_data = []\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.PREFETCH_SIZE = prefetch_size\n",
    "        self.OVERLAP = overlap\n",
    "        self.relative_joints = relative_joints\n",
    "\n",
    "        self.MAX_SEQ_LEN = seq_len ## 40 for example\n",
    "        self.MIN_SEQ_LEN = seq_len//2 # so like 20\n",
    "        self.OBS_DIM = dataset[0]['obs'].shape[-1]\n",
    "        if self.relative_joints:\n",
    "            self.ACT_DIM = dataset[0]['target_poses'].shape[-1] + 1 # +1 for the gripper\n",
    "        else:\n",
    "            self.ACT_DIM = dataset[0]['acts'].shape[-1]\n",
    "            \n",
    "        self.GOAL_DIM = dataset[0]['achieved_goals'].shape[-1]\n",
    "\n",
    "        self.random_obj = random.Random(seed)\n",
    "\n",
    "    def create_goal(self, trajectory, ti, tf):\n",
    "        return np.tile(trajectory['achieved_goals'][tf, :], (tf-ti,1))\n",
    "\n",
    "    def traj_to_subtrajs(self, trajectory, idx):\n",
    "        \"\"\"\n",
    "        Converts a T-length trajectory into M subtrajectories of length SEQ_LEN, pads time dim to SEQ_LEN\n",
    "        \"\"\"\n",
    "        T = len(trajectory['obs'])\n",
    "        subtrajs = []\n",
    "        window_size = max(int(self.MAX_SEQ_LEN*self.OVERLAP),1)\n",
    "        for ti in range(0,T,window_size):\n",
    "            SEQ_LEN = np.random.randint(self.MIN_SEQ_LEN, self.MAX_SEQ_LEN) # random sequence lengths\n",
    "            tf = ti + SEQ_LEN\n",
    "            if T-1 < tf:\n",
    "                break #trajectory would be cut off by the end of the data \n",
    "                \n",
    "            pad_len = self.MAX_SEQ_LEN-(tf-ti)\n",
    "            time_padding = ((0,pad_len),(0,0))\n",
    "            #print(trajectory['obs'][ti:tf,:].shape, np.pad(trajectory['obs'][ti:tf,:], time_padding).shape)\n",
    "            #print(np.pad(self.create_goal(trajectory, ti, tf), time_padding).shape)\n",
    "            #print(np.pad(np.ones(tf-ti), time_padding[0]).shape)\n",
    "            #print(np.pad(np.arange(ti, tf, 1), time_padding[0]).shape)\n",
    "            \n",
    "            if self.relative_joints:\n",
    "                rel = trajectory['target_poses'][ti:tf] - trajectory['joint_poses'][ti:tf, :7]\n",
    "                gripper = np.expand_dims(trajectory['acts'][ti:tf, -1], -1)\n",
    "                action = np.pad(np.concatenate([rel, gripper], -1), time_padding)\n",
    "            else:\n",
    "                action = np.pad(trajectory['acts'][ti:tf], time_padding)\n",
    "                \n",
    "            \n",
    "            subtraj_dict = {\n",
    "                            'obs':np.pad(trajectory['obs'][ti:tf,:], time_padding)\n",
    "                            , 'acts':action\n",
    "                            , 'goals':np.pad(self.create_goal(trajectory, ti, tf), time_padding)\n",
    "                            , 'loss_mask': np.pad(np.ones(tf-ti), time_padding[0])\n",
    "                            , 'dataset_path':trajectory['reset_idx'] # which trajectory it is in the datadir\n",
    "                            , 'tstep_idxs':np.pad(np.arange(ti, tf, 1), time_padding[0])   # which tstep it is in the trajectory\n",
    "                            }\n",
    "            subtrajs.append(subtraj_dict)\n",
    "        return subtrajs\n",
    "\n",
    "    def convert_dataset(self):\n",
    "        \"\"\" Converts raw dataset to a shuffled subtraj dataset \"\"\"\n",
    "        for idx, train_sample in enumerate(self._train_data):\n",
    "            self.train_data.extend(self.traj_to_subtrajs(train_sample, idx))\n",
    "\n",
    "        for idx, valid_sample in enumerate(self._valid_data):\n",
    "            self.valid_data.extend(self.traj_to_subtrajs(valid_sample, idx))\n",
    "\n",
    "    def create_tf_ds(self, ds_type='train'):\n",
    "        dataset = self.train_data if ds_type=='train' else self.valid_data\n",
    "        def gen():\n",
    "            for d in dataset:\n",
    "                yield (d['obs'], d['acts'], d['goals'], d['loss_mask'], d['dataset_path'], d['tstep_idxs'])\n",
    "\n",
    "        with tf.device('/cpu:0'):\n",
    "            tf_ds =  tf.data.Dataset.from_generator(\n",
    "                        gen\n",
    "                        , output_types = (tf.float32, tf.float32, tf.float32, tf.float32, tf.int32, tf.int32)\n",
    "                        , output_shapes = ((None,self.OBS_DIM), (None,self.ACT_DIM), (None,self.GOAL_DIM), (None), (None), (None)\n",
    "            ))\n",
    "            tf_ds = tf_ds.shuffle(len(dataset))\n",
    "            tf_ds = tf_ds.batch(self.BATCH_SIZE, drop_remainder=True)\n",
    "            tf_ds = tf_ds.prefetch(self.PREFETCH_SIZE)\n",
    "        return tf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#rsd = PyBulletRobotSeqDataset(dataset, batch_size=32, overlap=0.01, train_test_split='last', relative_joints=RELATIVE_JOINTS)\n",
    "rsd = PyBulletRobotSeqDataset(dataset, batch_size=32, overlap=0.01, train_test_split=0.9, relative_joints=RELATIVE_JOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rsd.convert_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf_train_data, tf_valid_data = rsd.create_tf_ds('train'), rsd.create_tf_ds('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_it = iter(tf_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 50, 19) (32, 50, 8) (32, 50, 11) (32, 50)\n"
     ]
    }
   ],
   "source": [
    "o, a, g, m, pth, tsteps = t_it.next()\n",
    "print(o.shape, a.shape, g.shape, m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, ReLU, Input\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, act_dim, num_distribs = 3, layer_size = 2048):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_distribs = num_distribs\n",
    "        self.act_dim = act_dim\n",
    "\n",
    "        self.RNN1 = tf.keras.layers.LSTM(layer_size, return_sequences=True, return_state = True, name='LSTM_in_1')\n",
    "        self.RNN2 = tf.keras.layers.LSTM(layer_size, return_sequences=True, return_state = True, name='LSTM_in_2')\n",
    "        self.mu = tf.keras.layers.Dense(act_dim*num_distribs, activation=None, name='mu')\n",
    "        self.scale = tf.keras.layers.Dense(act_dim*num_distribs, activation=\"softplus\", name='sigma')\n",
    "        self.weightings = tf.keras.layers.Dense(act_dim*num_distribs, activation=\"softplus\", name='alpha')\n",
    "\n",
    "    def call(self, inputs, goal, training=False, past_state = None):\n",
    "        B = inputs.shape[0]\n",
    "        inputs = tf.concat([inputs, goal], -1)\n",
    "        state_out = None\n",
    "        if len(inputs.shape) == 3:\n",
    "            [x, _, _] = self.RNN1(inputs)\n",
    "            [x, _, _] = self.RNN2(x)\n",
    "        else:\n",
    "            x = tf.expand_dims(inputs,1)\n",
    "            [x, s1l1, s2l1] = self.RNN1(x, initial_state = past_state[0])\n",
    "            [x, s1l2, s2l2] = self.RNN2(x, initial_state = past_state[1])\n",
    "            state_out = [[s1l1, s2l1], [s1l2, s2l2]]\n",
    "            \n",
    "\n",
    "        mu, scale, weightings = self.mu(x), self.scale(x), self.weightings(x)\n",
    "        mu, scale, weightings = tf.reshape(mu, (B, -1, self.act_dim, self.num_distribs)), tf.reshape(scale, (B, -1, self.act_dim, self.num_distribs)), tf.reshape(weightings, (B, -1, self.act_dim, self.num_distribs))\n",
    "        dist = tfd.Logistic(loc=mu, scale=scale)\n",
    "        \n",
    "        mixture = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(\n",
    "                          probs=weightings),components_distribution=dist)\n",
    "        if state_out is None:\n",
    "            return mixture\n",
    "        else:\n",
    "            return mixture, state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "import time\n",
    "\n",
    "# Whether to use probabilstic MLP or not\n",
    "PROBS = True\n",
    "# Whether to use LSTM models, as probabilistic models are better they will all be PROB true\n",
    "SEQ = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def step(obs,acts,goals, model, mask=None):\n",
    "    \n",
    "    mixture = model(obs,goals)\n",
    "    # make it the same dimension as the mask if we have one\n",
    "    \n",
    "    if mask is not None:\n",
    "        vals = tf.reduce_mean(mixture.log_prob(acts), -1)\n",
    "        loss = -tf.reduce_mean(vals * mask)\n",
    "    else:\n",
    "        loss = -tf.reduce_mean(mixture.log_prob(acts), -1)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(obs,acts, goals, model, optimizer, mask = None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = step(obs,acts, goals, model, mask)\n",
    "        \n",
    "    variables = model.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer to train the model. Use same LR as LFP paper. \n",
    "optimizer = Adam(learning_rate=2e-4)\n",
    "# Instantiate a loss function.\n",
    "\n",
    "model = LSTM(act_dim = rsd.ACT_DIM)\n",
    "\n",
    "\n",
    "# Prepare the metrics.\n",
    "# train_acc_metric = Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'lstm_4/LSTM_in_2/kernel:0' shape=(2048, 8192) dtype=float32, numpy=\narray([[-8.7558609e-03,  1.1279732e-02, -1.6353726e-03, ...,\n        -2.4138646e-02, -8.8269264e-04,  3.4308769e-03],\n       [-1.2264274e-02, -2.2590287e-02,  3.1206235e-03, ...,\n         1.6896408e-02, -1.5400019e-02,  5.0310791e-03],\n       [-1.9078480e-02,  3.1910557e-03, -1.9588400e-02, ...,\n        -1.0508533e-02, -9.3128271e-03, -1.6060837e-02],\n       ...,\n       [ 1.0129433e-02,  1.3469864e-02,  2.0357296e-02, ...,\n         2.3426432e-03,  7.2997436e-03, -1.3124378e-02],\n       [ 9.3218349e-03,  1.9194774e-02,  8.7473541e-05, ...,\n         1.2013141e-02, -2.2969738e-02, -1.3086138e-02],\n       [-2.2814902e-02, -5.8318563e-03,  2.3492649e-02, ...,\n        -4.0217899e-03, -2.2990664e-02, -4.0056650e-03]], dtype=float32)>, <tf.Variable 'lstm_4/sigma/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/sigma/kernel:0' shape=(2048, 24) dtype=float32, numpy=\narray([[-0.03558096, -0.00070117,  0.00592139, ...,  0.0052109 ,\n        -0.03577098, -0.05099903],\n       [-0.03349667,  0.04286991,  0.02832632, ..., -0.0215254 ,\n        -0.04740891,  0.01208163],\n       [ 0.00067439, -0.04664311, -0.0061528 , ..., -0.00704732,\n        -0.04251143,  0.00915317],\n       ...,\n       [-0.01270136, -0.04904081,  0.01318809, ..., -0.02370362,\n         0.05279856, -0.03928585],\n       [ 0.01173855, -0.04236545,  0.00436025, ..., -0.02507695,\n        -0.00152303, -0.04355532],\n       [-0.04957844, -0.0423603 , -0.04988742, ...,  0.04359387,\n        -0.02379451,  0.01142227]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_1/recurrent_kernel:0' shape=(2048, 8192) dtype=float32, numpy=\narray([[ 1.1722803e-02, -1.2206056e-02, -5.0307647e-03, ...,\n        -9.4872154e-03, -9.0107759e-03, -8.3659723e-04],\n       [ 8.1386128e-03,  3.7157536e-04,  4.5910729e-03, ...,\n         6.5795309e-03,  1.3895286e-02,  2.4101960e-03],\n       [ 1.3392898e-03,  4.1404651e-03,  1.4531136e-02, ...,\n        -1.5067315e-02, -1.9390328e-02,  1.2615856e-02],\n       ...,\n       [ 7.2509064e-03, -1.1854500e-02,  2.8918542e-02, ...,\n         9.4529823e-06,  9.8108454e-03,  1.6738918e-02],\n       [-7.0979227e-03,  7.1739143e-04,  3.2192694e-03, ...,\n        -3.1430472e-03,  5.4560653e-03,  1.4712692e-02],\n       [-1.0686095e-02, -1.3707252e-03,  2.1310026e-02, ...,\n         6.0470104e-03,  1.3515354e-02,  7.2370297e-03]], dtype=float32)>, <tf.Variable 'lstm_4/mu/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/alpha/kernel:0' shape=(2048, 24) dtype=float32, numpy=\narray([[-0.0382323 ,  0.02428715,  0.02190856, ...,  0.04385316,\n        -0.05027322, -0.01639406],\n       [ 0.02176427,  0.04820236, -0.0506365 , ..., -0.01361012,\n        -0.01183639, -0.04203073],\n       [-0.0127135 ,  0.00102558, -0.04670165, ..., -0.02153642,\n         0.05165726,  0.04655879],\n       ...,\n       [ 0.05198671,  0.0251432 , -0.04970287, ...,  0.05133532,\n        -0.02510978, -0.00527176],\n       [ 0.01957192, -0.03511206, -0.01908096, ...,  0.01173208,\n         0.02205735,  0.03338088],\n       [-0.04987144, -0.04206938,  0.01109828, ..., -0.00665107,\n        -0.00022151,  0.03703906]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_1/kernel:0' shape=(30, 8192) dtype=float32, numpy=\narray([[-0.02476955, -0.00740049, -0.01613558, ..., -0.02646751,\n         0.01701941, -0.02543185],\n       [ 0.02654716,  0.0251285 ,  0.00063251, ...,  0.02117107,\n         0.01204248,  0.01807057],\n       [ 0.01424273, -0.01626753,  0.00635382, ..., -0.00910228,\n         0.00367128, -0.00556922],\n       ...,\n       [-0.01444278, -0.02691599, -0.01744529, ...,  0.00670027,\n         0.01115233, -0.02296151],\n       [ 0.02619522,  0.01937368,  0.02186958, ...,  0.00988094,\n        -0.0088517 ,  0.0083493 ],\n       [-0.02411659, -0.02379331,  0.00813016, ...,  0.00149358,\n         0.0213602 ,  0.00097895]], dtype=float32)>, <tf.Variable 'lstm_4/mu/kernel:0' shape=(2048, 24) dtype=float32, numpy=\narray([[-0.01984536, -0.04934827,  0.01029475, ...,  0.05273224,\n        -0.00716121,  0.00707312],\n       [ 0.04565504,  0.04778946,  0.034736  , ..., -0.02240479,\n         0.029627  ,  0.03482871],\n       [ 0.05134745, -0.00725384, -0.00866444, ...,  0.03941258,\n        -0.01917814, -0.02950441],\n       ...,\n       [ 0.00961451, -0.02055251,  0.03827628, ...,  0.01649708,\n         0.04135102, -0.00062309],\n       [-0.04361416,  0.01702504, -0.01000915, ...,  0.02174034,\n        -0.04004355,  0.04487365],\n       [ 0.00535644,  0.00300488,  0.05152975, ..., -0.01403945,\n        -0.02102214,  0.03075273]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_1/bias:0' shape=(8192,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_2/recurrent_kernel:0' shape=(2048, 8192) dtype=float32, numpy=\narray([[ 0.00569999, -0.01441923, -0.0128439 , ...,  0.00766872,\n        -0.00374   , -0.01032177],\n       [ 0.01131991, -0.03299177, -0.02597008, ...,  0.00087403,\n         0.01395257,  0.01042721],\n       [-0.0047798 , -0.0068864 ,  0.0172435 , ..., -0.00316323,\n        -0.00276908, -0.00067459],\n       ...,\n       [ 0.00561035, -0.00275012,  0.00032888, ..., -0.00963472,\n        -0.00374895, -0.01526405],\n       [ 0.01095653,  0.01307732, -0.00139801, ...,  0.01708035,\n         0.02595888,  0.01080748],\n       [-0.00014837, -0.00669387, -0.00625818, ..., -0.01533257,\n         0.00042934, -0.00442866]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_2/bias:0' shape=(8192,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/alpha/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-141f11bb2794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#valid_obs, valid_acts, valid_goals, valid_mask = sample_sequence_batch(valid_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kerasoverfit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    233\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0;31m# streaming restore for any variables created in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0mtrackable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m       \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_nontrivial_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\u001b[0m in \u001b[0;36massert_nontrivial_match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m              \u001b[0;34m\"Typically this means that the checkpoint does not match the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m              \u001b[0;34m\"Python program. The following objects have no matching \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m              \"checkpointed value: %s\") % (list(unused_python_objects),))\n\u001b[0m\u001b[1;32m    802\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'lstm_4/LSTM_in_2/kernel:0' shape=(2048, 8192) dtype=float32, numpy=\narray([[-8.7558609e-03,  1.1279732e-02, -1.6353726e-03, ...,\n        -2.4138646e-02, -8.8269264e-04,  3.4308769e-03],\n       [-1.2264274e-02, -2.2590287e-02,  3.1206235e-03, ...,\n         1.6896408e-02, -1.5400019e-02,  5.0310791e-03],\n       [-1.9078480e-02,  3.1910557e-03, -1.9588400e-02, ...,\n        -1.0508533e-02, -9.3128271e-03, -1.6060837e-02],\n       ...,\n       [ 1.0129433e-02,  1.3469864e-02,  2.0357296e-02, ...,\n         2.3426432e-03,  7.2997436e-03, -1.3124378e-02],\n       [ 9.3218349e-03,  1.9194774e-02,  8.7473541e-05, ...,\n         1.2013141e-02, -2.2969738e-02, -1.3086138e-02],\n       [-2.2814902e-02, -5.8318563e-03,  2.3492649e-02, ...,\n        -4.0217899e-03, -2.2990664e-02, -4.0056650e-03]], dtype=float32)>, <tf.Variable 'lstm_4/sigma/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/sigma/kernel:0' shape=(2048, 24) dtype=float32, numpy=\narray([[-0.03558096, -0.00070117,  0.00592139, ...,  0.0052109 ,\n        -0.03577098, -0.05099903],\n       [-0.03349667,  0.04286991,  0.02832632, ..., -0.0215254 ,\n        -0.04740891,  0.01208163],\n       [ 0.00067439, -0.04664311, -0.0061528 , ..., -0.00704732,\n        -0.04251143,  0.00915317],\n       ...,\n       [-0.01270136, -0.04904081,  0.01318809, ..., -0.02370362,\n         0.05279856, -0.03928585],\n       [ 0.01173855, -0.04236545,  0.00436025, ..., -0.02507695,\n        -0.00152303, -0.04355532],\n       [-0.04957844, -0.0423603 , -0.04988742, ...,  0.04359387,\n        -0.02379451,  0.01142227]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_1/recurrent_kernel:0' shape=(2048, 8192) dtype=float32, numpy=\narray([[ 1.1722803e-02, -1.2206056e-02, -5.0307647e-03, ...,\n        -9.4872154e-03, -9.0107759e-03, -8.3659723e-04],\n       [ 8.1386128e-03,  3.7157536e-04,  4.5910729e-03, ...,\n         6.5795309e-03,  1.3895286e-02,  2.4101960e-03],\n       [ 1.3392898e-03,  4.1404651e-03,  1.4531136e-02, ...,\n        -1.5067315e-02, -1.9390328e-02,  1.2615856e-02],\n       ...,\n       [ 7.2509064e-03, -1.1854500e-02,  2.8918542e-02, ...,\n         9.4529823e-06,  9.8108454e-03,  1.6738918e-02],\n       [-7.0979227e-03,  7.1739143e-04,  3.2192694e-03, ...,\n        -3.1430472e-03,  5.4560653e-03,  1.4712692e-02],\n       [-1.0686095e-02, -1.3707252e-03,  2.1310026e-02, ...,\n         6.0470104e-03,  1.3515354e-02,  7.2370297e-03]], dtype=float32)>, <tf.Variable 'lstm_4/mu/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/alpha/kernel:0' shape=(2048, 24) dtype=float32, numpy=\narray([[-0.0382323 ,  0.02428715,  0.02190856, ...,  0.04385316,\n        -0.05027322, -0.01639406],\n       [ 0.02176427,  0.04820236, -0.0506365 , ..., -0.01361012,\n        -0.01183639, -0.04203073],\n       [-0.0127135 ,  0.00102558, -0.04670165, ..., -0.02153642,\n         0.05165726,  0.04655879],\n       ...,\n       [ 0.05198671,  0.0251432 , -0.04970287, ...,  0.05133532,\n        -0.02510978, -0.00527176],\n       [ 0.01957192, -0.03511206, -0.01908096, ...,  0.01173208,\n         0.02205735,  0.03338088],\n       [-0.04987144, -0.04206938,  0.01109828, ..., -0.00665107,\n        -0.00022151,  0.03703906]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_1/kernel:0' shape=(30, 8192) dtype=float32, numpy=\narray([[-0.02476955, -0.00740049, -0.01613558, ..., -0.02646751,\n         0.01701941, -0.02543185],\n       [ 0.02654716,  0.0251285 ,  0.00063251, ...,  0.02117107,\n         0.01204248,  0.01807057],\n       [ 0.01424273, -0.01626753,  0.00635382, ..., -0.00910228,\n         0.00367128, -0.00556922],\n       ...,\n       [-0.01444278, -0.02691599, -0.01744529, ...,  0.00670027,\n         0.01115233, -0.02296151],\n       [ 0.02619522,  0.01937368,  0.02186958, ...,  0.00988094,\n        -0.0088517 ,  0.0083493 ],\n       [-0.02411659, -0.02379331,  0.00813016, ...,  0.00149358,\n         0.0213602 ,  0.00097895]], dtype=float32)>, <tf.Variable 'lstm_4/mu/kernel:0' shape=(2048, 24) dtype=float32, numpy=\narray([[-0.01984536, -0.04934827,  0.01029475, ...,  0.05273224,\n        -0.00716121,  0.00707312],\n       [ 0.04565504,  0.04778946,  0.034736  , ..., -0.02240479,\n         0.029627  ,  0.03482871],\n       [ 0.05134745, -0.00725384, -0.00866444, ...,  0.03941258,\n        -0.01917814, -0.02950441],\n       ...,\n       [ 0.00961451, -0.02055251,  0.03827628, ...,  0.01649708,\n         0.04135102, -0.00062309],\n       [-0.04361416,  0.01702504, -0.01000915, ...,  0.02174034,\n        -0.04004355,  0.04487365],\n       [ 0.00535644,  0.00300488,  0.05152975, ..., -0.01403945,\n        -0.02102214,  0.03075273]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_1/bias:0' shape=(8192,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_2/recurrent_kernel:0' shape=(2048, 8192) dtype=float32, numpy=\narray([[ 0.00569999, -0.01441923, -0.0128439 , ...,  0.00766872,\n        -0.00374   , -0.01032177],\n       [ 0.01131991, -0.03299177, -0.02597008, ...,  0.00087403,\n         0.01395257,  0.01042721],\n       [-0.0047798 , -0.0068864 ,  0.0172435 , ..., -0.00316323,\n        -0.00276908, -0.00067459],\n       ...,\n       [ 0.00561035, -0.00275012,  0.00032888, ..., -0.00963472,\n        -0.00374895, -0.01526405],\n       [ 0.01095653,  0.01307732, -0.00139801, ...,  0.01708035,\n         0.02595888,  0.01080748],\n       [-0.00014837, -0.00669387, -0.00625818, ..., -0.01533257,\n         0.00042934, -0.00442866]], dtype=float32)>, <tf.Variable 'lstm_4/LSTM_in_2/bias:0' shape=(8192,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'lstm_4/alpha/bias:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "# Maybe load model \n",
    "valid_data_iter = iter(tf_valid_data.repeat(-1))\n",
    "valid_obs, valid_acts, valid_goals, valid_mask,_,_ = valid_data_iter.next()\n",
    "#valid_obs, valid_acts, valid_goals, valid_mask = sample_sequence_batch(valid_data)\n",
    "valid_loss = step(valid_obs, valid_acts, valid_goals, model, valid_mask)\n",
    "model.load_weights('kerasoverfit')\n",
    "valid_loss = step(valid_obs, valid_acts, valid_goals, model, valid_mask)\n",
    "print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps = []\n",
    "losses = []\n",
    "valid_losses = []\n",
    "valid_steps = []\n",
    "n_steps = 300000\n",
    "progbar = Progbar(n_steps, verbose=1, interval=0.5)\n",
    "data_time = []\n",
    "train_time = []\n",
    "best_valid_loss = np.float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sholto/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/categorical.py:225: Categorical._logits_deprecated_behavior (from tensorflow_probability.python.distributions.categorical) is deprecated and will be removed after 2019-10-01.\n",
      "Instructions for updating:\n",
      "The `logits` property will return `None` when the distribution is parameterized with `logits=None`. Use `logits_parameter()` instead.\n",
      "  1600/300000 [..............................] - ETA: 14:54:41 - Validation Loss: -1.0627Regenning Datset\n",
      "  3100/300000 [..............................] - ETA: 14:23:03 - Validation Loss: -1.2828Regenning Datset\n",
      "  4700/300000 [..............................] - ETA: 13:49:20 - Validation Loss: -1.3899Regenning Datset\n",
      "  6200/300000 [..............................] - ETA: 13:31:13 - Validation Loss: -1.4368Regenning Datset\n",
      "  7700/300000 [..............................] - ETA: 13:18:47 - Validation Loss: -1.4617Regenning Datset\n",
      "  9300/300000 [..............................] - ETA: 13:07:25 - Validation Loss: -1.4647Regenning Datset\n",
      " 10800/300000 [>.............................] - ETA: 12:58:49 - Validation Loss: -1.4582Regenning Datset\n",
      " 12400/300000 [>.............................] - ETA: 12:50:43 - Validation Loss: -1.4474Regenning Datset\n",
      " 13900/300000 [>.............................] - ETA: 12:43:46 - Validation Loss: -1.4295Regenning Datset\n",
      " 15400/300000 [>.............................] - ETA: 12:37:36 - Validation Loss: -1.4103Regenning Datset\n",
      " 17000/300000 [>.............................] - ETA: 12:31:13 - Validation Loss: -1.3854Regenning Datset\n",
      " 18500/300000 [>.............................] - ETA: 12:25:28 - Validation Loss: -1.3592Regenning Datset\n",
      " 20100/300000 [=>............................] - ETA: 12:19:50 - Validation Loss: -1.3324Regenning Datset\n",
      " 21600/300000 [=>............................] - ETA: 12:14:44 - Validation Loss: -1.3049Regenning Datset\n",
      " 23100/300000 [=>............................] - ETA: 12:09:44 - Validation Loss: -1.2779Regenning Datset\n",
      " 24700/300000 [=>............................] - ETA: 12:04:40 - Validation Loss: -1.2440Regenning Datset\n",
      " 26200/300000 [=>............................] - ETA: 12:00:05 - Validation Loss: -1.2132Regenning Datset\n",
      " 27800/300000 [=>............................] - ETA: 11:55:02 - Validation Loss: -1.1785Regenning Datset\n",
      " 29300/300000 [=>............................] - ETA: 11:50:24 - Validation Loss: -1.1454Regenning Datset\n",
      " 30800/300000 [==>...........................] - ETA: 11:45:54 - Validation Loss: -1.1092Regenning Datset\n",
      " 32400/300000 [==>...........................] - ETA: 11:41:07 - Validation Loss: -1.0727Regenning Datset\n",
      " 33900/300000 [==>...........................] - ETA: 11:36:37 - Validation Loss: -1.0388Regenning Datset\n",
      " 35400/300000 [==>...........................] - ETA: 11:32:16 - Validation Loss: -1.0047Regenning Datset\n",
      " 37000/300000 [==>...........................] - ETA: 11:27:33 - Validation Loss: -0.9681Regenning Datset\n",
      " 38500/300000 [==>...........................] - ETA: 11:23:19 - Validation Loss: -0.9361Regenning Datset\n",
      " 40100/300000 [===>..........................] - ETA: 11:18:48 - Validation Loss: -0.8995Regenning Datset\n",
      " 41600/300000 [===>..........................] - ETA: 11:14:31 - Validation Loss: -0.8640Regenning Datset\n",
      " 43100/300000 [===>..........................] - ETA: 11:10:18 - Validation Loss: -0.8280Regenning Datset\n",
      " 44700/300000 [===>..........................] - ETA: 11:05:50 - Validation Loss: -0.7914Regenning Datset\n",
      " 46200/300000 [===>..........................] - ETA: 11:01:31 - Validation Loss: -0.7569Regenning Datset\n",
      " 47800/300000 [===>..........................] - ETA: 10:57:06 - Validation Loss: -0.7193Regenning Datset\n",
      " 49300/300000 [===>..........................] - ETA: 10:52:48 - Validation Loss: -0.6847Regenning Datset\n",
      " 50800/300000 [====>.........................] - ETA: 10:48:34 - Validation Loss: -0.6501Regenning Datset\n",
      " 52400/300000 [====>.........................] - ETA: 10:44:08 - Validation Loss: -0.6139Regenning Datset\n",
      " 53900/300000 [====>.........................] - ETA: 10:39:55 - Validation Loss: -0.5801Regenning Datset\n",
      " 55500/300000 [====>.........................] - ETA: 10:35:28 - Validation Loss: -0.5447Regenning Datset\n",
      " 57000/300000 [====>.........................] - ETA: 10:31:22 - Validation Loss: -0.5106Regenning Datset\n",
      " 58500/300000 [====>.........................] - ETA: 10:27:10 - Validation Loss: -0.4750Regenning Datset\n",
      " 60100/300000 [=====>........................] - ETA: 10:22:46 - Validation Loss: -0.4403Regenning Datset\n",
      " 61600/300000 [=====>........................] - ETA: 10:18:43 - Validation Loss: -0.4081Regenning Datset\n",
      " 63100/300000 [=====>........................] - ETA: 10:14:35 - Validation Loss: -0.3753Regenning Datset\n",
      " 64700/300000 [=====>........................] - ETA: 10:10:08 - Validation Loss: -0.3418Regenning Datset\n",
      " 66200/300000 [=====>........................] - ETA: 10:06:05 - Validation Loss: -0.3100Regenning Datset\n",
      " 67800/300000 [=====>........................] - ETA: 10:01:43 - Validation Loss: -0.2774Regenning Datset\n",
      " 69300/300000 [=====>........................] - ETA: 9:57:38 - Validation Loss: -0.2474Regenning Datset\n",
      " 70800/300000 [======>.......................] - ETA: 9:53:34 - Validation Loss: -0.2175Regenning Datset\n",
      " 72400/300000 [======>.......................] - ETA: 9:49:15 - Validation Loss: -0.1860Regenning Datset\n",
      " 73900/300000 [======>.......................] - ETA: 9:45:14 - Validation Loss: -0.1562Regenning Datset\n",
      " 75500/300000 [======>.......................] - ETA: 9:40:55 - Validation Loss: -0.1244Regenning Datset\n",
      " 77000/300000 [======>.......................] - ETA: 9:36:56 - Validation Loss: -0.0944Regenning Datset\n",
      " 78500/300000 [======>.......................] - ETA: 9:32:55 - Validation Loss: -0.0658Regenning Datset\n",
      " 80100/300000 [=======>......................] - ETA: 9:28:37 - Validation Loss: -0.0354Regenning Datset\n",
      " 81600/300000 [=======>......................] - ETA: 9:24:37 - Validation Loss: -0.0079Regenning Datset\n",
      " 83200/300000 [=======>......................] - ETA: 9:20:21 - Validation Loss: 0.0221Regenning Datset\n",
      " 84700/300000 [=======>......................] - ETA: 9:16:21 - Validation Loss: 0.0512Regenning Datset\n",
      " 86200/300000 [=======>......................] - ETA: 9:12:19 - Validation Loss: 0.0797Regenning Datset\n",
      " 87800/300000 [=======>......................] - ETA: 9:08:00 - Validation Loss: 0.1081Regenning Datset\n",
      " 89300/300000 [=======>......................] - ETA: 9:04:00 - Validation Loss: 0.1361Regenning Datset\n",
      " 90900/300000 [========>.....................] - ETA: 8:59:45 - Validation Loss: 0.1656Regenning Datset\n",
      " 92400/300000 [========>.....................] - ETA: 8:55:45 - Validation Loss: 0.1925Regenning Datset\n",
      " 93900/300000 [========>.....................] - ETA: 8:51:48 - Validation Loss: 0.2183Regenning Datset\n",
      " 95500/300000 [========>.....................] - ETA: 8:47:33 - Validation Loss: 0.2458Regenning Datset\n",
      " 97000/300000 [========>.....................] - ETA: 8:43:35 - Validation Loss: 0.2700Regenning Datset\n",
      " 98500/300000 [========>.....................] - ETA: 8:39:37 - Validation Loss: 0.2944Regenning Datset\n",
      "100100/300000 [=========>....................] - ETA: 8:35:22 - Validation Loss: 0.3196Regenning Datset\n",
      "101600/300000 [=========>....................] - ETA: 8:31:24 - Validation Loss: 0.3432Regenning Datset\n",
      "103200/300000 [=========>....................] - ETA: 8:27:09 - Validation Loss: 0.3690Regenning Datset\n",
      "104700/300000 [=========>....................] - ETA: 8:23:15 - Validation Loss: 0.3937Regenning Datset\n",
      "106200/300000 [=========>....................] - ETA: 8:19:18 - Validation Loss: 0.4175Regenning Datset\n",
      "107800/300000 [=========>....................] - ETA: 8:15:06 - Validation Loss: 0.4429Regenning Datset\n",
      "109300/300000 [=========>....................] - ETA: 8:11:09 - Validation Loss: 0.4661Regenning Datset\n",
      "110900/300000 [==========>...................] - ETA: 8:06:56 - Validation Loss: 0.4901Regenning Datset\n",
      "112400/300000 [==========>...................] - ETA: 8:03:01 - Validation Loss: 0.5132Regenning Datset\n",
      "113900/300000 [==========>...................] - ETA: 7:59:04 - Validation Loss: 0.5353Regenning Datset\n",
      "115500/300000 [==========>...................] - ETA: 7:54:51 - Validation Loss: 0.5578Regenning Datset\n",
      "117000/300000 [==========>...................] - ETA: 7:50:54 - Validation Loss: 0.5784Regenning Datset\n",
      "118600/300000 [==========>...................] - ETA: 7:46:43 - Validation Loss: 0.6009Regenning Datset\n",
      "120100/300000 [===========>..................] - ETA: 7:42:47 - Validation Loss: 0.6221Regenning Datset\n",
      "121600/300000 [===========>..................] - ETA: 7:38:50 - Validation Loss: 0.6438Regenning Datset\n",
      "123200/300000 [===========>..................] - ETA: 7:34:40 - Validation Loss: 0.6668Regenning Datset\n",
      "124700/300000 [===========>..................] - ETA: 7:30:43 - Validation Loss: 0.6874Regenning Datset\n",
      "126200/300000 [===========>..................] - ETA: 7:26:49 - Validation Loss: 0.7084Regenning Datset\n",
      "127800/300000 [===========>..................] - ETA: 7:22:39 - Validation Loss: 0.7294Regenning Datset\n",
      "129300/300000 [===========>..................] - ETA: 7:18:44 - Validation Loss: 0.7490Regenning Datset\n",
      "130900/300000 [============>.................] - ETA: 7:14:32 - Validation Loss: 0.7699Regenning Datset\n",
      "132400/300000 [============>.................] - ETA: 7:10:37 - Validation Loss: 0.7894Regenning Datset\n",
      "133900/300000 [============>.................] - ETA: 7:06:42 - Validation Loss: 0.8087Regenning Datset\n",
      "135500/300000 [============>.................] - ETA: 7:02:31 - Validation Loss: 0.8284Regenning Datset\n",
      "137000/300000 [============>.................] - ETA: 6:58:38 - Validation Loss: 0.8487Regenning Datset\n",
      "138600/300000 [============>.................] - ETA: 6:54:26 - Validation Loss: 0.8687Regenning Datset\n",
      "140100/300000 [=============>................] - ETA: 6:50:31 - Validation Loss: 0.8875Regenning Datset\n",
      "141600/300000 [=============>................] - ETA: 6:46:38 - Validation Loss: 0.9062Regenning Datset\n",
      "143200/300000 [=============>................] - ETA: 6:42:27 - Validation Loss: 0.9253Regenning Datset\n",
      "144700/300000 [=============>................] - ETA: 6:38:34 - Validation Loss: 0.9436Regenning Datset\n",
      "146300/300000 [=============>................] - ETA: 6:34:25 - Validation Loss: 0.9625Regenning Datset\n",
      "147800/300000 [=============>................] - ETA: 6:30:31 - Validation Loss: 0.9817Regenning Datset\n",
      "149300/300000 [=============>................] - ETA: 6:26:40 - Validation Loss: 1.0003Regenning Datset\n",
      "150900/300000 [==============>...............] - ETA: 6:22:30 - Validation Loss: 1.0201Regenning Datset\n",
      "152400/300000 [==============>...............] - ETA: 6:18:36 - Validation Loss: 1.0384Regenning Datset\n",
      "153900/300000 [==============>...............] - ETA: 6:14:45 - Validation Loss: 1.0561Regenning Datset\n",
      "155500/300000 [==============>...............] - ETA: 6:10:37 - Validation Loss: 1.0747Regenning Datset\n",
      "157000/300000 [==============>...............] - ETA: 6:06:43 - Validation Loss: 1.0919Regenning Datset\n",
      "158600/300000 [==============>...............] - ETA: 6:02:34 - Validation Loss: 1.1113Regenning Datset\n",
      "160100/300000 [===============>..............] - ETA: 5:58:42 - Validation Loss: 1.1279Regenning Datset\n",
      "161600/300000 [===============>..............] - ETA: 5:54:50 - Validation Loss: 1.1462Regenning Datset\n",
      "163200/300000 [===============>..............] - ETA: 5:50:41 - Validation Loss: 1.1639Regenning Datset\n",
      "164700/300000 [===============>..............] - ETA: 5:46:51 - Validation Loss: 1.1815Regenning Datset\n",
      "166300/300000 [===============>..............] - ETA: 5:42:43 - Validation Loss: 1.2006Regenning Datset\n",
      "167800/300000 [===============>..............] - ETA: 5:38:50 - Validation Loss: 1.2176Regenning Datset\n",
      "169300/300000 [===============>..............] - ETA: 5:34:57 - Validation Loss: 1.2341Regenning Datset\n",
      "170900/300000 [================>.............] - ETA: 5:30:48 - Validation Loss: 1.2516Regenning Datset\n",
      "172400/300000 [================>.............] - ETA: 5:26:56 - Validation Loss: 1.2677Regenning Datset\n",
      "174000/300000 [================>.............] - ETA: 5:22:49 - Validation Loss: 1.2847Regenning Datset\n",
      "175500/300000 [================>.............] - ETA: 5:18:57 - Validation Loss: 1.3014Regenning Datset\n",
      "177000/300000 [================>.............] - ETA: 5:15:05 - Validation Loss: 1.3180Regenning Datset\n",
      "178600/300000 [================>.............] - ETA: 5:10:57 - Validation Loss: 1.3358Regenning Datset\n",
      "180100/300000 [=================>............] - ETA: 5:07:05 - Validation Loss: 1.3521Regenning Datset\n",
      "181700/300000 [=================>............] - ETA: 5:02:58 - Validation Loss: 1.3684Regenning Datset\n",
      "183200/300000 [=================>............] - ETA: 4:59:06 - Validation Loss: 1.3845Regenning Datset\n",
      "184700/300000 [=================>............] - ETA: 4:55:14 - Validation Loss: 1.3998Regenning Datset\n",
      "186300/300000 [=================>............] - ETA: 4:51:06 - Validation Loss: 1.4165Regenning Datset\n",
      "187800/300000 [=================>............] - ETA: 4:47:15 - Validation Loss: 1.4321Regenning Datset\n",
      "189300/300000 [=================>............] - ETA: 4:43:25 - Validation Loss: 1.4476Regenning Datset\n",
      "190900/300000 [==================>...........] - ETA: 4:39:17 - Validation Loss: 1.4648Regenning Datset\n",
      "192400/300000 [==================>...........] - ETA: 4:35:26 - Validation Loss: 1.4796Regenning Datset\n",
      "194000/300000 [==================>...........] - ETA: 4:31:18 - Validation Loss: 1.4957Regenning Datset\n",
      "195500/300000 [==================>...........] - ETA: 4:27:27 - Validation Loss: 1.5099Regenning Datset\n",
      "197000/300000 [==================>...........] - ETA: 4:23:37 - Validation Loss: 1.5245Regenning Datset\n",
      "198600/300000 [==================>...........] - ETA: 4:19:31 - Validation Loss: 1.5406Regenning Datset\n",
      "200100/300000 [===================>..........] - ETA: 4:15:40 - Validation Loss: 1.5560Regenning Datset\n",
      "201700/300000 [===================>..........] - ETA: 4:11:34 - Validation Loss: 1.5723Regenning Datset\n",
      "203200/300000 [===================>..........] - ETA: 4:07:42 - Validation Loss: 1.5875Regenning Datset\n",
      "204700/300000 [===================>..........] - ETA: 4:03:51 - Validation Loss: 1.6025Regenning Datset\n",
      "206300/300000 [===================>..........] - ETA: 3:59:45 - Validation Loss: 1.6183Regenning Datset\n",
      "207800/300000 [===================>..........] - ETA: 3:55:54 - Validation Loss: 1.6332Regenning Datset\n",
      "209400/300000 [===================>..........] - ETA: 3:51:48 - Validation Loss: 1.6487Regenning Datset\n",
      "210900/300000 [====================>.........] - ETA: 3:47:58 - Validation Loss: 1.6632Regenning Datset\n",
      "212400/300000 [====================>.........] - ETA: 3:44:08 - Validation Loss: 1.6778Regenning Datset\n",
      "214000/300000 [====================>.........] - ETA: 3:40:01 - Validation Loss: 1.6932Regenning Datset\n",
      "215500/300000 [====================>.........] - ETA: 3:36:11 - Validation Loss: 1.7074Regenning Datset\n",
      "217000/300000 [====================>.........] - ETA: 3:32:21 - Validation Loss: 1.7219Regenning Datset\n",
      "218600/300000 [====================>.........] - ETA: 3:28:15 - Validation Loss: 1.7380Regenning Datset\n",
      "220100/300000 [=====================>........] - ETA: 3:24:26 - Validation Loss: 1.7528Regenning Datset\n",
      "221700/300000 [=====================>........] - ETA: 3:20:21 - Validation Loss: 1.7682Regenning Datset\n",
      "223200/300000 [=====================>........] - ETA: 3:16:31 - Validation Loss: 1.7823Regenning Datset\n",
      "224700/300000 [=====================>........] - ETA: 3:12:42 - Validation Loss: 1.7965Regenning Datset\n",
      "226300/300000 [=====================>........] - ETA: 3:08:36 - Validation Loss: 1.8118Regenning Datset\n",
      "227800/300000 [=====================>........] - ETA: 3:04:47 - Validation Loss: 1.8263Regenning Datset\n",
      "229400/300000 [=====================>........] - ETA: 3:00:42 - Validation Loss: 1.8411Regenning Datset\n",
      "230500/300000 [======================>.......] - ETA: 2:57:55 - Validation Loss: 1.8518"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a376bca16aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#train_obs,train_acts,train_goals, train_mask = sample_sequence_batch(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_obs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Repeat datasets indefinitely\n",
    "valid_data_iter = iter(tf_valid_data.repeat(-1))\n",
    "#train_data_iter = iter(tf_train_data.repeat(-1))\n",
    "\n",
    "# TODO RAY async trajectories in background so we can watch it's learning progress.\n",
    "# We want to reshuffle the datset each time\n",
    "\n",
    "train_data_iter = iter(rsd.create_tf_ds('train'))\n",
    "\n",
    "t0  = time.time()\n",
    "for t in range(len(steps),n_steps):\n",
    "    t1= time.time()\n",
    "    try:\n",
    "        train_obs,train_acts,train_goals, train_mask, _,_  = train_data_iter.next()\n",
    "    except:\n",
    "        print('Regenning Datset')\n",
    "        train_data_iter= iter(rsd.create_tf_ds('train'))\n",
    "        train_obs,train_acts,train_goals, train_mask, _,_  = train_data_iter.next()\n",
    "        \n",
    "    #train_obs,train_acts,train_goals, train_mask = sample_sequence_batch(train_data)\n",
    "    t2 = time.time()\n",
    "    loss = train_step(train_obs,train_acts,train_goals, model, optimizer, train_mask)\n",
    "    t3 = time.time()\n",
    "    data_time.append(t2-t1)\n",
    "    train_time.append(t3-t2)\n",
    "    steps.append(t)\n",
    "    losses.append(loss)\n",
    "    if t % 100 == 0:\n",
    "        valid_steps.append(t)\n",
    "        valid_obs, valid_acts, valid_goals, valid_mask,_,_ = valid_data_iter.next()\n",
    "        #valid_obs, valid_acts, valid_goals, valid_mask = sample_sequence_batch(valid_data)\n",
    "        valid_loss = step(valid_obs, valid_acts, valid_goals, model, valid_mask)\n",
    "        valid_losses.append(valid_loss)\n",
    "        progbar.add(100, [('Validation Loss', valid_loss)])\n",
    "        if valid_loss.numpy() <= best_valid_loss:\n",
    "            model.save_weights('saved_models/ONEOBJ_play')\n",
    "            best_valid_loss = valid_loss.numpy()\n",
    "        \n",
    "        #print(t, valid_loss)\n",
    "    \n",
    "    \n",
    "plt.plot(steps, losses)\n",
    "plt.plot(valid_steps, valid_losses)\n",
    "print(f\"Total time was {time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7a7473afd0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "plt.plot(steps, losses)\n",
    "plt.plot(valid_steps, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(sum(data_time), sum(train_time)) #Tristan pls fix my retarded data input pipieline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('good1obj2048')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(0, g.shape[-1]):\n",
    "#     plt.hist( g[:, :, i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect, Deterministic Reset and Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/home/sholto/Desktop/AI/pandaRL/pandaRL/envs\n",
      "/home/sholto/Desktop/AI/pandaRL/pandaRL/envs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sholto/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "import pandaRL\n",
    "env = gym.make('pandaPlayJoints1Obj-v0')\n",
    "env.reset()\n",
    "env.render('playback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/home/sholto/Desktop/AI/pandaRL/pandaRL/envs\n",
      "/home/sholto/Desktop/AI/pandaRL/pandaRL/envs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sholto/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'observation': array([-5.28812446e-02,  8.03594738e-02,  6.39511719e-02, -5.00000834e-01,\n",
       "         5.00003517e-01,  4.99988109e-01,  5.00007510e-01,  0.00000000e+00,\n",
       "         9.70024150e-03,  1.21327564e-01,  5.87366559e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  4.01235396e-35,\n",
       "         0.00000000e+00,  1.10677083e-03,  0.00000000e+00], dtype=float32),\n",
       " 'achieved_goal': array([9.70024150e-03, 1.21327564e-01, 5.87366559e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 4.01235396e-35,\n",
       "        0.00000000e+00, 1.10677083e-03, 0.00000000e+00], dtype=float32),\n",
       " 'desired_goal': array([0.08497275, 0.21297932, 0.09821208], dtype=float32),\n",
       " 'controllable_achieved_goal': array([-0.05288124,  0.08035947,  0.06395117,  0.        ], dtype=float32),\n",
       " 'full_positional_state': array([-5.28812446e-02,  8.03594738e-02,  6.39511719e-02, -5.00000834e-01,\n",
       "         5.00003517e-01,  4.99988109e-01,  5.00007510e-01,  0.00000000e+00,\n",
       "         9.70024150e-03,  1.21327564e-01,  5.87366559e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  4.01235396e-35,\n",
       "         0.00000000e+00,  1.10677083e-03,  0.00000000e+00], dtype=float32),\n",
       " 'joints': [-0.008544189158468551,\n",
       "  0.6507350294023287,\n",
       "  -0.2957179695252731,\n",
       "  -2.214127819368449,\n",
       "  1.3815556417494523,\n",
       "  1.3333234062411772,\n",
       "  1.0386982117681267,\n",
       "  0.0],\n",
       " 'img': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "import pandaRL\n",
    "if RELATIVE_JOINTS:\n",
    "    env = gym.make('pandaPlayJoints1Obj-v0')\n",
    "    #env = gym.make('pandaPlayJoints-v0')\n",
    "else:\n",
    "    env = gym.make('pandaPlay-v0')\n",
    "env.render('human')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_it = iter(tf_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 80, 19) (32, 80, 8) (32, 80, 11) (32, 80)\n"
     ]
    }
   ],
   "source": [
    "o, a, g, m, pth, tsteps = t_it.next()\n",
    "print(o.shape, a.shape, g.shape, m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(o))\n",
    "traj_end = len(np.where(m[idx] == 1)[0])-1\n",
    "#env.panda.reset_goal_pos(ag_to_dg(g[idx, traj_end,:]))\n",
    "env.p.restoreState(fileName=dataset_path+'states_and_ims/'+str(int(pth[idx]))+'/env_states/'+str(int(tsteps[idx,0]))+'.bullet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, traj_end+1):\n",
    "    #env.p.restoreState(fileName=dataset_path+str(int(pth[idx]))+'/env_states/'+str(int(tsteps[idx,i]))+'.bullet')\n",
    "    #time.sleep(0.1)\n",
    "    env.step(a[idx, i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_subsequences(t_it, retries = 3, use_ori = True, replay=False):\n",
    "    \n",
    "    \n",
    "    obs, acts, goals, masks, pth, tsteps = t_it.next()\n",
    "    idx = np.random.choice(len(obs))\n",
    "    \n",
    "    \n",
    "    start_idx = str(int(tsteps[idx,0]))\n",
    "    traj_end = len(np.where(masks[idx] == 1)[0])-1\n",
    "    \n",
    "    env.p.restoreState(fileName=dataset_path+'states_and_ims/'+str(int(pth[idx]))+'/env_states/'+str(int(tsteps[idx,0]))+'.bullet')\n",
    "    print(dataset_path+'states_and_ims/'+str(int(pth[idx]))+'/env_states/'+str(int(tsteps[idx,0]))+'.bullet')\n",
    "    o = tf.expand_dims(obs[idx][0],0)\n",
    "    \n",
    "    goal = goals[idx, traj_end,:]\n",
    "    #env.panda.reset_goal_pos(ag_to_dg(goal))\n",
    "    goal = tf.expand_dims(goal, 0)\n",
    "    \n",
    "    \n",
    "    if replay:\n",
    "        retries = 1\n",
    "\n",
    "        \n",
    "    for i in range(0,retries):\n",
    "        past_state = [None, None]\n",
    "        for i in range(0, traj_end+1):\n",
    "\n",
    "            \n",
    "            if not use_ori:\n",
    "                a[3:7] =  np.array(env.panda.default_arm_orn) # because it hasn't ever had to cope with\n",
    "            if replay:\n",
    "                a=acts[idx, i, :] # uncomment this to replay play subsequences\n",
    "            else:\n",
    "                distrib, past_state = model(o, goal,  past_state = past_state)\n",
    "                a = distrib.sample().numpy().squeeze() \n",
    "                \n",
    "            o, r, d, _ = env.step(a)\n",
    "            o = tf.expand_dims(o['observation'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/236.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/598.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4128.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/720.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3586.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1193.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2950.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/956.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1020.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1672.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2849.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/851.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3075.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1252.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1578.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/584.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1802.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/709.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4344.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1615.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2678.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/910.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2873.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/914.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4890.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1765.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2506.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/2160.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/122.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/641.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4609.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/282.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3372.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/634.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/299.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3143.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1143.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/667.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/2123.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1684.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/736.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/110.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3235.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/510.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/306.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2892.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/982.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/736.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3630.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4601.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1045.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/774.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/521.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/480.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/2408.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1769.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2658.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2492.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/340.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1070.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/55.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/96.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2187.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/453.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4550.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4022.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1600.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2913.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/2066.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/343.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1164.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1123.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4950.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1899.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1724.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/566.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2527.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3785.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3029.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2418.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2954.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1700.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1040.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2281.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/707.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/611.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/2110.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/2333.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4602.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4170.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/102.bullet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/4358.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/1477.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3097.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/2/env_states/786.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1154.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/677.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1275.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/1800.bullet\n",
      "data_collection/collected_data/play_one_obj_demos/states_and_ims/14/env_states/3861.bullet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = iter(tf_valid_data)\n",
    "for i in range(0,100):\n",
    "    test_subsequences(data, retries=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLP Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ag_to_dg(ag):\n",
    "    dg = np.concatenate([ag[0:3], ag[7:10]])\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This below is only appropriate for non sequence models, which will aim for shorter timespans. \n",
    "n_valid_trajectories = len(valid_data['obs'])\n",
    "idx = np.random.choice(n_valid_trajectories)\n",
    "traj_obs, traj_acts, traj_init_o, traj_init_v = [valid_data[key][idx] for key in valid_data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "o = env.reset()\n",
    "# A few representative points along the trajectory for us to test how it goes from there (before it loses coherence\n",
    "# over the long trajectory)\n",
    "ZERO, QUARTER, HALF, THREEQ = 0, len(traj_obs)//4, len(traj_obs)//2, len(traj_obs)*3//4\n",
    "# Get the init point\n",
    "init_o = traj_obs[THREEQ][START_OBS:END_OBS]# traj_init_o\n",
    "# reset to our desired init, but with 0 velocity - fine for now. \n",
    "env.robot.reset(env, init_o, traj_init_v)\n",
    "# select the goal as the end state of the trajectory \n",
    "goal = traj_obs[-1][START_GOAL:END_GOAL]\n",
    "for i in range(len(traj_acts)):\n",
    "    o = tf.expand_dims(np.concatenate([o[START_OBS:END_OBS], goal], -1),0)\n",
    "    if PROBS:# need to sample from the model if its probabilistic. \n",
    "        a = model(o).sample()[0]\n",
    "    else:\n",
    "        a = model.predict(o)[0]\n",
    "    #a = traj_acts[i]\n",
    "    o, r, d, _ = env.step(a) # the key change\n",
    "    \n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid = dataset[int(N_TRAJS*train_partition):]\n",
    "\n",
    "def test_subsequences():\n",
    "    \n",
    "    obs, acts, goals, masks = sample_sequence_batch(valid)\n",
    "    o = env.reset()\n",
    "    idx = np.random.choice(len(obs))\n",
    "    traj_end = len(np.where(masks[idx] == 1)[0])-1\n",
    "\n",
    "    masks[idx][traj_end]\n",
    "    start_pos = obs[idx][0][START_OBS:END_OBS].numpy()\n",
    "    goal = np.expand_dims(obs[idx][traj_end][START_GOAL:END_GOAL],0)\n",
    "    zero_vel = np.zeros(29)\n",
    "\n",
    "    env.robot.reset(env, start_pos, zero_vel)\n",
    "    o = np.squeeze(obs[idx][0])\n",
    "    env.render()\n",
    "    past_state = [None, None]\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        for i in range(0, traj_end+1):\n",
    "            o = tf.expand_dims(o[START_OBS:END_OBS], 0)\n",
    "            distrib, past_state = model(o, goal,  past_state = past_state)\n",
    "\n",
    "            a = distrib.sample().numpy().squeeze() \n",
    "            #a = acts[idx, i, :] # uncomment this to replay play subsequences\n",
    "            o, r, d, _ = env.step(a)\n",
    "            env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    test_subsequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# What about on a full trajectory? Where we give it the intermediate goals?\n",
    "n_valid_trajectories = len(valid)\n",
    "idx = np.random.choice(n_valid_trajectories)\n",
    "traj_obs, traj_acts, traj_goals, traj_init_o, traj_init_v = [valid[idx][key] for key in valid[idx].keys()]\n",
    "o = env.reset()\n",
    "traj_len = len(traj_obs)\n",
    "intervals = np.array([0, traj_len//4, traj_len//2, traj_len*3//4, traj_len])\n",
    "init_o = traj_obs[0][START_OBS:END_OBS]# traj_init_o\n",
    "# reset to our desired init, but with 0 velocity - fine for now. \n",
    "env.robot.reset(env, init_o, traj_init_v)\n",
    "env.render()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "past_state = [None, None]\n",
    "for t in range(traj_len):\n",
    "        goal_idx = np.where(t < intervals)[0][0] # which part of the task we are up to\n",
    "        goal = tf.cast(tf.expand_dims(traj_obs[intervals[goal_idx]-1][START_GOAL:END_GOAL], 0), tf.float32)\n",
    "        o = tf.cast(tf.expand_dims(o[START_OBS:END_OBS],0), tf.float32)\n",
    "        distrib, past_state = model(o,goal, past_state = past_state)\n",
    "        \n",
    "        #a = distrib.sample().numpy().squeeze() \n",
    "        a = traj_acts[t, :] # uncomment this to replay play subsequences\n",
    "        o, r, d, _ = env.step(a)\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mine = [2,3,2,1,0,1,0,3,3,1,1,3]\n",
    "fast = [0,2,2,0,1,4,0,2,1,4,3,0]\n",
    "print(np.mean(mine), np.mean(fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf.concat([o, goal], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "#     train_acc_metric.update_state(y, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "#     val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch}\")\n",
    "    start_time = time.time()\n",
    "    progbar = Progbar(len(observations), verbose=1, interval=0.5)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (obs,acts) in enumerate(zip(observations, actions)):\n",
    "#         obs = traj_batch['observations']\n",
    "#         acts = traj_batch['actions']\n",
    "    \n",
    "        loss_value = train_step(obs, acts)\n",
    "        progbar.add(1, [('Loss', loss_value)])\n",
    "#     print()\n",
    "        \n",
    "    # Display metrics at the end of each epoch.\n",
    "#     train_acc = train_acc_metric.result()\n",
    "#     print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "#     train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "#     for x_batch_val, y_batch_val in val_dataset:\n",
    "#         test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "#     val_acc = val_acc_metric.result()\n",
    "#     val_acc_metric.reset_states()\n",
    "#     print(\"Validation acc: %.4f\" % (float(val_acc),))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch}\")\n",
    "    start_time = time.time()\n",
    "    progbar = Progbar(len(observations), verbose=1, interval=0.5)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (obs,acts) in enumerate(zip(observations, actions)):\n",
    "#         obs = traj_batch['observations']\n",
    "#         acts = traj_batch['actions']\n",
    "    \n",
    "        loss_value = train_step(obs, acts)\n",
    "        progbar.add(1, [('Loss', loss_value)])\n",
    "#     print()\n",
    "        \n",
    "    # Display metrics at the end of each epoch.\n",
    "#     train_acc = train_acc_metric.result()\n",
    "#     print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "#     train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "#     for x_batch_val, y_batch_val in val_dataset:\n",
    "#         test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "#     val_acc = val_acc_metric.result()\n",
    "#     val_acc_metric.reset_states()\n",
    "#     print(\"Validation acc: %.4f\" % (float(val_acc),))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import adept_envs\n",
    "\n",
    "env = gym.make(\"kitchen_relax-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLP Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This below is only appropriate for non sequence models, which will aim for shorter timespans. \n",
    "n_valid_trajectories = len(valid_data['obs'])\n",
    "idx = np.random.choice(n_valid_trajectories)\n",
    "traj_obs, traj_acts, traj_init_o, traj_init_v = [valid_data[key][idx] for key in valid_data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "o = env.reset()\n",
    "# A few representative points along the trajectory for us to test how it goes from there (before it loses coherence\n",
    "# over the long trajectory)\n",
    "ZERO, QUARTER, HALF, THREEQ = 0, len(traj_obs)//4, len(traj_obs)//2, len(traj_obs)*3//4\n",
    "# Get the init point\n",
    "init_o = traj_obs[THREEQ][START_OBS:END_OBS]# traj_init_o\n",
    "# reset to our desired init, but with 0 velocity - fine for now. \n",
    "env.robot.reset(env, init_o, traj_init_v)\n",
    "# select the goal as the end state of the trajectory \n",
    "goal = traj_obs[-1][START_GOAL:END_GOAL]\n",
    "for i in range(len(traj_acts)):\n",
    "    o = tf.expand_dims(np.concatenate([o[START_OBS:END_OBS], goal], -1),0)\n",
    "    if PROBS:# need to sample from the model if its probabilistic. \n",
    "        a = model(o).sample()[0]\n",
    "    else:\n",
    "        a = model.predict(o)[0]\n",
    "    #a = traj_acts[i]\n",
    "    o, r, d, _ = env.step(a) # the key change\n",
    "    \n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_subsequences():\n",
    "    obs, acts, masks = sample_sequence_batch(valid_data)\n",
    "    o = env.reset()\n",
    "    idx = np.random.choice(len(obs))\n",
    "    traj_end = len(np.where(masks[idx] == 1)[0])-1\n",
    "\n",
    "    masks[idx][traj_end]\n",
    "    start_pos = obs[idx][0][START_OBS:END_OBS].numpy()\n",
    "    goal = obs[idx][traj_end][START_GOAL:END_GOAL]\n",
    "    zero_vel = np.zeros(29)\n",
    "\n",
    "    env.robot.reset(env, start_pos, zero_vel)\n",
    "    o = np.squeeze(obs[idx][0])\n",
    "    env.render()\n",
    "\n",
    "\n",
    "    past_state = [None, None]\n",
    "\n",
    "    for i in range(0, traj_end+1):\n",
    "        o = tf.expand_dims(np.concatenate([o[START_OBS:END_OBS], goal], -1),0)\n",
    "        distrib, past_state = model(o, past_state = past_state)\n",
    "        #a = acts[idx, i, :] # uncomment this to replay play subsequences\n",
    "        a = distrib.sample().numpy().squeeze() \n",
    "        o, r, d, _ = env.step(a)\n",
    "        env.render()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    test_subsequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# What about on a full trajectory? Where we give it the intermediate goals?\n",
    "n_valid_trajectories = len(valid_data)\n",
    "idx = np.random.choice(n_valid_trajectories)\n",
    "traj_obs, traj_acts, traj_init_o, traj_init_v = [valid_data[key][idx] for key in valid_data.keys()]\n",
    "o = env.reset()\n",
    "traj_len = len(traj_obs)\n",
    "intervals = np.array([0, traj_len//4, traj_len//2, traj_len*3//4, traj_len])\n",
    "init_o = traj_obs[0][START_OBS:END_OBS]# traj_init_o\n",
    "# reset to our desired init, but with 0 velocity - fine for now. \n",
    "env.robot.reset(env, init_o, traj_init_v)\n",
    "env.render()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_state = [None, None]\n",
    "for t in range(traj_len):\n",
    "        goal_idx = np.where(t < intervals)[0][0] # which part of the task we are up to\n",
    "        goal = traj_obs[intervals[goal_idx]-1][START_GOAL:END_GOAL]\n",
    "        o = tf.expand_dims(np.concatenate([o[START_OBS:END_OBS], goal], -1),0)\n",
    "        distrib, past_state = model(o, past_state = past_state)\n",
    "        #a = acts[idx, i, :] # uncomment this to replay play subsequences\n",
    "        a = distrib.sample().numpy().squeeze() \n",
    "        o, r, d, _ = env.step(a)\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about on a full trajectory? Where we give it the intermediate goals?\n",
    "n_valid_trajectories = len(valid_data)\n",
    "idx = np.random.choice(n_valid_trajectories)\n",
    "traj_obs, traj_acts, traj_init_o, traj_init_v = [valid_data[key][idx] for key in valid_data.keys()]\n",
    "o = env.reset()\n",
    "traj_len = len(traj_obs)\n",
    "intervals = np.array([0, traj_len//4, traj_len//2, traj_len*3//4, traj_len])\n",
    "init_o = traj_obs[0][START_OBS:END_OBS]# traj_init_o\n",
    "# reset to our desired init, but with 0 velocity - fine for now. \n",
    "env.robot.reset(env, init_o, traj_init_v)\n",
    "env.render()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_state = [None, None]\n",
    "for t in range(traj_len):\n",
    "        goal_idx = np.where(t < intervals)[0][0] # which part of the task we are up to\n",
    "        goal = traj_obs[intervals[goal_idx]-1][START_GOAL:END_GOAL]\n",
    "        o = tf.expand_dims(np.concatenate([o[START_OBS:END_OBS], goal], -1),0)\n",
    "        distrib, past_state = model(o, past_state = past_state)\n",
    "        #a = acts[idx, i, :] # uncomment this to replay play subsequences\n",
    "        a = distrib.sample().numpy().squeeze() \n",
    "        o, r, d, _ = env.step(a)\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "#     train_acc_metric.update_state(y, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "#     val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch}\")\n",
    "    start_time = time.time()\n",
    "    progbar = Progbar(len(observations), verbose=1, interval=0.5)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (obs,acts) in enumerate(zip(observations, actions)):\n",
    "#         obs = traj_batch['observations']\n",
    "#         acts = traj_batch['actions']\n",
    "    \n",
    "        loss_value = train_step(obs, acts)\n",
    "        progbar.add(1, [('Loss', loss_value)])\n",
    "#     print()\n",
    "        \n",
    "    # Display metrics at the end of each epoch.\n",
    "#     train_acc = train_acc_metric.result()\n",
    "#     print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "#     train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "#     for x_batch_val, y_batch_val in val_dataset:\n",
    "#         test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "#     val_acc = val_acc_metric.result()\n",
    "#     val_acc_metric.reset_states()\n",
    "#     print(\"Validation acc: %.4f\" % (float(val_acc),))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3*180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "54/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48+6+45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.928203230275509"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "135/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "705-25*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "570-20*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
