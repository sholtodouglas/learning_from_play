{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LMP Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G84fGXVwv9Fh",
        "-yC0L1P3v9GA",
        "8SHQGBjnv9GK",
        "b7CMny5dv9Gx",
        "njbQpQAGv9G2"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "lfp_venv",
      "language": "python",
      "name": "lfp_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/train_lfp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxJ4ndRw18QF",
        "outputId": "bf760a45-6cd0-4d2d-aae2-9e4962de0417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install wandb -q\n",
        "!pip install pathy -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 6.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 23.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 13.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.5MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 122kB 9.5MB/s \n",
            "\u001b[?25h  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNiDIt3L0ImF",
        "outputId": "9fe4c72f-bab5-420d-c3b5-9389dd3f3ed1"
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='LFP training arguments')\n",
        "parser.add_argument('run_name')\n",
        "parser.add_argument('--train_datasets', nargs='+', help='Training dataset names')\n",
        "parser.add_argument('--test_datasets', nargs='+', help='Testing dataset names')\n",
        "parser.add_argument('-c', '--colab', default=False, action='store_true', help='Enable if using colab environment')\n",
        "parser.add_argument('-s', '--data_source', default='LOCAL', help='Source of training data')\n",
        "parser.add_argument('-tfr', '--from_tfrecords', default=False, action='store_true', help='Enable if using tfrecords format')\n",
        "parser.add_argument('-d', '--device', default='CPU', help='Hardware device to train on')\n",
        "parser.add_argument('-b', '--batch_size', default=32, type=int)\n",
        "parser.add_argument('-la', '--actor_layer_size', default=256, type=int, help='Layer size of actor, increases size of neural net')\n",
        "parser.add_argument('-le', '--encoder_layer_size', default=256, type=int, help='Layer size of encoder, increases size of neural net')\n",
        "parser.add_argument('-lp', '--planner_layer_size', default=256, type=int, help='Layer size of planner, increases size of neural net')\n",
        "parser.add_argument('-z', '--latent_dim', default=32, type=int, help='Size of the VAE latent space')\n",
        "parser.add_argument('-g', '--gcbc', default=False, action='store_true', help='Enables GCBC, a simpler model with no encoder/planner')\n",
        "parser.add_argument('-n', '--num_distribs', default=None, type=int, help='Number of distributions to use in logistic mixture model')\n",
        "parser.add_argument('-q', '--qbits', default=None, type=int, help='Number of quantisation bits to discrete distributions into. Total quantisations = 2**qbits')\n",
        "parser.add_argument('-lr', '--learning_rate', type=float, default=3e-4)\n",
        "parser.add_argument('-t', '--train_steps', type=int, default=100000)\n",
        "parser.add_argument('-r', '--resume', default=False, action='store_true')\n",
        "\n",
        "\n",
        "# args = parser.parse_args()\n",
        "\n",
        "### Sample local config\n",
        "args = parser.parse_args('''\n",
        "dummy_run \n",
        "--train_dataset UR5\n",
        "--test_dataset UR5\n",
        "-tfr\n",
        "'''.split())\n",
        "\n",
        "## Sample colab config\n",
        "args = parser.parse_args('''\n",
        "refactor_test\n",
        "--train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "--test_dataset UR5_slow_gripper_test\n",
        "-c\n",
        "-tfr\n",
        "-s GCS\n",
        "-d TPU\n",
        "-b 512\n",
        "-la 2048\n",
        "-le 512\n",
        "-lp 2048\n",
        "-z 256\n",
        "-lr 3e-4\n",
        "'''.split())\n",
        "\n",
        "## Sample colab config\n",
        "args = parser.parse_args('''\n",
        "single_opt_fully_in_line\n",
        "--train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "--test_dataset UR5_slow_gripper_test\n",
        "-c\n",
        "-s DRIVE\n",
        "-d TPU\n",
        "-b 512\n",
        "-la 2048\n",
        "-le 512\n",
        "-lp 2048\n",
        "-z 256\n",
        "-lr 3e-4\n",
        "'''.split())\n",
        "\n",
        "print(args)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(actor_layer_size=2048, batch_size=512, colab=True, data_source='DRIVE', device='TPU', encoder_layer_size=512, from_tfrecords=False, gcbc=False, latent_dim=256, learning_rate=0.0003, num_distribs=None, planner_layer_size=2048, qbits=None, resume=False, run_name='single_opt_fully_in_line', test_datasets=['UR5_slow_gripper_test'], train_datasets=['UR5', 'UR5_slow_gripper', 'UR5_high_transition'], train_steps=100000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "B5NOOBUY0ImP",
        "outputId": "e7e17c44-e8f3-414f-deff-323358553c6c"
      },
      "source": [
        "from pathlib import Path\n",
        "from pathy import Pathy\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "import pprint\n",
        "import logging\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "import io\n",
        "import wandb\n",
        "from natsort import natsorted\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctlokyqh0ImP",
        "outputId": "a55ba83c-7a9e-417c-c0f1-687de757cd4f"
      },
      "source": [
        "#@title Workpace Setup (Local vs Colab)\n",
        "\n",
        "# Set up working directory and libraries\n",
        "if args.colab:\n",
        "    from google.colab import drive, auth\n",
        "    print('Using colab setup')\n",
        "    WORKING_PATH = Path('/content/learning_from_play')\n",
        "    # Clone repo\n",
        "    try:\n",
        "        !git clone 'https://github.com/sholtodouglas/learning_from_play' {WORKING_PATH}\n",
        "    except: \n",
        "        pass\n",
        "    # Mount drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print('Using local setup')\n",
        "    WORKING_PATH = Path().absolute().parent\n",
        "    print(f'Working path: {WORKING_PATH}')\n",
        "\n",
        "# Change working directory to learning_from_play\n",
        "os.chdir(WORKING_PATH)\n",
        "import lfp\n",
        "        \n",
        "# Set up storage directory and datasets\n",
        "if args.data_source == 'DRIVE':\n",
        "    assert args.colab, \"Must be using Colab\"\n",
        "    print('Reading data from Google Drive')\n",
        "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
        "elif args.data_source == 'GCS':\n",
        "    assert args.colab, \"Must be using Colab\"\n",
        "    print('Reading data from Google Cloud Storage')\n",
        "    r = requests.get('https://ipinfo.io')\n",
        "    region = r.json()['region']\n",
        "    if region != 'Iowa':\n",
        "        logging.warning(f'You are accessing GCS data from {region}, outside of Iowa region')\n",
        "    project_id = 'learning-from-play-303306'\n",
        "    bucket_name = 'iowa_bucket_lfp'\n",
        "    auth.authenticate_user()\n",
        "    STORAGE_PATH = Pathy(f'gs://{bucket_name}')\n",
        "else:\n",
        "    print('Reading data from local filesystem')\n",
        "    STORAGE_PATH = WORKING_PATH\n",
        "\n",
        "print(f'Storage path: {STORAGE_PATH}')\n",
        "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.train_datasets]\n",
        "TEST_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.test_datasets]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab setup\n",
            "Cloning into '/content/learning_from_play'...\n",
            "remote: Enumerating objects: 418, done.\u001b[K\n",
            "remote: Counting objects: 100% (418/418), done.\u001b[K\n",
            "remote: Compressing objects: 100% (282/282), done.\u001b[K\n",
            "remote: Total 1682 (delta 281), reused 248 (delta 135), pack-reused 1264\n",
            "Receiving objects: 100% (1682/1682), 60.68 MiB | 34.95 MiB/s, done.\n",
            "Resolving deltas: 100% (923/923), done.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading data from Google Drive\n",
            "Storage path: /content/drive/My Drive/Robotic Learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EliqxOpPv9Dy"
      },
      "source": [
        "# Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HejtDH_Yx8h",
        "outputId": "fbdcb9db-0a34-4bb6-e0a3-db1791398080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use this to edit modules without needing to restart the kernel\n",
        "!git pull\n",
        "import importlib\n",
        "importlib.reload(lfp.data)\n",
        "importlib.reload(lfp.model)\n",
        "importlib.reload(lfp.plotting)\n",
        "importlib.reload(lfp.train)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/sholtodouglas/learning_from_play\n",
            "   5473e48..bb18510  master     -> origin/master\n",
            "Updating 5473e48..bb18510\n",
            "Fast-forward\n",
            " lfp/train.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'lfp.train' from '/content/learning_from_play/lfp/train.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zbmq324x2yv",
        "outputId": "e17c717b-3a85-4a95-9d6b-d111514f62d2"
      },
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "if args.device == 'TPU':\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
        "    print(\"REPLICAS: \", NUM_DEVICES)\n",
        "else:\n",
        "    physical_devices = tf.config.list_physical_devices()\n",
        "    if args.device == 'GPU':\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
        "    NUM_DEVICES = 1\n",
        "    print(physical_devices)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.108.89.34:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.108.89.34:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.108.89.34:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.108.89.34:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.108.89.34:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL0UZVa1v9D9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI6JP06FdTv"
      },
      "source": [
        "### Config Flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lBWIyOFdTv"
      },
      "source": [
        "GLOBAL_BATCH_SIZE = args.batch_size * NUM_DEVICES\n",
        "\n",
        "dl = lfp.data.PlayDataloader(batch_size=GLOBAL_BATCH_SIZE)\n",
        "dl.shuffle_size = GLOBAL_BATCH_SIZE * 1 # May need to be smaller with images - lets test"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiz4AXCnFdTv",
        "outputId": "890fc78e-1bd8-4363-db98-7c1640010992"
      },
      "source": [
        "# Train data\n",
        "train_data = dl.extract(TRAIN_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "train_dataset = dl.load(train_data)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UR5: 100%|██████████| 52/52 [00:00<00:00, 58.57it/s]\n",
            "UR5_slow_gripper: 100%|██████████| 23/23 [00:00<00:00, 53.44it/s]\n",
            "UR5_high_transition: 100%|██████████| 32/32 [00:00<00:00, 58.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(4096, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(4096, 50, 11), dtype=tf.float32, name=None),\n",
            "    'masks': TensorSpec(shape=(4096, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(4096, 50, 18), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(4096,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ZDAVpLFdTw",
        "outputId": "c39baffb-4ee8-443a-80fb-345940f7a541"
      },
      "source": [
        "# Validation data\n",
        "valid_data = dl.extract(TEST_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "valid_dataset = dl.load(valid_data)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UR5_slow_gripper_test: 100%|██████████| 2/2 [00:00<00:00, 46.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(4096, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(4096, 50, 11), dtype=tf.float32, name=None),\n",
            "    'masks': TensorSpec(shape=(4096, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(4096, 50, 18), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(4096,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN3YJSSLv9Ez",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpRPRuv9E6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uMXBjGzgZCA"
      },
      "source": [
        "def train_setup():\n",
        "    model_params = {'obs_dim':dl.obs_dim,\n",
        "                    'goal_dim':dl.goal_dim,\n",
        "                    'act_dim':dl.act_dim,\n",
        "                    'latent_dim':args.latent_dim}\n",
        "    \n",
        "    actor = lfp.model.create_actor(**model_params, layer_size=args.actor_layer_size, gcbc=args.gcbc, num_distribs=args.num_distribs)\n",
        "\n",
        "    if args.gcbc:\n",
        "        encoder = None\n",
        "        planner = None\n",
        "    else:\n",
        "        encoder = lfp.model.create_encoder(layer_size=args.encoder_layer_size,**model_params)\n",
        "        planner = lfp.model.create_planner(layer_size=args.planner_layer_size,**model_params)\n",
        "        \n",
        "    trainer = lfp.train.LFPTrainer(dl, \n",
        "                                 actor,\n",
        "                                 encoder=encoder, \n",
        "                                 planner=planner, \n",
        "                                 probabilistic=args.num_distribs is not None,\n",
        "                                 distribute_strategy=strategy,\n",
        "                                 learning_rate=args.learning_rate,\n",
        "                                 clipnorm=1.0,\n",
        "                                 gcbc=args.gcbc)\n",
        "    \n",
        "    return trainer\n",
        "\n",
        "if args.device=='GPU' or args.device == 'CPU':\n",
        "    trainer = train_setup()\n",
        "    train_dataset = iter(train_dataset)\n",
        "    valid_dataset = iter(valid_dataset)\n",
        "    plotting_dataset = valid_dataset # For consistnecy with the distributed form \n",
        "else:\n",
        "    with strategy.scope():\n",
        "        trainer = train_setup()   \n",
        "    train_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
        "    plotting_dataset = iter(valid_dataset) # for the cluster fig, easier with a non distributed dataset\n",
        "    valid_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "xtSlIEoBlDyp",
        "outputId": "6fea3dfb-6fb9-4b89-9568-e5315a43fd14"
      },
      "source": [
        "# 0.00001 so far works best for MAE - try lower - 0.00003 with a BETA accel of 10 so far works best, perfect encoder, nicely mapped planner\n",
        "# recall 0.01 worked okay for probabilistic - proba still too unstable!\n",
        "beta_sched = lfp.train.BetaScheduler('linear', \n",
        "                                   beta=0.00003, \n",
        "                                   beta_max=0.00003, \n",
        "                                   max_steps=args.train_steps, \n",
        "                                   cycles=90, \n",
        "                                   duty_cycle=0.5)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSGD_2imWDi"
      },
      "source": [
        "progbar = tf.keras.utils.Progbar(args.train_steps, verbose=1, interval=0.5)\n",
        "best_valid_loss = np.float('inf')\n",
        "\n",
        "valid_inc = 20\n",
        "save_inc = 1000\n",
        "\n",
        "prev_global_grad_norm = np.float('inf')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "oTyriZrYowMJ",
        "outputId": "3fedac58-c8ea-4c4b-b292-0d79647a9887"
      },
      "source": [
        "model_path = f'/content/drive/My Drive/Robotic Learning/saved_models/{args.run_name}/'\n",
        "\n",
        "if args.resume:\n",
        "    with open(model_path+'/config.json') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        wandb.init(project=\"learning-from-play_v2\", id=data['run_id'], resume=\"must\")\n",
        "        trainer.load_weights(model_path, with_optimizer=True)\n",
        "        print('Loaded model weights and optimiser state')\n",
        "        t = wandb.run.step + valid_inc\n",
        "else:\n",
        "    wandb.init(project=\"learning-from-play_v2\", config=args)\n",
        "    wandb.run.name = args.run_name\n",
        "    t = 0"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.17<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">charmed-silence-137</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/1lmo5qyc\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/1lmo5qyc</a><br/>\n",
              "                Run data is saved locally in <code>/content/learning_from_play/wandb/run-20210204_134351-1lmo5qyc</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBKlM1WSSavg"
      },
      "source": [
        "from lfp.metric import log # gets state and clears simultaneously"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXF0Y8aKrsng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7578b3-0598-42b5-f34f-550b223a4ce7"
      },
      "source": [
        "while t < args.train_steps:\n",
        "    start_time = time.time()\n",
        "    beta = beta_sched.scheduler(t)\n",
        "    x = next(train_dataset)\n",
        "    total_train_loss = trainer.distributed_train_step(x, beta, prev_global_grad_norm)\n",
        "    prev_global_grad_norm = log(trainer.metrics['global_grad_norm'])\n",
        "\n",
        "    if t % valid_inc == 0:  \n",
        "        valid_x = next(valid_dataset)\n",
        "        if args.gcbc:\n",
        "            total_val_loss= trainer.distributed_test_step(valid_x, beta)\n",
        "        else:\n",
        "            total_val_loss, ze, zp = trainer.distributed_test_step(valid_x, beta)\n",
        "\n",
        "        metrics = {metric_name: log(metric) for metric_name, metric in trainer.metrics.items()}\n",
        "\n",
        "        # validation plotting\n",
        "        progbar.add(valid_inc, [('Train Loss', metrics['train_loss']), \n",
        "                                ('Validation Loss', metrics['valid_loss']), \n",
        "                                ('Time (s)', round(time.time() - start_time, 1))])\n",
        "\n",
        "        wandb.log(metrics, step=t)\n",
        "          \n",
        "    if t % save_inc == 0:\n",
        "        trainer.save_weights(model_path, args, wandb.run.id)\n",
        "        if not args.gcbc:\n",
        "            z_enc, z_plan = lfp.plotting.produce_cluster_fig(next(plotting_dataset), trainer.encoder, trainer.planner, TEST_DATA_PATHS[0], num_take=dl.batch_size//4)\n",
        "            convergence_plot = lfp.plotting.project_enc_and_plan(ze, zp)\n",
        "            wandb.log({'z_enc':z_enc, 'z_plan':z_plan, 'convergence_plot':convergence_plot}, step=t)\n",
        "    t += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r    20/100000 [..............................] - ETA: 255:54:20 - Train Loss: 0.0303 - Validation Loss: 0.0292 - Time (s): 28.5000Saving training config...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  c = np.array(c)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  c = np.array(c)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    40/100000 [..............................] - ETA: 172:28:48 - Train Loss: 0.0278 - Validation Loss: 0.0243 - Time (s): 15.6500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:474: UserWarning:\n",
            "\n",
            "Dang! That path collection is out of this world. I totally don't know what to do with it yet! Plotly can only import path collections linked to 'data' coordinates\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   140/100000 [..............................] - ETA: 85:29:32 - Train Loss: 0.0159 - Validation Loss: 0.0163 - Time (s): 6.4857"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV8WSBhITSEI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}