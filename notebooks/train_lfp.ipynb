{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LMP Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G84fGXVwv9Fh",
        "-yC0L1P3v9GA",
        "8SHQGBjnv9GK",
        "b7CMny5dv9Gx",
        "njbQpQAGv9G2"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/train_lfp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jUYgZwpGfav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0b811e-6f44-4a39-f8ad-9c692f2e5583"
      },
      "source": [
        "!pip install wandb -q\r\n",
        "!pip install pathy -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 24.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 13.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 122kB 9.3MB/s \n",
            "\u001b[?25h  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68MkXdDZaSZ",
        "outputId": "8e5ad0f0-01d1-412e-afb1-fff45ee7dd5d"
      },
      "source": [
        "import argparse\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser(description='LFP training arguments')\r\n",
        "parser.add_argument('run_name')\r\n",
        "parser.add_argument('--train_datasets', nargs='+', help='Training dataset names')\r\n",
        "parser.add_argument('--test_datasets', nargs='+', help='Testing dataset names')\r\n",
        "parser.add_argument('-c', '--colab', default=False, action='store_true', help='Enable if using colab environment')\r\n",
        "parser.add_argument('-s', '--data_source', default='DRIVE', help='Source of training data')\r\n",
        "parser.add_argument('-tfr', '--from_tfrecords', default=False, action='store_true', help='Enable if using tfrecords format')\r\n",
        "parser.add_argument('-d', '--device', default='TPU', help='Hardware device to train on')\r\n",
        "parser.add_argument('-b', '--batch_size', default=512, type=int)\r\n",
        "parser.add_argument('-la', '--actor_layer_size', default=2048, type=int, help='Layer size of actor, increases size of neural net')\r\n",
        "parser.add_argument('-le', '--encoder_layer_size', default=512, type=int, help='Layer size of encoder, increases size of neural net')\r\n",
        "parser.add_argument('-lp', '--planner_layer_size', default=512, type=int, help='Layer size of planner, increases size of neural net')\r\n",
        "parser.add_argument('-z', '--latent_dim', default=256, type=int, help='Size of the VAE latent space')\r\n",
        "parser.add_argument('-g', '--gcbc', default=False, action='store_true', help='Enables GCBC, a simpler model with no encoder/planner')\r\n",
        "parser.add_argument('-n', '--num_distribs', default=None, type=int, help='Number of distributions to use in logistic mixture model')\r\n",
        "parser.add_argument('-q', '--qbits', default=None, type=int, help='Number of quantisation bits to discrete distributions into. Total quantisations = 2**qbits')\r\n",
        "parser.add_argument('-lr', '--learning_rate', type=float, default=3e-4)\r\n",
        "parser.add_argument('-t', '--train_steps', type=int, default=100000)\r\n",
        "parser.add_argument('-r', '--resume', default=False, action='store_true')\r\n",
        "\r\n",
        "\r\n",
        "# args = parser.parse_args()\r\n",
        "\r\n",
        "### Sample local config\r\n",
        "args = parser.parse_args('''\r\n",
        "dummy_run \r\n",
        "--train_dataset UR5\r\n",
        "--test_dataset UR5\r\n",
        "-tfr\r\n",
        "'''.split())\r\n",
        "\r\n",
        "## Sample colab config\r\n",
        "args = parser.parse_args('''\r\n",
        "refactor_test\r\n",
        "--train_dataset UR5 UR5_slow_gripper UR5_high_transition\r\n",
        "--test_dataset UR5_slow_gripper_test\r\n",
        "-c\r\n",
        "-tfr\r\n",
        "-s GCS\r\n",
        "-d TPU\r\n",
        "-b 512\r\n",
        "-la 2048\r\n",
        "-le 512\r\n",
        "-lp 2048\r\n",
        "-z 256\r\n",
        "-lr 3e-4\r\n",
        "'''.split())\r\n",
        "\r\n",
        "## Sample colab config\r\n",
        "args = parser.parse_args('''\r\n",
        "reclass2_from_working\r\n",
        "--train_dataset UR5 UR5_slow_gripper UR5_high_transition\r\n",
        "--test_dataset UR5_slow_gripper_test\r\n",
        "-c\r\n",
        "-s DRIVE\r\n",
        "-d TPU\r\n",
        "-b 512\r\n",
        "-la 2048\r\n",
        "-le 512\r\n",
        "-lp 512\r\n",
        "-z 256\r\n",
        "-lr 3e-4\r\n",
        "'''.split())\r\n",
        "\r\n",
        "print(args)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(actor_layer_size=2048, batch_size=512, colab=True, data_source='DRIVE', device='TPU', encoder_layer_size=512, from_tfrecords=False, gcbc=False, latent_dim=256, learning_rate=0.0003, num_distribs=None, planner_layer_size=512, qbits=None, resume=False, run_name='reclass2_from_working', test_datasets=['UR5_slow_gripper_test'], train_datasets=['UR5', 'UR5_slow_gripper', 'UR5_high_transition'], train_steps=100000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EliqxOpPv9Dy"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMJ___6ARZ4u",
        "outputId": "ea8c697b-01b0-4ea9-c7aa-d35bd839f96a"
      },
      "source": [
        "#@title Workpace Setup (Local vs Colab)\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# COLAB = False #@param {type:\"boolean\"}\n",
        "AUTH_GCS = False #@param {type:\"boolean\"}\n",
        "# DEVICE = \"CPU\" #@param [\"TPU\", \"GPU\", \"CPU\"]\n",
        "DATA_SOURCE = \"Google Drive\" #@param [\"Google Drive\", \"GCS\"]\n",
        "# TRAIN_DATASETS = [\"UR5\"]#,\"UR5_slow_gripper\",\"UR5_high_transition\"]\n",
        "# TEST_DATASET = \"UR5_slow_gripper_test\" #@param [\"UR5_slow_gripper_test\"]\n",
        "GCS_USER = \"sholto\" #@param [\"sholto\", \"tristan\"]\n",
        "\n",
        "if args.colab:\n",
        "    from google.colab import drive, auth\n",
        "    print('Using colab setup')\n",
        "    !git clone 'https://github.com/sholtodouglas/learning_from_play'\n",
        "    WORKING_PATH = Path('/content/learning_from_play')\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir(WORKING_PATH)\n",
        "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
        "    print(f'Storage path: {STORAGE_PATH}')\n",
        "else:\n",
        "    print('Using local setup')\n",
        "    WORKING_PATH = Path().absolute().parent\n",
        "    print(f'Working path: {WORKING_PATH}')\n",
        "    os.chdir(WORKING_PATH)\n",
        "    STORAGE_PATH = WORKING_PATH\n",
        "    print(f'Storage path: {STORAGE_PATH}')\n",
        "\n",
        "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.train_datasets]\n",
        "TEST_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.test_datasets]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab setup\n",
            "Cloning into 'learning_from_play'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 1749 (delta 32), reused 9 (delta 4), pack-reused 1694\u001b[K\n",
            "Receiving objects: 100% (1749/1749), 57.59 MiB | 40.92 MiB/s, done.\n",
            "Resolving deltas: 100% (989/989), done.\n",
            "Mounted at /content/drive\n",
            "Storage path: /content/drive/My Drive/Robotic Learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zbmq324x2yv",
        "outputId": "77393bfa-8b10-4fd8-d03a-7daac9e13d65"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "if args.device == \"TPU\":\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
        "    print(\"REPLICAS: \", NUM_DEVICES)\n",
        "else:\n",
        "    physical_devices = tf.config.list_physical_devices()\n",
        "    if args.device == 'GPU':\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
        "    NUM_DEVICES = 1\n",
        "    print(physical_devices)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.84.19.34:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.84.19.34:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.84.19.34:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF1m_wf3v9D-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import lfp\n",
        "from natsort import natsorted"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HejtDH_Yx8h"
      },
      "source": [
        "# Use this to edit modules without needing to restart the kernel\n",
        "# !git pull\n",
        "# import importlib\n",
        "# importlib.reload(lfp.data)\n",
        "# importlib.reload(lfp.model)\n",
        "# importlib.reload(lfp.train)\n",
        "# importlib.reload(lfp.metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI6JP06FdTv"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lBWIyOFdTv"
      },
      "source": [
        "GLOBAL_BATCH_SIZE = args.batch_size * NUM_DEVICES\n",
        "dl = lfp.data.PlayDataloader(batch_size=GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiz4AXCnFdTv",
        "outputId": "6340f8de-15cd-46a0-f747-4515beb7e0bf"
      },
      "source": [
        "# Train data\n",
        "train_data = dl.extract(TRAIN_DATA_PATHS)\n",
        "train_dataset = dl.load(train_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UR5: 100%|██████████| 52/52 [00:25<00:00,  2.04it/s]\n",
            "UR5_slow_gripper: 100%|██████████| 23/23 [00:20<00:00,  1.11it/s]\n",
            "UR5_high_transition: 100%|██████████| 32/32 [00:11<00:00,  2.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(4096, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(4096, 50, 11), dtype=tf.float32, name=None),\n",
            "    'masks': TensorSpec(shape=(4096, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(4096, 50, 18), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(4096,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ZDAVpLFdTw",
        "outputId": "ef17c328-89aa-4444-b582-2b20c6d5779b"
      },
      "source": [
        "# Validation data\n",
        "valid_data = dl.extract(TEST_DATA_PATHS)\n",
        "valid_dataset = dl.load(valid_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UR5_slow_gripper_test: 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(4096, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(4096, 50, 11), dtype=tf.float32, name=None),\n",
            "    'masks': TensorSpec(shape=(4096, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(4096, 50, 18), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(4096,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpRPRuv9E6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "-3r_TDl7v9E7",
        "outputId": "46130fd9-4a3d-47f0-a0c5-5e6279029793"
      },
      "source": [
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import Progbar\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "\n",
        "import time\n",
        "import io\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uMXBjGzgZCA"
      },
      "source": [
        "from lfp.train import LFPTrainer\n",
        "\n",
        "def train_setup():\n",
        "    model_params = {'obs_dim':dl.obs_dim,\n",
        "                'goal_dim':dl.goal_dim,\n",
        "                'act_dim':dl.act_dim,\n",
        "                'layer_size':args.actor_layer_size, \n",
        "                'latent_dim':args.latent_dim}\n",
        "    \n",
        "    actor = lfp.model.create_actor(**model_params, gcbc=args.gcbc, num_distribs=args.num_distribs)\n",
        "\n",
        "    if args.gcbc:\n",
        "        encoder = None\n",
        "        planner = None\n",
        "    else:\n",
        "        model_params['layer_size'] = args.encoder_layer_size\n",
        "        encoder = lfp.model.create_encoder(**model_params)\n",
        "        model_params['layer_size'] = args.planner_layer_size\n",
        "        planner = lfp.model.create_planner(**model_params)\n",
        "\n",
        "    optimizer = tf.optimizers.Adam(learning_rate=args.learning_rate)\n",
        "    trainable_variables = actor.trainable_variables + encoder.trainable_variables + planner.trainable_variables\n",
        "    return actor, encoder, planner, optimizer, trainable_variables\n",
        "\n",
        "if args.device=='CPU' or args.device=='GPU':\n",
        "    actor, encoder, planner, optimizer, trainable_variables = train_setup()\n",
        "else:\n",
        "    with strategy.scope():\n",
        "        actor, encoder, planner, optimizer, trainable_variables = train_setup()\n",
        "        trainer= LFPTrainer(actor, encoder, planner, optimizer, strategy, args, dl)\n",
        "        \n",
        "train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
        "valid_dist_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))\n",
        "plotting_dataset = iter(valid_dataset) #for the cluster fig, easier with a non distributed dataset"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "xtSlIEoBlDyp",
        "outputId": "ee14ceff-47a8-4211-f3bd-a1d0bf478522"
      },
      "source": [
        "from lfp.train import BetaScheduler\n",
        "\n",
        "TRAIN_STEPS = 200000\n",
        "# 0.00001 so far works best for MAE - try lower - 0.00003 with a BETA accel of 10 so far works best, perfect encoder, nicely mapped planner\n",
        "# recall 0.01 worked okay for probabilistic - proba still too unstable!\n",
        "beta_sched = BetaScheduler('linear', \n",
        "                           beta=0.00003, \n",
        "                           beta_max=0.00003, \n",
        "                           max_steps=TRAIN_STEPS, \n",
        "                           cycles=90, \n",
        "                           duty_cycle=0.5\n",
        "                           )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSGD_2imWDi"
      },
      "source": [
        "progbar = Progbar(TRAIN_STEPS, verbose=1, interval=0.5)\n",
        "valid_inc = 20\n",
        "save_inc = 1000\n",
        "prev_grad_norm = np.float('inf')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "oTyriZrYowMJ",
        "outputId": "ede00ac2-7131-4e6e-bbac-e321372fbd0a"
      },
      "source": [
        "run_name = args.run_name\n",
        "model_path = f'/content/drive/My Drive/Robotic Learning/saved_models/{run_name}/'\n",
        "\n",
        "if args.resume:\n",
        "  run_id = str(np.load(model_path+'hyper_params.npz')['run_id'])\n",
        "  wandb.init(project=\"learning-from-play_v2\", id='12621l2h',  resume=\"must\")\n",
        "  load_weights(model_path, actor, encoder, planner)\n",
        "  load_optimizer_state(optimizer, model_path, strategy)\n",
        "  print('Loaded model weights and optimiser state')\n",
        "  t = wandb.run.step + valid_inc\n",
        "  prognar.add(t, []) # update the progbar to the most recent point\n",
        "else:\n",
        "  wandb.init(project=\"learning-from-play_v2\")\n",
        "  wandb.run.name = run_name\n",
        "  t = 0\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msholto\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.17<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dainty-sunset-149</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/1luxua7s\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/1luxua7s</a><br/>\n",
              "                Run data is saved locally in <code>/content/learning_from_play/wandb/run-20210206_031659-1luxua7s</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnc22FOGae1"
      },
      "source": [
        "from lfp.plotting import produce_cluster_fig, project_enc_and_plan, plot_to_image\n",
        "from lfp.metric import log"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXF0Y8aKrsng",
        "outputId": "e976dd9c-9e6b-4af9-ae2c-d89c744d3d2e"
      },
      "source": [
        "while t < TRAIN_STEPS:\n",
        "    start_time = time.time()\n",
        "    beta = beta_sched.scheduler(t)\n",
        "    x = next(train_dist_dataset)\n",
        "    total_train_loss = trainer.distributed_train_step(x, beta, prev_grad_norm)\n",
        "    \n",
        "    if t % valid_inc == 0:  \n",
        "        valid_x = next(valid_dist_dataset)\n",
        "        if args.gcbc:\n",
        "          total_val_loss = trainer.distributed_test_step(valid_x, beta)\n",
        "        else:\n",
        "          total_val_loss, ze, zp = trainer.distributed_test_step(valid_x, beta)\n",
        "\n",
        "        # validation plotting\n",
        "        metrics = {metric_name: log(metric) for metric_name, metric in trainer.metrics.items()}\n",
        "\n",
        "        # validation plotting\n",
        "        progbar.add(valid_inc, [('Train Loss', metrics['train_loss']), \n",
        "                                ('Validation Loss', metrics['valid_loss']), \n",
        "                                ('Time (s)', round(time.time() - start_time, 1))])\n",
        "\n",
        "        wandb.log(metrics, step=t)\n",
        "\n",
        "        prev_grad_norm = metrics['global_grad_norm']\n",
        "          \n",
        "    if t % save_inc == 0:\n",
        "        trainer.save_weights(model_path, wandb.run.id)\n",
        "        if not args.gcbc:\n",
        "          z_enc, z_plan = produce_cluster_fig(next(plotting_dataset), encoder, planner, TEST_DATA_PATHS[0], num_take=dl.batch_size//4)\n",
        "          wandb.log({'z_enc':z_enc, 'z_plan':z_plan}, step=t)\n",
        "          #latent_fig = project_enc_and_plan(ze, zp)\n",
        "          #latent_img = plot_to_image(latent_fig)\n",
        "\n",
        "    t += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    40/200000 [..............................] - ETA: 2514:13:37 - Train Loss: 0.0417 - Validation Loss: 0.0308 - Time (s): 199.7000Saving training config...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  c = np.array(c)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  c = np.array(c)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r    60/200000 [..............................] - ETA: 1755:26:26 - Train Loss: 0.0350 - Validation Loss: 0.0265 - Time (s): 134.2000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  1040/200000 [..............................] - ETA: 201:28:10 - Train Loss: 0.0063 - Validation Loss: 0.0108 - Time (s): 10.7115Saving training config...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  1060/200000 [..............................] - ETA: 200:04:28 - Train Loss: 0.0062 - Validation Loss: 0.0108 - Time (s): 10.5679"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}