{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LMP Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G84fGXVwv9Fh",
        "-yC0L1P3v9GA",
        "8SHQGBjnv9GK",
        "b7CMny5dv9Gx",
        "njbQpQAGv9G2"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/train_lfp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUYgZwpGfav",
        "outputId": "4b39c3f3-756a-4bbc-daa4-fb89114cb1d2"
      },
      "source": [
        "!pip install wandb -q\n",
        "!pip install pathy -q\n",
        "!pip install comet_ml -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 6.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 22.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 22.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 122kB 9.3MB/s \n",
            "\u001b[?25h  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 256kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 522kB 17.2MB/s \n",
            "\u001b[?25h  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFJvewo0ee6r",
        "outputId": "9461736f-bb0d-4d5f-f391-bebcd1a0e4cd"
      },
      "source": [
        "# import comet_ml at the top of your file\n",
        "from comet_ml import Experiment\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68MkXdDZaSZ",
        "outputId": "d81730eb-3477-425e-b400-acaa8a773681"
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='LFP training arguments')\n",
        "parser.add_argument('run_name')\n",
        "parser.add_argument('--train_datasets', nargs='+', help='Training dataset names')\n",
        "parser.add_argument('--test_datasets', nargs='+', help='Testing dataset names')\n",
        "parser.add_argument('-c', '--colab', default=False, action='store_true', help='Enable if using colab environment')\n",
        "parser.add_argument('-s', '--data_source', default='DRIVE', help='Source of training data')\n",
        "parser.add_argument('-tfr', '--from_tfrecords', default=False, action='store_true', help='Enable if using tfrecords format')\n",
        "parser.add_argument('-d', '--device', default='TPU', help='Hardware device to train on')\n",
        "parser.add_argument('-b', '--batch_size', default=512, type=int)\n",
        "parser.add_argument('-wmax', '--window_size_max', default=50, type=int)\n",
        "parser.add_argument('-wmin', '--window_size_min', default=20, type=int)\n",
        "parser.add_argument('-la', '--actor_layer_size', default=2048, type=int, help='Layer size of actor, increases size of neural net')\n",
        "parser.add_argument('-le', '--encoder_layer_size', default=512, type=int, help='Layer size of encoder, increases size of neural net')\n",
        "parser.add_argument('-lp', '--planner_layer_size', default=512, type=int, help='Layer size of planner, increases size of neural net')\n",
        "parser.add_argument('-embd', '--img_embedding_size', default=64, type=int, help='Embedding size of features,goal space')\n",
        "parser.add_argument('-z', '--latent_dim', default=256, type=int, help='Size of the VAE latent space')\n",
        "parser.add_argument('-g', '--gcbc', default=False, action='store_true', help='Enables GCBC, a simpler model with no encoder/planner')\n",
        "parser.add_argument('-n', '--num_distribs', default=None, type=int, help='Number of distributions to use in logistic mixture model')\n",
        "parser.add_argument('-q', '--qbits', default=None, type=int, help='Number of quantisation bits to discrete distributions into. Total quantisations = 2**qbits')\n",
        "parser.add_argument('-lr', '--learning_rate', type=float, default=3e-4)\n",
        "parser.add_argument('-t', '--train_steps', type=int, default=200000)\n",
        "parser.add_argument('-r', '--resume', default=False, action='store_true')\n",
        "parser.add_argument('-B', '--beta', type=float, default=0.00003)\n",
        "parser.add_argument('-i', '--images', default=False, action='store_true')\n",
        "parser.add_argument('--fp16', default=False, action='store_true')\n",
        "parser.add_argument('--bucket_name', help='GCS bucket name to stream data from')\n",
        "parser.add_argument('--tpu_name', help='GCP TPU name') # Only used in the script on GCP\n",
        "\n",
        "\n",
        "# ## Sample colab config\n",
        "# args = parser.parse_args('''\n",
        "# refactor_test\n",
        "# --train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "# --test_dataset UR5_slow_gripper_test\n",
        "# -c\n",
        "# -tfr\n",
        "# -s GCS\n",
        "# -d TPU\n",
        "# -b 512\n",
        "# -la 2048\n",
        "# -le 512\n",
        "# -lp 512\n",
        "# -z 256\n",
        "# -lr 3e-4\n",
        "# --bucket_name iowa_bucket_lfp\n",
        "# -i\n",
        "# '''.split())\n",
        "\n",
        "## Sample colab config\n",
        "args = parser.parse_args('''\n",
        "PB0_02\n",
        "--train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "--test_dataset UR5_slow_gripper_test\n",
        "-c\n",
        "-s GCS\n",
        "-d TPU\n",
        "-b 16\n",
        "-la 2048\n",
        "-le 512\n",
        "-lp 2048\n",
        "-z 256\n",
        "-lr 3e-4\n",
        "-B 0.02\n",
        "-i \n",
        "-tfr\n",
        "-n 5\n",
        "--bucket_name iowa_bucket_lfp\n",
        "'''.split())\n",
        "\n",
        "# -n 5\n",
        "# -q 8\n",
        "\n",
        "print(args)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(actor_layer_size=2048, batch_size=16, beta=0.02, bucket_name='iowa_bucket_lfp', colab=True, data_source='GCS', device='TPU', encoder_layer_size=512, fp16=False, from_tfrecords=True, gcbc=False, images=True, img_embedding_size=64, latent_dim=256, learning_rate=0.0003, num_distribs=5, planner_layer_size=2048, qbits=None, resume=False, run_name='PB0_02', test_datasets=['UR5_slow_gripper_test'], tpu_name=None, train_datasets=['UR5', 'UR5_slow_gripper', 'UR5_high_transition'], train_steps=200000, window_size_max=50, window_size_min=20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EliqxOpPv9Dy"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMJ___6ARZ4u",
        "outputId": "f6f34778-5bd9-451f-fe97-dafa73f65d5b"
      },
      "source": [
        "from pathlib import Path\n",
        "from pathy import Pathy\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "import pprint\n",
        "import logging\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "#@title Workpace Setup (Local vs Colab)\n",
        "\n",
        "# Set up working directory and libraries\n",
        "if args.colab:\n",
        "    from google.colab import drive, auth\n",
        "    print('Using colab setup')\n",
        "    WORKING_PATH = Path('/content/learning_from_play')\n",
        "    # Clone repo\n",
        "    try:\n",
        "        get_ipython().system(\"git clone 'https://github.com/sholtodouglas/learning_from_play' {WORKING_PATH}\")\n",
        "    except: \n",
        "        pass\n",
        "    # Mount drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print('Using local setup')\n",
        "    WORKING_PATH = Path.cwd()\n",
        "    print(f'Working path: {WORKING_PATH}')\n",
        "\n",
        "# Change working directory to learning_from_play\n",
        "os.chdir(WORKING_PATH)\n",
        "import lfp\n",
        "\n",
        "# Set up storage directory and datasets\n",
        "if args.data_source == 'DRIVE':\n",
        "    assert args.colab, \"Must be using Colab\"\n",
        "    print('Reading data from Google Drive')\n",
        "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
        "elif args.data_source == 'GCS':\n",
        "    if args.colab:\n",
        "      auth.authenticate_user()\n",
        "    print('Reading data from Google Cloud Storage')\n",
        "    r = requests.get('https://ipinfo.io')\n",
        "    region = r.json()['region']\n",
        "    project_id = 'learning-from-play-303306'\n",
        "    logging.warning(f'You are accessing GCS data from {region}, make sure this is the same as your bucket {args.bucket_name}')\n",
        "    STORAGE_PATH = Pathy(f'gs://{args.bucket_name}')\n",
        "else:\n",
        "    print('Reading data from local filesystem')\n",
        "    STORAGE_PATH = WORKING_PATH\n",
        "\n",
        "print(f'Storage path: {STORAGE_PATH}')\n",
        "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.train_datasets]\n",
        "TEST_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.test_datasets]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab setup\n",
            "fatal: destination path '/content/learning_from_play' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:You are accessing GCS data from Iowa, make sure this is the same as your bucket iowa_bucket_lfp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No pybullet installation found - which is fine if training\n",
            "Reading data from Google Cloud Storage\n",
            "Storage path: gs://iowa_bucket_lfp/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zbmq324x2yv",
        "outputId": "20b971b7-7788-46d8-9eb3-3ba75e9eeb4e"
      },
      "source": [
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "if args.device == 'TPU':\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args.tpu_name)  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
        "    print(\"REPLICAS: \", NUM_DEVICES)\n",
        "    if args.fp16:\n",
        "        tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
        "else:\n",
        "    physical_devices = tf.config.list_physical_devices()\n",
        "    if args.device == 'GPU':\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
        "        if args.fp16:\n",
        "            tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    NUM_DEVICES = 1\n",
        "    print(physical_devices)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.55.189.82:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.55.189.82:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.55.189.82:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HejtDH_Yx8h",
        "outputId": "054d3845-af4d-4bf6-ae48-a6088037f50c"
      },
      "source": [
        "# Use this to edit modules without needing to restart the kernel (can also edit local, push/pull)\n",
        "!git pull\n",
        "import importlib\n",
        "importlib.reload(lfp.data)\n",
        "importlib.reload(lfp.model)\n",
        "importlib.reload(lfp.train)\n",
        "importlib.reload(lfp.metric)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'lfp.metric' from '/content/learning_from_play/lfp/metric.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI6JP06FdTv"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lBWIyOFdTv"
      },
      "source": [
        "GLOBAL_BATCH_SIZE = args.batch_size * NUM_DEVICES\n",
        "dl = lfp.data.PlayDataloader(include_imgs = args.images, batch_size=GLOBAL_BATCH_SIZE,  window_size=args.window_size_max, min_window_size=args.window_size_min)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiz4AXCnFdTv",
        "outputId": "99dc81a3-cb65-45b6-85df-ad78bcb40db8"
      },
      "source": [
        "# Train data\n",
        "train_data = dl.extract(TRAIN_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "train_dataset = dl.load(train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(128, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(128, None), dtype=tf.int32, name=None),\n",
            "    'goal_imgs': TensorSpec(shape=(128, 50, 200, 200, 3), dtype=tf.uint8, name=None),\n",
            "    'goals': TensorSpec(shape=(128, 50, 11), dtype=tf.float32, name=None),\n",
            "    'imgs': TensorSpec(shape=(128, 50, 200, 200, 3), dtype=tf.uint8, name=None),\n",
            "    'masks': TensorSpec(shape=(128, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(128, 50, 18), dtype=tf.float32, name=None),\n",
            "    'proprioceptive_features': TensorSpec(shape=(128, 50, 7), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(128,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(128, None), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8ZDAVpLFdTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c3d23c-d868-4687-a099-0833b999a5fb"
      },
      "source": [
        "# Validation data\n",
        "valid_data = dl.extract(TEST_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "valid_dataset = dl.load(valid_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(128, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(128, None), dtype=tf.int32, name=None),\n",
            "    'goal_imgs': TensorSpec(shape=(128, 50, 200, 200, 3), dtype=tf.uint8, name=None),\n",
            "    'goals': TensorSpec(shape=(128, 50, 11), dtype=tf.float32, name=None),\n",
            "    'imgs': TensorSpec(shape=(128, 50, 200, 200, 3), dtype=tf.uint8, name=None),\n",
            "    'masks': TensorSpec(shape=(128, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(128, 50, 18), dtype=tf.float32, name=None),\n",
            "    'proprioceptive_features': TensorSpec(shape=(128, 50, 7), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(128,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(128, None), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpRPRuv9E6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uMXBjGzgZCA"
      },
      "source": [
        "from lfp.train import LFPTrainer\n",
        "\n",
        "def train_setup():\n",
        "    model_params = {'obs_dim':args.img_embedding_size + dl.proprioceptive_features_dim if args.images else dl.obs_dim,\n",
        "                'goal_dim':args.img_embedding_size if args.images else dl.goal_dim,\n",
        "                'act_dim':dl.act_dim,\n",
        "                'layer_size':args.actor_layer_size, \n",
        "                'latent_dim':args.latent_dim}\n",
        "\n",
        "    actor = lfp.model.create_actor(**model_params, gcbc=args.gcbc, num_distribs=args.num_distribs, qbits=args.qbits)\n",
        "\n",
        "    if args.gcbc:\n",
        "        encoder = None\n",
        "        planner = None\n",
        "    else:\n",
        "        model_params['layer_size'] = args.encoder_layer_size\n",
        "        encoder = lfp.model.create_encoder(**model_params)\n",
        "        model_params['layer_size'] = args.planner_layer_size\n",
        "        planner = lfp.model.create_planner(**model_params)\n",
        "\n",
        "    if args.images:\n",
        "      cnn = lfp.model.create_vision_network(dl.img_size, dl.img_size, embedding_size=args.img_embedding_size)\n",
        "    else:\n",
        "      cnn = None\n",
        "\n",
        "    #optimizer = tfa.optimizers.LAMB(learning_rate=args.learning_rate)\n",
        "    optimizer = optimizer = tf.optimizers.Adam\n",
        "    trainer = LFPTrainer(args, actor, dl, encoder, planner, cnn, optimizer, strategy, GLOBAL_BATCH_SIZE)\n",
        "    return actor, encoder, planner, trainer\n",
        "\n",
        "\n",
        "if args.device=='CPU' or args.device=='GPU':\n",
        "     actor, encoder, planner, trainer = train_setup()\n",
        "else:\n",
        "    with strategy.scope():\n",
        "         actor, encoder, planner, trainer = train_setup()\n",
        "        \n",
        "        \n",
        "train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
        "valid_dist_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))\n",
        "plotting_dataset = iter(valid_dataset) #for the cluster fig, easier with a non distributed dataset\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtSlIEoBlDyp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ff7fcf2d-f827-4128-e624-c93145c93fe7"
      },
      "source": [
        "from lfp.train import BetaScheduler\n",
        "\n",
        "\n",
        "# 0.00001 so far works best for MAE - try lower - 0.00003 with a BETA accel of 10 so far works best, perfect encoder, nicely mapped planner\n",
        "# recall 0.01 worked okay for probabilistic - proba still too unstable!\n",
        "beta_sched = BetaScheduler('linear', \n",
        "                           beta=args.beta, \n",
        "                           beta_max=args.beta, \n",
        "                           max_steps=args.train_steps, \n",
        "                           cycles=90, \n",
        "                           duty_cycle=0.5\n",
        "                           )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSGD_2imWDi"
      },
      "source": [
        "\n",
        "from tensorflow.keras.utils import Progbar\n",
        "progbar = Progbar(args.train_steps, verbose=1, interval=0.5)\n",
        "valid_inc = 20\n",
        "save_inc = 2000\n",
        "prev_grad_norm = np.float('inf')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTyriZrYowMJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "764ad610-7d66-4f68-a95e-b419ccd083f0"
      },
      "source": [
        "run_name = args.run_name\n",
        "model_path = str(STORAGE_PATH/'saved_models'/args.run_name)\n",
        "\n",
        "if args.resume:\n",
        "  # WandB reinit\n",
        "  with open(f'{model_path}/config.json', 'r') as f:\n",
        "      data = json.load(f)\n",
        "  # Comet ML reinit\n",
        "  exp = ExistingExperiment(api_key=\"C4vcCM57bnSYEsdncguxDW8pO\",  previous_experiment=data['experiment_key'])\n",
        "\n",
        "  wandb.init(project=\"learning-from-play_v2\", id=data['run_id'],  resume=\"must\")\n",
        "  t = wandb.run.step + valid_inc # Todo get this from comet to complete the transition\n",
        "\n",
        "  load_weights(model_path, actor, encoder, planner, with_optimizer=True)\n",
        "  print('Loaded model weights and optimiser state')\n",
        "  \n",
        "  prognar.add(t, []) # update the progbar to the most recent point\n",
        "else:\n",
        "  #Comet\n",
        "  experiment = Experiment(api_key=\"C4vcCM57bnSYEsdncguxDW8pO\",project_name=\"learning-from-play\",workspace=\"sholtodouglas\")\n",
        "  experiment.set_name(run_name)\n",
        "  # WandB\n",
        "  wandb.init(project=\"learning-from-play_v2\")\n",
        "  wandb.run.name = run_name\n",
        "  t = 0\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/sholtodouglas/learning-from-play/d7a63e86757646d8933056f8ecb3cab5\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.21<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dark-microwave-233</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/2m0g2qgu\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/2m0g2qgu</a><br/>\n",
              "                Run data is saved locally in <code>/content/learning_from_play/wandb/run-20210309_233709-2m0g2qgu</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnc22FOGae1"
      },
      "source": [
        "from lfp.plotting import produce_cluster_fig, project_enc_and_plan, plot_to_image\n",
        "from lfp.metric import log # gets state and clears simultaneously"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjEkQ-OeXOVX"
      },
      "source": [
        "import time"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3sybgPOU5Vv",
        "outputId": "38f4595b-cf51-49b6-f619-e4c15d590319"
      },
      "source": [
        "t = time.time()\r\n",
        "for i in range(0,10):\r\n",
        "  train_batch = next(train_dist_dataset)\r\n",
        "  trainer.distributed_train_step(train_batch, args.beta)\r\n",
        "print(time.time() - t)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.735045909881592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGGc3Uh-XI2-"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXF0Y8aKrsng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "546cd282-5919-4e81-dd4c-e6ac36cbd4ff"
      },
      "source": [
        "\n",
        "\n",
        "# Creating these autograph wrappers so that tf.data operations are executed in graph mode\n",
        "@tf.function\n",
        "def train(train_dataset, beta):\n",
        "    train_batch = next(train_dataset)\n",
        "    trainer.distributed_train_step(train_batch, beta)\n",
        "\n",
        "@tf.function\n",
        "def test(valid_dataset, beta):\n",
        "    valid_batch = next(valid_dataset)\n",
        "    trainer.distributed_test_step(valid_batch, beta)\n",
        "\n",
        "while t < args.train_steps:\n",
        "    start_time = time.time()\n",
        "    beta = beta_sched.scheduler(t)\n",
        "    train(train_dist_dataset, beta)\n",
        "\n",
        "    if t % valid_inc == 0:\n",
        "        test(valid_dist_dataset, beta)\n",
        "        step_time = round(time.time() - start_time, 1)\n",
        "\n",
        "        metrics = {metric_name: log(metric) for metric_name, metric in trainer.metrics.items()}\n",
        "        metrics['step_time'] = step_time\n",
        "\n",
        "        # validation plotting\n",
        "        progbar.add(valid_inc, [('Train Loss', metrics['train_loss']),\n",
        "                                ('Validation Loss', metrics['valid_loss']),\n",
        "                                ('Time (s)', step_time)])\n",
        "        #Plot on Comet\n",
        "        experiment.log_metrics(metrics,step=t)\n",
        "        # Plot on WandB\n",
        "        wandb.log(metrics, step=t)\n",
        "\n",
        "    if (t+1) % save_inc == 0:\n",
        "        trainer.save_weights(model_path, run_id=wandb.run.id, experiment_key=experiment.get_key())\n",
        "        if not args.gcbc and not args.images:\n",
        "          z_enc, z_plan = produce_cluster_fig(next(plotting_dataset), encoder, planner, TEST_DATA_PATHS[0], num_take=dl.batch_size//4)\n",
        "\n",
        "          #Comet\n",
        "          experiment.log_figure('z_enc', z_enc, step=t)\n",
        "          experiment.log_figure('z_plan', z_plan,step=t)\n",
        "\n",
        "          # WandB\n",
        "          wandb.log({'z_enc':z_enc, 'z_plan':z_plan}, step=t)\n",
        "\n",
        "          #latent_fig = project_enc_and_plan(ze, zp)\n",
        "          #latent_img = plot_to_image(latent_fig)\n",
        "\n",
        "    t += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    60/200000 [..............................] - ETA: 409:30:55 - Train Loss: 0.0339 - Validation Loss: 0.0255 - Time (s): 75.9667 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-86281f5d3dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_sched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dist_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalid_inc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw21h14BnX3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}