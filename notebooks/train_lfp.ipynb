{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LMP Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G84fGXVwv9Fh",
        "-yC0L1P3v9GA",
        "8SHQGBjnv9GK",
        "b7CMny5dv9Gx",
        "njbQpQAGv9G2"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/train_lfp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUYgZwpGfav",
        "outputId": "2a378b7c-7f3d-4be0-a3e2-073e0b6069e8"
      },
      "source": [
        "!pip install wandb -q\n",
        "!pip install pathy -q\n",
        "!pip install comet_ml -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 44.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 44.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 122kB 8.8MB/s \n",
            "\u001b[?25h  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 256kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 522kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 5.3MB/s \n",
            "\u001b[?25h  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "OFJvewo0ee6r",
        "outputId": "617882eb-b5ed-4f31-f7ab-7e81d8c4d9ac"
      },
      "source": [
        "# import comet_ml at the top of your file\n",
        "from comet_ml import Experiment\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68MkXdDZaSZ",
        "outputId": "c74632eb-f963-4254-fbc0-62edf5fd925d"
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='LFP training arguments')\n",
        "parser.add_argument('run_name')\n",
        "parser.add_argument('--train_datasets', nargs='+', help='Training dataset names')\n",
        "parser.add_argument('--test_datasets', nargs='+', help='Testing dataset names')\n",
        "parser.add_argument('-c', '--colab', default=False, action='store_true', help='Enable if using colab environment')\n",
        "parser.add_argument('-s', '--data_source', default='DRIVE', help='Source of training data')\n",
        "parser.add_argument('-tfr', '--from_tfrecords', default=False, action='store_true', help='Enable if using tfrecords format')\n",
        "parser.add_argument('-d', '--device', default='TPU', help='Hardware device to train on')\n",
        "parser.add_argument('-b', '--batch_size', default=512, type=int)\n",
        "parser.add_argument('-wmax', '--window_size_max', default=40, type=int)\n",
        "parser.add_argument('-wmin', '--window_size_min', default=20, type=int)\n",
        "parser.add_argument('-la', '--actor_layer_size', default=2048, type=int, help='Layer size of actor, increases size of neural net')\n",
        "parser.add_argument('-le', '--encoder_layer_size', default=512, type=int, help='Layer size of encoder, increases size of neural net')\n",
        "parser.add_argument('-lp', '--planner_layer_size', default=2048, type=int, help='Layer size of planner, increases size of neural net')\n",
        "parser.add_argument('-embd', '--img_embedding_size', default=64, type=int, help='Embedding size of features,goal space')\n",
        "parser.add_argument('-z', '--latent_dim', default=256, type=int, help='Size of the VAE latent space')\n",
        "parser.add_argument('-g', '--gcbc', default=False, action='store_true', help='Enables GCBC, a simpler model with no encoder/planner')\n",
        "parser.add_argument('-n', '--num_distribs', default=None, type=int, help='Number of distributions to use in logistic mixture model')\n",
        "parser.add_argument('-q', '--qbits', default=None, type=int, help='Number of quantisation bits to discrete distributions into. Total quantisations = 2**qbits')\n",
        "parser.add_argument('-lr', '--learning_rate', type=float, default=3e-4)\n",
        "parser.add_argument('-t', '--train_steps', type=int, default=200000)\n",
        "parser.add_argument('-r', '--resume', default=False, action='store_true')\n",
        "parser.add_argument('-B', '--beta', type=float, default=0.00003)\n",
        "parser.add_argument('-i', '--images', default=False, action='store_true')\n",
        "parser.add_argument('--fp16', default=False, action='store_true')\n",
        "parser.add_argument('--bucket_name', help='GCS bucket name to stream data from')\n",
        "parser.add_argument('--tpu_name', help='GCP TPU name') # Only used in the script on GCP\n",
        "\n",
        "\n",
        "# ## Sample colab config\n",
        "# args = parser.parse_args('''\n",
        "# refactor_test\n",
        "# --train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "# --test_dataset UR5_slow_gripper_test\n",
        "# -c\n",
        "# -tfr\n",
        "# -s GCS\n",
        "# -d TPU\n",
        "# -b 512\n",
        "# -la 2048\n",
        "# -le 512\n",
        "# -lp 512\n",
        "# -z 256\n",
        "# -lr 3e-4\n",
        "# --bucket_name iowa_bucket_lfp\n",
        "# -i\n",
        "# '''.split())\n",
        "\n",
        "## Sample colab config\n",
        "args = parser.parse_args('''\n",
        "PB0_02\n",
        "--train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "--test_dataset UR5_slow_gripper_test\n",
        "-c\n",
        "-s GCS\n",
        "-d TPU\n",
        "-b 16\n",
        "-la 2048\n",
        "-le 512\n",
        "-lp 2048\n",
        "-wmax 40\n",
        "-wmin 20\n",
        "-z 256\n",
        "-lr 3e-4\n",
        "-B 0.02\n",
        "-i \n",
        "-tfr\n",
        "-n 5\n",
        "--bucket_name iowa_bucket_lfp\n",
        "'''.split())\n",
        "\n",
        "# -n 5\n",
        "# -q 8\n",
        "\n",
        "print(args)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(actor_layer_size=2048, batch_size=16, beta=0.02, bucket_name='iowa_bucket_lfp', colab=True, data_source='GCS', device='TPU', encoder_layer_size=512, fp16=False, from_tfrecords=True, gcbc=False, images=True, img_embedding_size=64, latent_dim=256, learning_rate=0.0003, num_distribs=5, planner_layer_size=2048, qbits=None, resume=False, run_name='PB0_02', test_datasets=['UR5_slow_gripper_test'], tpu_name=None, train_datasets=['UR5', 'UR5_slow_gripper', 'UR5_high_transition'], train_steps=200000, window_size_max=40, window_size_min=20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EliqxOpPv9Dy"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMJ___6ARZ4u",
        "outputId": "70af5391-4fee-4806-ce81-63e18752a6d1"
      },
      "source": [
        "from pathlib import Path\n",
        "from pathy import Pathy\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "import pprint\n",
        "import logging\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "#@title Workpace Setup (Local vs Colab)\n",
        "\n",
        "# Set up working directory and libraries\n",
        "if args.colab:\n",
        "    from google.colab import drive, auth\n",
        "    print('Using colab setup')\n",
        "    WORKING_PATH = Path('/content/learning_from_play')\n",
        "    # Clone repo\n",
        "    try:\n",
        "        get_ipython().system(\"git clone 'https://github.com/sholtodouglas/learning_from_play' {WORKING_PATH}\")\n",
        "    except: \n",
        "        pass\n",
        "    # Mount drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print('Using local setup')\n",
        "    WORKING_PATH = Path.cwd()\n",
        "    print(f'Working path: {WORKING_PATH}')\n",
        "\n",
        "# Change working directory to learning_from_play\n",
        "os.chdir(WORKING_PATH)\n",
        "import lfp\n",
        "\n",
        "# Set up storage directory and datasets\n",
        "if args.data_source == 'DRIVE':\n",
        "    assert args.colab, \"Must be using Colab\"\n",
        "    print('Reading data from Google Drive')\n",
        "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
        "elif args.data_source == 'GCS':\n",
        "    if args.colab:\n",
        "      auth.authenticate_user()\n",
        "    print('Reading data from Google Cloud Storage')\n",
        "    r = requests.get('https://ipinfo.io')\n",
        "    region = r.json()['region']\n",
        "    project_id = 'learning-from-play-303306'\n",
        "    logging.warning(f'You are accessing GCS data from {region}, make sure this is the same as your bucket {args.bucket_name}')\n",
        "    STORAGE_PATH = Pathy(f'gs://{args.bucket_name}')\n",
        "else:\n",
        "    print('Reading data from local filesystem')\n",
        "    STORAGE_PATH = WORKING_PATH\n",
        "\n",
        "print(f'Storage path: {STORAGE_PATH}')\n",
        "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.train_datasets]\n",
        "TEST_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.test_datasets]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab setup\n",
            "fatal: destination path '/content/learning_from_play' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading data from Google Cloud Storage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:You are accessing GCS data from Iowa, make sure this is the same as your bucket iowa_bucket_lfp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Storage path: gs://iowa_bucket_lfp/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zbmq324x2yv",
        "outputId": "fd75ac15-5f92-491e-f3ba-2640da031713"
      },
      "source": [
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "if args.device == 'TPU':\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args.tpu_name)  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
        "    print(\"REPLICAS: \", NUM_DEVICES)\n",
        "    if args.fp16:\n",
        "        tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
        "else:\n",
        "    physical_devices = tf.config.list_physical_devices()\n",
        "    if args.device == 'GPU':\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
        "        if args.fp16:\n",
        "            tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    NUM_DEVICES = 1\n",
        "    print(physical_devices)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.44.16.250:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.44.16.250:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.44.16.250:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.44.16.250:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.44.16.250:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HejtDH_Yx8h",
        "outputId": "780983e8-80fe-4246-ff23-53cc579d730e"
      },
      "source": [
        "# Use this to edit modules without needing to restart the kernel (can also edit local, push/pull)\n",
        "!git pull\n",
        "import importlib\n",
        "importlib.reload(lfp.data)\n",
        "importlib.reload(lfp.model)\n",
        "importlib.reload(lfp.train)\n",
        "importlib.reload(lfp.metric)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'lfp.metric' from '/content/learning_from_play/lfp/metric.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI6JP06FdTv"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lBWIyOFdTv"
      },
      "source": [
        "GLOBAL_BATCH_SIZE = args.batch_size * NUM_DEVICES\n",
        "dl = lfp.data.PlayDataloader(include_imgs = args.images, batch_size=GLOBAL_BATCH_SIZE,  window_size=args.window_size_max, min_window_size=args.window_size_min)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiz4AXCnFdTv",
        "outputId": "e83dfd64-52b9-4f35-ba28-9928a56cf00c"
      },
      "source": [
        "# Train data\n",
        "train_data = dl.extract(TRAIN_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "train_dataset = dl.load(train_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(128, None, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(128, None), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(128, None, 11), dtype=tf.float32, name=None),\n",
            "    'imgs': TensorSpec(shape=(128, None, 200, 200, 3), dtype=tf.uint8, name=None),\n",
            "    'obs': TensorSpec(shape=(128, None, 18), dtype=tf.float32, name=None),\n",
            "    'proprioceptive_features': TensorSpec(shape=(128, None, 7), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(128, None), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8ZDAVpLFdTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf607ce-5cbf-4355-cca9-50bdb3c7e689"
      },
      "source": [
        "# Validation data\n",
        "valid_data = dl.extract(TEST_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "valid_dataset = dl.load(valid_data)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(128, None, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(128, None), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(128, None, 11), dtype=tf.float32, name=None),\n",
            "    'imgs': TensorSpec(shape=(128, None, 200, 200, 3), dtype=tf.uint8, name=None),\n",
            "    'obs': TensorSpec(shape=(128, None, 18), dtype=tf.float32, name=None),\n",
            "    'proprioceptive_features': TensorSpec(shape=(128, None, 7), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(128, None), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpRPRuv9E6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uMXBjGzgZCA"
      },
      "source": [
        "from lfp.train import LFPTrainer\n",
        "\n",
        "def train_setup():\n",
        "    model_params = {'obs_dim':args.img_embedding_size + dl.proprioceptive_features_dim if args.images else dl.obs_dim,\n",
        "                'goal_dim':args.img_embedding_size if args.images else dl.goal_dim,\n",
        "                'act_dim':dl.act_dim,\n",
        "                'layer_size':args.actor_layer_size, \n",
        "                'latent_dim':args.latent_dim}\n",
        "\n",
        "    actor = lfp.model.create_actor(**model_params, gcbc=args.gcbc, num_distribs=args.num_distribs, qbits=args.qbits)\n",
        "\n",
        "    if args.gcbc:\n",
        "        encoder = None\n",
        "        planner = None\n",
        "    else:\n",
        "        model_params['layer_size'] = args.encoder_layer_size\n",
        "        encoder = lfp.model.create_encoder(**model_params)\n",
        "        model_params['layer_size'] = args.planner_layer_size\n",
        "        planner = lfp.model.create_planner(**model_params)\n",
        "\n",
        "    if args.images:\n",
        "      cnn = lfp.model.cnn(dl.img_size, dl.img_size, embedding_size=args.img_embedding_size)\n",
        "      lfp.utils.build_cnn(cnn)  # Have to do this becasue it is subclassed and the reshapes in the spatial softmax don't play nice with model auto build\n",
        "    else:\n",
        "      cnn = None\n",
        "\n",
        "    #optimizer = tfa.optimizers.LAMB(learning_rate=args.learning_rate)\n",
        "    optimizer = optimizer = tf.optimizers.Adam\n",
        "    trainer = LFPTrainer(args, actor, dl, encoder, planner, cnn, optimizer, strategy, GLOBAL_BATCH_SIZE)\n",
        "    return actor, encoder, planner, cnn, trainer\n",
        "\n",
        "\n",
        "if args.device=='CPU' or args.device=='GPU':\n",
        "     actor, encoder, planner, cnn, trainer = train_setup()\n",
        "else:\n",
        "    with strategy.scope():\n",
        "         actor, encoder, planner, cnn, trainer = train_setup()\n",
        "        \n",
        "        \n",
        "train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
        "valid_dist_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))\n",
        "plotting_dataset = iter(valid_dataset) #for the cluster fig, easier with a non distributed dataset\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSGD_2imWDi"
      },
      "source": [
        "\n",
        "from tensorflow.keras.utils import Progbar\n",
        "progbar = Progbar(args.train_steps, verbose=1, interval=0.5)\n",
        "valid_inc = 20\n",
        "save_inc = 2000\n",
        "prev_grad_norm = np.float('inf')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTyriZrYowMJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7f252b7b-f4c4-4ade-d161-48f788abe05a"
      },
      "source": [
        "run_name = args.run_name\n",
        "model_path = str(STORAGE_PATH/'saved_models'/args.run_name)\n",
        "\n",
        "if args.resume:\n",
        "  # WandB reinit\n",
        "  with open(f'{model_path}/config.json', 'r') as f:\n",
        "      data = json.load(f)\n",
        "  # Comet ML reinit\n",
        "  exp = ExistingExperiment(api_key=\"C4vcCM57bnSYEsdncguxDW8pO\",  previous_experiment=data['experiment_key'])\n",
        "\n",
        "  wandb.init(project=\"learning-from-play_v2\", id=data['run_id'],  resume=\"must\")\n",
        "  t = wandb.run.step + valid_inc # Todo get this from comet to complete the transition\n",
        "\n",
        "  load_weights(model_path, actor, encoder, planner, with_optimizer=True)\n",
        "  print('Loaded model weights and optimiser state')\n",
        "  \n",
        "  prognar.add(t, []) # update the progbar to the most recent point\n",
        "else:\n",
        "  #Comet\n",
        "  experiment = Experiment(api_key=\"C4vcCM57bnSYEsdncguxDW8pO\",project_name=\"learning-from-play\",workspace=\"sholtodouglas\")\n",
        "  experiment.set_name(run_name)\n",
        "  # WandB\n",
        "  wandb.init(project=\"learning-from-play_v2\")\n",
        "  wandb.run.name = run_name\n",
        "  t = 0\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/sholtodouglas/learning-from-play/092ef386bcd54432b1620d4f755c30ee\n",
            "\n",
            "wandb: Currently logged in as: sholto (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lucky-surf-246</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/369z7b8o\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/369z7b8o</a><br/>\n",
              "                Run data is saved locally in <code>/content/learning_from_play/wandb/run-20210315_222956-369z7b8o</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnc22FOGae1"
      },
      "source": [
        "from lfp.plotting import produce_cluster_fig, project_enc_and_plan, plot_to_image\n",
        "from lfp.metric import log # gets state and clears simultaneously"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjEkQ-OeXOVX"
      },
      "source": [
        "import time\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3sybgPOU5Vv"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXF0Y8aKrsng"
      },
      "source": [
        "\n",
        "\n",
        "# Creating these autograph wrappers so that tf.data operations are executed in graph mode\n",
        "#@tf.function\n",
        "def train(train_dataset, beta):\n",
        "    train_batch = next(train_dataset)\n",
        "    trainer.distributed_train_step(train_batch, beta)\n",
        "\n",
        "#@tf.function\n",
        "def test(valid_dataset, beta):\n",
        "    valid_batch = next(valid_dataset)\n",
        "    trainer.distributed_test_step(valid_batch, beta)\n",
        "\n",
        "while t < args.train_steps:\n",
        "    start_time = time.time()\n",
        "    beta = beta_sched.scheduler(t)\n",
        "    train(train_dist_dataset, beta)\n",
        "\n",
        "    if t % valid_inc == 0:\n",
        "        test(valid_dist_dataset, beta)\n",
        "        step_time = round(time.time() - start_time, 1)\n",
        "\n",
        "        metrics = {metric_name: log(metric) for metric_name, metric in trainer.metrics.items()}\n",
        "        metrics['step_time'] = step_time\n",
        "\n",
        "        # validation plotting\n",
        "        progbar.add(valid_inc, [('Train Loss', metrics['train_loss']),\n",
        "                                ('Validation Loss', metrics['valid_loss']),\n",
        "                                ('Time (s)', step_time)])\n",
        "        #Plot on Comet\n",
        "        experiment.log_metrics(metrics,step=t)\n",
        "        # Plot on WandB\n",
        "        wandb.log(metrics, step=t)\n",
        "\n",
        "    if (t+1) % save_inc == 0:\n",
        "        trainer.save_weights(model_path, run_id=wandb.run.id, experiment_key=experiment.get_key())\n",
        "        if not args.gcbc and not args.images:\n",
        "          z_enc, z_plan = produce_cluster_fig(next(plotting_dataset), encoder, planner, TEST_DATA_PATHS[0], num_take=dl.batch_size//4)\n",
        "\n",
        "          #Comet\n",
        "          experiment.log_figure('z_enc', z_enc, step=t)\n",
        "          experiment.log_figure('z_plan', z_plan,step=t)\n",
        "\n",
        "          # WandB\n",
        "          wandb.log({'z_enc':z_enc, 'z_plan':z_plan}, step=t)\n",
        "\n",
        "          #latent_fig = project_enc_and_plan(ze, zp)\n",
        "          #latent_img = plot_to_image(latent_fig)\n",
        "\n",
        "    t += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw21h14BnX3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3422a615-43c5-4278-b747-eccf10fcba72"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "t = time.time()\r\n",
        "for i in tqdm(range(0,10)):\r\n",
        "  train_batch = next(train_dist_dataset)\r\n",
        "  trainer.distributed_train_step(train_batch, args.beta)\r\n",
        "print(time.time() - t)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:03<00:00,  2.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.469046115875244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbNXA19QIxU8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}