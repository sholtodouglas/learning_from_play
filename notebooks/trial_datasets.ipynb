{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LMP Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G84fGXVwv9Fh",
        "-yC0L1P3v9GA",
        "8SHQGBjnv9GK",
        "b7CMny5dv9Gx",
        "njbQpQAGv9G2"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/trial_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUYgZwpGfav",
        "outputId": "2f731850-b8d2-470f-b969-52892e813fd1"
      },
      "source": [
        "!pip install wandb -q\n",
        "!pip install pathy -q\n",
        "!pip install comet_ml -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 23.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 22.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 122kB 9.3MB/s \n",
            "\u001b[?25h  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 256kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 522kB 17.0MB/s \n",
            "\u001b[?25h  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A74JBvLldKd-",
        "outputId": "e9a75073-29ec-4be1-f9b1-f5fa35d191ce"
      },
      "source": [
        "import requests\n",
        "r = requests.get('https://ipinfo.io')\n",
        "r.json()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': 'Council Bluffs',\n",
              " 'country': 'US',\n",
              " 'hostname': '37.186.192.35.bc.googleusercontent.com',\n",
              " 'ip': '35.192.186.37',\n",
              " 'loc': '41.2619,-95.8608',\n",
              " 'org': 'AS15169 Google LLC',\n",
              " 'postal': '51502',\n",
              " 'readme': 'https://ipinfo.io/missingauth',\n",
              " 'region': 'Iowa',\n",
              " 'timezone': 'America/Chicago'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFJvewo0ee6r",
        "outputId": "2c8ac3c2-9c84-4763-ffaa-43813e3d0345"
      },
      "source": [
        "# import comet_ml at the top of your file\n",
        "from comet_ml import Experiment\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msholto\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68MkXdDZaSZ",
        "outputId": "7604724f-629c-4452-8d4e-6a340d428430"
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='LFP training arguments')\n",
        "parser.add_argument('run_name')\n",
        "parser.add_argument('--train_datasets', nargs='+', help='Training dataset names')\n",
        "parser.add_argument('--test_datasets', nargs='+', help='Testing dataset names')\n",
        "parser.add_argument('-c', '--colab', default=False, action='store_true', help='Enable if using colab environment')\n",
        "parser.add_argument('-s', '--data_source', default='DRIVE', help='Source of training data')\n",
        "parser.add_argument('-tfr', '--from_tfrecords', default=False, action='store_true', help='Enable if using tfrecords format')\n",
        "parser.add_argument('-d', '--device', default='TPU', help='Hardware device to train on')\n",
        "parser.add_argument('-b', '--batch_size', default=512, type=int)\n",
        "parser.add_argument('-wmax', '--window_size_max', default=50, type=int)\n",
        "parser.add_argument('-wmin', '--window_size_min', default=20, type=int)\n",
        "parser.add_argument('-la', '--actor_layer_size', default=2048, type=int, help='Layer size of actor, increases size of neural net')\n",
        "parser.add_argument('-le', '--encoder_layer_size', default=512, type=int, help='Layer size of encoder, increases size of neural net')\n",
        "parser.add_argument('-lp', '--planner_layer_size', default=512, type=int, help='Layer size of planner, increases size of neural net')\n",
        "parser.add_argument('-embd', '--img_embedding_size', default=64, type=int, help='Embedding size of features,goal space')\n",
        "parser.add_argument('-z', '--latent_dim', default=256, type=int, help='Size of the VAE latent space')\n",
        "parser.add_argument('-g', '--gcbc', default=False, action='store_true', help='Enables GCBC, a simpler model with no encoder/planner')\n",
        "parser.add_argument('-n', '--num_distribs', default=None, type=int, help='Number of distributions to use in logistic mixture model')\n",
        "parser.add_argument('-q', '--qbits', default=None, type=int, help='Number of quantisation bits to discrete distributions into. Total quantisations = 2**qbits')\n",
        "parser.add_argument('-lr', '--learning_rate', type=float, default=3e-4)\n",
        "parser.add_argument('-t', '--train_steps', type=int, default=200000)\n",
        "parser.add_argument('-r', '--resume', default=False, action='store_true')\n",
        "parser.add_argument('-B', '--beta', type=float, default=0.00003)\n",
        "parser.add_argument('-i', '--images', default=False, action='store_true')\n",
        "parser.add_argument('--fp16', default=False, action='store_true')\n",
        "parser.add_argument('--bucket_name', help='GCS bucket name to stream data from')\n",
        "parser.add_argument('--tpu_name', help='GCP TPU name') # Only used in the script on GCP\n",
        "\n",
        "\n",
        "# ## Sample colab config\n",
        "# args = parser.parse_args('''\n",
        "# refactor_test\n",
        "# --train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "# --test_dataset UR5_slow_gripper_test\n",
        "# -c\n",
        "# -tfr\n",
        "# -s GCS\n",
        "# -d TPU\n",
        "# -b 512\n",
        "# -la 2048\n",
        "# -le 512\n",
        "# -lp 512\n",
        "# -z 256\n",
        "# -lr 3e-4\n",
        "# --bucket_name iowa_bucket_lfp\n",
        "# -i\n",
        "# '''.split())\n",
        "\n",
        "## Sample colab config\n",
        "args = parser.parse_args('''\n",
        "PB0_02\n",
        "--train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
        "--test_dataset UR5_slow_gripper_test\n",
        "-c\n",
        "-s GCS\n",
        "-d TPU\n",
        "-b 16\n",
        "-la 2048\n",
        "-le 512\n",
        "-lp 2048\n",
        "-z 256\n",
        "-lr 3e-4\n",
        "-B 0.02\n",
        "-i \n",
        "-tfr\n",
        "-n 5\n",
        "--bucket_name iowa_bucket_lfp\n",
        "'''.split())\n",
        "\n",
        "# -n 5\n",
        "# -q 8\n",
        "\n",
        "print(args)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(actor_layer_size=2048, batch_size=16, beta=0.02, bucket_name='iowa_bucket_lfp', colab=True, data_source='GCS', device='TPU', encoder_layer_size=512, fp16=False, from_tfrecords=True, gcbc=False, images=True, img_embedding_size=64, latent_dim=256, learning_rate=0.0003, num_distribs=5, planner_layer_size=2048, qbits=None, resume=False, run_name='PB0_02', test_datasets=['UR5_slow_gripper_test'], tpu_name=None, train_datasets=['UR5', 'UR5_slow_gripper', 'UR5_high_transition'], train_steps=200000, window_size_max=50, window_size_min=20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EliqxOpPv9Dy"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMJ___6ARZ4u",
        "outputId": "2688389d-306b-47e7-e46d-d1622e96f056"
      },
      "source": [
        "from pathlib import Path\n",
        "from pathy import Pathy\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "import pprint\n",
        "import logging\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "#@title Workpace Setup (Local vs Colab)\n",
        "\n",
        "# Set up working directory and libraries\n",
        "if args.colab:\n",
        "    from google.colab import drive, auth\n",
        "    print('Using colab setup')\n",
        "    WORKING_PATH = Path('/content/learning_from_play')\n",
        "    # Clone repo\n",
        "    try:\n",
        "        get_ipython().system(\"git clone 'https://github.com/sholtodouglas/learning_from_play' {WORKING_PATH}\")\n",
        "    except: \n",
        "        pass\n",
        "    # Mount drive\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print('Using local setup')\n",
        "    WORKING_PATH = Path.cwd()\n",
        "    print(f'Working path: {WORKING_PATH}')\n",
        "\n",
        "# Change working directory to learning_from_play\n",
        "os.chdir(WORKING_PATH)\n",
        "import lfp\n",
        "\n",
        "# Set up storage directory and datasets\n",
        "if args.data_source == 'DRIVE':\n",
        "    assert args.colab, \"Must be using Colab\"\n",
        "    print('Reading data from Google Drive')\n",
        "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
        "elif args.data_source == 'GCS':\n",
        "    if args.colab:\n",
        "      auth.authenticate_user()\n",
        "    print('Reading data from Google Cloud Storage')\n",
        "    r = requests.get('https://ipinfo.io')\n",
        "    region = r.json()['region']\n",
        "    project_id = 'learning-from-play-303306'\n",
        "    logging.warning(f'You are accessing GCS data from {region}, make sure this is the same as your bucket {args.bucket_name}')\n",
        "    STORAGE_PATH = Pathy(f'gs://{args.bucket_name}')\n",
        "else:\n",
        "    print('Reading data from local filesystem')\n",
        "    STORAGE_PATH = WORKING_PATH\n",
        "\n",
        "print(f'Storage path: {STORAGE_PATH}')\n",
        "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.train_datasets]\n",
        "TEST_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.test_datasets]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab setup\n",
            "fatal: destination path '/content/learning_from_play' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:You are accessing GCS data from Iowa, make sure this is the same as your bucket iowa_bucket_lfp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No pybullet installation found - which is fine if training\n",
            "Reading data from Google Cloud Storage\n",
            "Storage path: gs://iowa_bucket_lfp/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zbmq324x2yv",
        "outputId": "d948b27e-950b-408a-af26-92140152dea7"
      },
      "source": [
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "if args.device == 'TPU':\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args.tpu_name)  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
        "    print(\"REPLICAS: \", NUM_DEVICES)\n",
        "    if args.fp16:\n",
        "        tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
        "else:\n",
        "    physical_devices = tf.config.list_physical_devices()\n",
        "    if args.device == 'GPU':\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
        "        if args.fp16:\n",
        "            tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    NUM_DEVICES = 1\n",
        "    print(physical_devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.16.93.98:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.93.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.93.98:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HejtDH_Yx8h"
      },
      "source": [
        "# Use this to edit modules without needing to restart the kernel (can also edit local, push/pull)\n",
        "!git pull\n",
        "import importlib\n",
        "importlib.reload(lfp.data)\n",
        "importlib.reload(lfp.model)\n",
        "importlib.reload(lfp.train)\n",
        "importlib.reload(lfp.metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI6JP06FdTv"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lBWIyOFdTv"
      },
      "source": [
        "GLOBAL_BATCH_SIZE = args.batch_size * NUM_DEVICES\n",
        "dl = lfp.data.PlayDataloader(include_imgs = args.images, batch_size=GLOBAL_BATCH_SIZE,  window_size=args.window_size_max, min_window_size=args.window_size_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiz4AXCnFdTv"
      },
      "source": [
        "# Train data\n",
        "train_data = dl.extract(TRAIN_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "train_dataset = dl.load(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8ZDAVpLFdTw"
      },
      "source": [
        "# Validation data\n",
        "valid_data = dl.extract(TEST_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "valid_dataset = dl.load(valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpRPRuv9E6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uMXBjGzgZCA"
      },
      "source": [
        "from lfp.train import LFPTrainer\n",
        "\n",
        "def train_setup():\n",
        "    model_params = {'obs_dim':args.img_embedding_size + dl.proprioceptive_features_dim if args.images else dl.obs_dim,\n",
        "                'goal_dim':args.img_embedding_size if args.images else dl.goal_dim,\n",
        "                'act_dim':dl.act_dim,\n",
        "                'layer_size':args.actor_layer_size, \n",
        "                'latent_dim':args.latent_dim}\n",
        "\n",
        "    actor = lfp.model.create_actor(**model_params, gcbc=args.gcbc, num_distribs=args.num_distribs, qbits=args.qbits)\n",
        "\n",
        "    if args.gcbc:\n",
        "        encoder = None\n",
        "        planner = None\n",
        "    else:\n",
        "        model_params['layer_size'] = args.encoder_layer_size\n",
        "        encoder = lfp.model.create_encoder(**model_params)\n",
        "        model_params['layer_size'] = args.planner_layer_size\n",
        "        planner = lfp.model.create_planner(**model_params)\n",
        "\n",
        "    if args.images:\n",
        "      cnn = lfp.model.create_vision_network(dl.img_size, dl.img_size, embedding_size=args.img_embedding_size)\n",
        "    else:\n",
        "      cnn = None\n",
        "\n",
        "    #optimizer = tfa.optimizers.LAMB(learning_rate=args.learning_rate)\n",
        "    optimizer = optimizer = tf.optimizers.Adam\n",
        "    trainer = LFPTrainer(args, actor, dl, encoder, planner, cnn, optimizer, strategy, GLOBAL_BATCH_SIZE)\n",
        "    return actor, encoder, planner, trainer\n",
        "\n",
        "\n",
        "if args.device=='CPU' or args.device=='GPU':\n",
        "     actor, encoder, planner, trainer = train_setup()\n",
        "else:\n",
        "    with strategy.scope():\n",
        "         actor, encoder, planner, trainer = train_setup()\n",
        "        \n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqCRP1L5f3gI"
      },
      "source": [
        "\n",
        "train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
        "valid_dist_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))\n",
        "plotting_dataset = iter(valid_dataset) #for the cluster fig, easier with a non distributed dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOTtdIKHfQk3"
      },
      "source": [
        "# Creating these autograph wrappers so that tf.data operations are executed in graph mode\n",
        "@tf.function\n",
        "def train(train_dataset, beta):\n",
        "    train_batch = next(train_dataset)\n",
        "    trainer.distributed_train_step(train_batch, beta)\n",
        "@tf.function\n",
        "def sampleOnfly(train_dataset, beta):\n",
        "    train_batch = next(train_dataset)\n",
        "\n",
        "#train(train_dist_dataset, args.beta)\n",
        "sampleOnfly(train_dist_dataset, args.beta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTRSCD06flrt",
        "outputId": "0c567067-5216-429a-d7e9-c014587be524"
      },
      "source": [
        "from tqdm import tqdm\n",
        "t = time.time()\n",
        "for i in tqdm(range(0,10)):\n",
        "  train(train_dist_dataset, args.beta)\n",
        "  # train_batch = next(train_dist_dataset)\n",
        "  # trainer.distributed_train_step(train_batch, args.beta)\n",
        "print(time.time()-t)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 218.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.048511505126953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvAmcAknnDyA",
        "outputId": "98aa845e-9011-49a3-b0d1-43946c298001"
      },
      "source": [
        "from tqdm import tqdm\n",
        "t = time.time()\n",
        "for i in tqdm(range(0,1000)):\n",
        "  sampleOnfly(train_dist_dataset, args.beta)\n",
        "  # train_batch = next(train_dist_dataset)\n",
        "  # trainer.distributed_train_step(train_batch, args.beta)\n",
        "print(time.time()-t)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:01<00:00, 707.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.4157133102416992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr4uTC5DpCw-",
        "outputId": "bfb79810-bdfb-4e81-ba7a-ce93b4a76ce5"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([34.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk3ed-Ifnt0C"
      },
      "source": [
        "#@title Serialise\n",
        "\n",
        "\n",
        "r = lfp.data.PlayDataloader(include_imgs = args.images, batch_size=1,  window_size=args.window_size_max, min_window_size=args.window_size_min)\n",
        "rd = r.extract(TRAIN_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
        "rd = r.load(rd)\n",
        "r_it = iter(rd)\n",
        "r_it.next()\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def sample():\n",
        "  return r_it.next()\n",
        "\n",
        "sample()['seq_lens']\n",
        "\n",
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Example, Features, Feature\n",
        "\n",
        "def serialise(data):\n",
        "    \n",
        "    obs, acts, goals, seq_lens, masks, dataset_path, tstep_idxs , imgs , goal_imgs, proprioceptive_features = data['obs'], \\\n",
        "    data['acts'], data['goals'], data['seq_lens'], data['masks'], data['dataset_path'], data['tstep_idxs'], data['imgs'], data['goal_imgs'], data['proprioceptive_features']\n",
        "    \n",
        "    # obs (1, 40, 18)\n",
        "    # acts (1, 40, 7)\n",
        "    # goals (1, 40, 11)\n",
        "    # seq_lens (1,)\n",
        "    # masks (1, 40)\n",
        "    # dataset_path (1, 40)\n",
        "    # tstep_idxs (1, 40)\n",
        "    # imgs (1, 40, 200, 200, 3)\n",
        "    # goal_imgs (1, 40, 200, 200, 3)\n",
        "    # proprioceptive_features (1, 40, 7)\n",
        "\n",
        "    goal_imgs = tf.expand_dims(goal_imgs[:,0,:,:,:],1) # crete a :, 1, :,:,: shaped goal images for less file IO\n",
        "\n",
        "    \n",
        "    obs = Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(tf.squeeze(obs)).numpy(),]))\n",
        "    acts = Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(tf.squeeze(acts)).numpy(),]))\n",
        "    goals = Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(tf.squeeze(goals)).numpy(),])) \n",
        "    seq_lens = Feature(int64_list=Int64List(value=[seq_lens,]))\n",
        "    masks = Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(tf.squeeze(masks)).numpy(),])) \n",
        "\n",
        "    imgs = Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(tf.squeeze(imgs)).numpy(),]))\n",
        "    goal_imgs = Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(tf.squeeze(goal_imgs)).numpy(),]))\n",
        "    proprioceptive_features = Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(tf.squeeze(proprioceptive_features)).numpy(),]))\n",
        "\n",
        "    \n",
        "    features = Features(feature={\n",
        "              'obs':obs,\n",
        "              'acts':acts,\n",
        "              'goals':goals,\n",
        "              'seq_lens':seq_lens,\n",
        "              'masks':masks,\n",
        "              'imgs':imgs,\n",
        "              'goal_imgs':goal_imgs,\n",
        "              'proprioceptive_features':proprioceptive_features})\n",
        "    \n",
        "    example = Example(features=features)\n",
        "    \n",
        "    return example.SerializeToString()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNKLeVdEoWqK",
        "outputId": "f4aae5db-c079-478c-bd94-c3a3ca50f2ba"
      },
      "source": [
        "#@title write to gcs\n",
        "data_paths = [str(STORAGE_PATH/'precompute')+f\"/{x}.tfrecords\" for x in range(0,4)]\n",
        "for path in data_paths:\n",
        "  with tf.io.TFRecordWriter(path) as file_writer:\n",
        "    print(path)\n",
        "    for i in tqdm(range(0,200)):\n",
        "        byte_stream = serialise(sample())\n",
        "        file_writer.write(byte_stream)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 3/200 [00:00<00:08, 24.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "gs://iowa_bucket_lfp/precompute/0.tfrecords\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:09<00:00, 21.61it/s]\n",
            "  2%|▏         | 3/200 [00:00<00:08, 23.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "gs://iowa_bucket_lfp/precompute/1.tfrecords\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:09<00:00, 21.40it/s]\n",
            "  2%|▏         | 3/200 [00:00<00:08, 23.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "gs://iowa_bucket_lfp/precompute/2.tfrecords\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:09<00:00, 21.78it/s]\n",
            "  2%|▏         | 3/200 [00:00<00:08, 23.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "gs://iowa_bucket_lfp/precompute/3.tfrecords\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:08<00:00, 22.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR6dq6KeoWss"
      },
      "source": [
        "# @------title decode\n",
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    #image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [200,200, 3]) # explicit size needed for TPU\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "            'obs':tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring,\n",
        "            'acts':tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring,\n",
        "            'goals':tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring,\n",
        "            'seq_lens':tf.io.FixedLenFeature([], tf.int64),\n",
        "            'masks':tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring,\n",
        "            'imgs':tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring,\n",
        "            'goal_imgs':tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring,\n",
        "            'proprioceptive_features':tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring,\n",
        "    }\n",
        "    data = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    \n",
        "    obs = tf.io.parse_tensor(data['obs'], tf.float32) \n",
        "    acts = tf.io.parse_tensor(data['acts'], tf.float32) \n",
        "    goals = tf.io.parse_tensor(data['goals'], tf.float32)  \n",
        "    seq_lens = tf.cast(data['seq_lens'], tf.int32) # this is meant to be 32 even though you serialize as 64\n",
        "    masks = tf.io.parse_tensor(data['masks'], tf.float32) \n",
        "    imgs = tf.io.parse_tensor(data['imgs'], tf.uint8)   \n",
        "    goal_imgs = tf.io.parse_tensor(data['goal_imgs'], tf.uint8)\n",
        "    goal_imgs = tf.tile(tf.expand_dims(tf.io.parse_tensor(data['goal_imgs'], tf.uint8),0), [args.window_size_max,1,1,1])   \n",
        "    proprioceptive_features =tf.io.parse_tensor( data['proprioceptive_features'], tf.float32) \n",
        "\n",
        "    \n",
        "    # img = decode_image(data['img'])\n",
        "\n",
        "    return {  'obs':obs,\n",
        "              'acts':acts,\n",
        "              'goals':goals,\n",
        "              'seq_lens':seq_lens,\n",
        "              'masks':masks,\n",
        "              'imgs':imgs,\n",
        "              'goal_imgs':goal_imgs,\n",
        "              'proprioceptive_features':proprioceptive_features}\n",
        "              \n",
        "def load_tf_records(filenames, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    # check, does this ignore intra order or just inter order? Both are an issue!\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=60) # automatically interleaves reads from multiple files - keep it at 1 we need the order\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=600)\n",
        "    dataset =   dataset.repeat()\\\n",
        "                .batch(dl.batch_size, drop_remainder=True)\\\n",
        "                .prefetch(dl.prefetch_size)\n",
        "    return dataset\n",
        "\n",
        "d =load_tf_records(data_paths, ordered=False)#['/home/sholto/Desktop/AI/learning_from_play/data/UR5_high_transition/tf_records/21.tfrecords'], ordered=True) #record_paths"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s4n1rTzrX_A"
      },
      "source": [
        "precomp_dist_dataset = iter(strategy.experimental_distribute_dataset(d))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekYKKG_Qr2FI",
        "outputId": "6e5df56c-0510-4514-b415-5fd33af4e50a"
      },
      "source": [
        "precomp_dist_dataset.next().keys()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['obs', 'acts', 'goals', 'seq_lens', 'masks', 'imgs', 'goal_imgs', 'proprioceptive_features'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM42n9QVv7jg",
        "outputId": "c5e9cac7-54e6-46a4-845f-30c92b50d369"
      },
      "source": [
        "for k,v in train_dist_dataset.next().items():\n",
        "  print(k)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "obs\n",
            "acts\n",
            "goals\n",
            "seq_lens\n",
            "masks\n",
            "dataset_path\n",
            "tstep_idxs\n",
            "imgs\n",
            "goal_imgs\n",
            "proprioceptive_features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5-WKXABwrDV"
      },
      "source": [
        "@tf.function\n",
        "def sampleprecomp():\n",
        "  train_batch = next(precomp_dist_dataset)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONDNh-PirlMZ",
        "outputId": "13250cb7-f23c-43d3-f130-793e65f663eb"
      },
      "source": [
        "from tqdm import tqdm\n",
        "t = time.time()\n",
        "for i in tqdm(range(0,100)):\n",
        "  # train(precomp_dist_dataset, args.beta)\n",
        "  sampleprecomp()\n",
        "  #trainer.distributed_train_step(train_batch, args.beta)\n",
        "print(time.time()-t)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 100/100 [00:00<00:00, 5201.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.022202491760253906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w32JLQP9oWu7"
      },
      "source": [
        "d = iter(d)\n",
        "x = d.next()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KmhweQb-q1Kd",
        "outputId": "02a0b0c6-3eaf-4bd9-b5d8-2d86779d4352"
      },
      "source": [
        "t = time.time()\n",
        "for i in range(0,100):\n",
        "  print(i)\n",
        "  x = d.next()\n",
        "print(time.time()-t)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# Fast path for the case `self._structure` is not a nested structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute '_from_compatible_tensor_list'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-f98e5e22e2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mfrom_compatible_tensor_list\u001b[0;34m(element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    242\u001b[0m   return _from_tensor_list_helper(\n\u001b[1;32m    243\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m       element_spec, tensor_list)\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m_from_tensor_list_helper\u001b[0;34m(decode_fn, element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponent_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_flat_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_specs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_spec_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_flat_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mflat_ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_flat_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(spec, value)\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m   return _from_tensor_list_helper(\n\u001b[0;32m--> 243\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m       element_spec, tensor_list)\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m_from_compatible_tensor_list\u001b[0;34m(self, tensor_list)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# information.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mtensor_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m       raise ValueError(\n\u001b[1;32m   1216\u001b[0m           \u001b[0;34m\"Tensor's shape %s is not compatible with supplied shape %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;31m# `_tensor_shape` is declared and defined in the definition of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# `EagerTensor`, in C.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtSlIEoBlDyp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "8c5cca44-dd35-4d23-ad78-e52fa1411690"
      },
      "source": [
        "from lfp.train import BetaScheduler\n",
        "\n",
        "\n",
        "# 0.00001 so far works best for MAE - try lower - 0.00003 with a BETA accel of 10 so far works best, perfect encoder, nicely mapped planner\n",
        "# recall 0.01 worked okay for probabilistic - proba still too unstable!\n",
        "beta_sched = BetaScheduler('linear', \n",
        "                           beta=args.beta, \n",
        "                           beta_max=args.beta, \n",
        "                           max_steps=args.train_steps, \n",
        "                           cycles=90, \n",
        "                           duty_cycle=0.5\n",
        "                           )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEGCAYAAAC6i5gfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7RdZX3n8fenSRN/AjEEm0mQG0ykDbWinMWP1Wo7RmLoKMHClGQ6izgyUsXMTOty1TCM1JWurhGZltFC1QhMkVEJZqRel7WIgrbSgtwABoIGbmJaEhAvAUPxR2jgM3/s58rO8dx7z03u2SeBz2uts87ez/7uZz9733PP9z57P3dv2SYiIqJJv9DvBkRExPNPkk9ERDQuySciIhqX5BMREY1L8omIiMZN73cDDkZHHnmkBwYG+t2MiIhDysaNGx+1Paeb2CSfDgYGBhgaGup3MyIiDimS/qnb2Jx2i4iIxiX5RERE45J8IiKicUk+ERHRuCSfiIhoXE+Tj6RlkrZIGpa0psPymZLWl+W3Sxoo5adJ2ijpnvL+xto6fyrpQUlPdlNXWXZhKd8i6c292t+IiOhOz5KPpGnAFcDpwGJgpaTFbWHnAY/bXghcBlxSyh8F3mr71cAq4NraOl8ETuqwyY51lW2uAI4HlgF/WdoWERF90suez0nAsO1ttp8CrgOWt8UsB64p0xuAJZJk+y7bD5XyzcALJc0EsH2b7Yc7bK9jXaX8Ott7bH8PGKZz8oqIiIb0MvnMAx6sze8oZR1jbO8FdgOz22LOAu60vafb7bXV1U07kHS+pCFJQyMjIxNsKiIiDsRBPeBA0vFUp89+v9fbsr3Odst2a86cru4OERER+6mXyWcncHRtfn4p6xgjaTpwOLCrzM8HbgDOtb11Mttrq6ubdkRERIN6mXzuABZJWiBpBtVF/8G2mEGqAQUAZwM327akI4AvAWts39rl9jrWVcpXlNFwC4BFwLf2e68iIuKA9Sz5lOsuq4Ebge8A19veLGmtpDNK2FXAbEnDwHuB0eHYq4GFwMWS7i6vowAkfVjSDuBFknZI+uB4ddneDFwP3Af8LfAe20/3ar8jImJiqjoHUddqtZy7WkdETI6kjbZb3cQe1AMOIiLiuSnJJyIiGpfkExERjUvyiYiIxiX5RERE45J8IiKicUk+ERHRuCSfiIhoXJJPREQ0LsknIiIal+QTERGNS/KJiIjGJflERETjknwiIqJxST4REdG4JJ+IiGhcT5OPpGWStkgalrSmw/KZktaX5bdLGijlp0naKOme8v7G2jonlvJhSR+VpFK+vvbU0+2S7i7lA5J+Ulv28V7uc0RETGx6ryqWNA24AjgN2AHcIWnQ9n21sPOAx20vlLQCuAQ4B3gUeKvthyT9KtWjuOeVdT4GvBO4HfgbYBnwZdvn1Lb9Z8Du2na22j6hF/sZERGT18uez0nAsO1ttp8CrgOWt8UsB64p0xuAJZJk+y7bD5XyzcALSy9pLnCY7dtcPf/7U8CZ9QpLT+h3gc/2ZrciIuJA9TL5zAMerM3v4Nney8/F2N5L1VuZ3RZzFnCn7T0lfscEdb4eeMT2A7WyBZLukvQNSa/v1FhJ50sakjQ0MjIy8d5FRMR+69lpt6kg6XiqU3FLJ7HaSvbt9TwMvML2LkknAn8t6XjbT9RXsr0OWAfQarV8YC2PiIjx9LLnsxM4ujY/v5R1jJE0HTgc2FXm5wM3AOfa3lqLnz9WnaWO3wHWj5bZ3mN7V5neCGwFXnWA+xYREQegl8nnDmCRpAWSZgArgMG2mEFgVZk+G7jZtiUdAXwJWGP71tFg2w8DT0g6pVzbORf4Qq2+NwHftf2zU3OS5pTBD0g6FlgEbJvKHY2IiMnpWfIp13BWU41U+w5wve3NktZKOqOEXQXMljQMvBcYHY69GlgIXFwbIn1UWXYBcCUwTNWL+XJtsyv4+YEGbwA2laHXG4B32X5sKvc1IiImR9WgsahrtVoeGhrqdzMiIg4pkjbabnUTmzscRERE45J8IiKicUk+ERHRuCSfiIhoXJJPREQ0LsknIiIal+QTERGNS/KJiIjGJflERETjknwiIqJxST4REdG4JJ+IiGhckk9ERDQuySciIhqX5BMREY1L8omIiMb1NPlIWiZpi6RhSWs6LJ8paX1ZfrukgVJ+mqSNku4p72+srXNiKR+W9NHyOG0kfVDSztqTT3+7ts6FJX6LpDf3cp8jImJiPUs+kqYBVwCnA4uBlZIWt4WdBzxueyFwGXBJKX8UeKvtVwOrgGtr63wMeCewqLyW1ZZdZvuE8vqb0o7FVI/XPr7E/mVpW0RE9Ekvez4nAcO2t9l+CrgOWN4Wsxy4pkxvAJZIku27bD9UyjcDLyy9pLnAYbZvc/X8708BZ07QjuXAdbb32P4eMFzaFhERfdLL5DMPeLA2v6OUdYyxvRfYDcxuizkLuNP2nhK/Y5w6V0vaJOlqSbMm0Q4knS9pSNLQyMhIN/sXERH76aAecCDpeKpTcb/fRfjHgFcCJwAPA382mW3ZXme7Zbs1Z86cSbc1IiK618vksxM4ujY/v5R1jJE0HTgc2FXm5wM3AOfa3lqLn9+pTtuP2H7a9jPAJ3n21Fo37YiIiAb1MvncASyStEDSDKqL/oNtMYNUAwoAzgZutm1JRwBfAtbYvnU02PbDwBOSTimj3M4FvgBQrgeNehtwb20bK8o1owVUgxS+NZU7GhERkzO9VxXb3itpNXAjMA242vZmSWuBIduDwFXAtZKGgceoEhTAamAhcLGki0vZUts/AC4A/gp4IfDl8gL4sKQTAAPbKafqyjavB+4D9gLvsf10r/Y7IiImpmrQWNS1Wi0PDQ31uxkREYcUSRttt7qJPagHHERExHNTkk9ERDQuySciIhqX5BMREY1L8omIiMYl+UREROOSfCIionFJPhER0bgkn4iIaFyST0RENC7JJyIiGpfkExERjUvyiYiIxiX5RERE45J8IiKicT1NPpKWSdoiaVjSmg7LZ0paX5bfLmmglJ8maaOke8r7G2vrnFjKhyV9tDzRFEmXSvqupE2SbihPQ0XSgKSfSLq7vD7ey32OiIiJ9Sz5SJoGXAGcDiwGVkpa3BZ2HvC47YXAZcAlpfxR4K22X031mO1ra+t8DHgn1eOwFwHLSvlNwK/a/jXgfuDC2jpbbZ9QXu+aqn2MiIj908uez0nAsO1ttp8CrgOWt8UsB64p0xuAJZJk+y7bD5XyzcALSy9pLnCY7dtcPYL1U8CZALa/YntvWec2YH7vdi0iIg5EL5PPPODB2vyOUtYxpiSO3cDstpizgDtt7ynxOyaoE+AdwJdr8wsk3SXpG5Je36mxks6XNCRpaGRkZPw9i4iIAzK93w0Yj6TjqU7FLZ3EOhcBe4FPl6KHgVfY3iXpROCvJR1v+4n6erbXAesAWq2Wp6L9ERHRWS97PjuBo2vz80tZxxhJ04HDgV1lfj5wA3Cu7a21+PrptH3qlPR24C3A75XTctjeY3tXmd4IbAVedeC7FxER+6uXyecOYJGkBZJmACuAwbaYQaoBBQBnAzfbdhmp9iVgje1bR4NtPww8IemUMsrtXOALUI2sA/4IOMP2j0fXkTSnDH5A0rFUgxS2Tf3uRkREt3qWfMo1nNXAjcB3gOttb5a0VtIZJewqYLakYeC9wOhw7NXAQuDi2hDpo8qyC4ArgWGqXszotZ3LgZcCN7UNqX4DsEnS3VSDGt5l+7Ee7XZERHRB5exU1LRaLQ8NDfW7GRERhxRJG223uonNHQ4iIqJxST4REdG4JJ+IiGhckk9ERDQuySciIhqX5BMREY1L8omIiMYl+UREROOSfCIionFJPhER0bhJPVKh3F/tBaPztv95ylsUERHPeV31fCSdIekB4HvAN4Dt7PuwtoiIiK51e9rtT4BTgPttLwCWUD2qOiIiYtK6TT7/Wh7I9guSfsH2LUBXdy6NiIho1+01nx9Kegnwd8CnJf0A+FHvmhUREc9l3fZ8lgM/Bv4Q+Fuqh7i9pVeNioiI57Zuk8/Ftp+xvdf2NbY/Crx/opUkLZO0RdKwpDUdls+UtL4sv13SQCk/TdJGSfeU9zfW1jmxlA9L+mh5nDaSXibpJkkPlPdZpVwlbljSJkmv63KfIyKiR7pNPqd1KDt9vBUkTQOuKHGLgZWSFreFnQc8bnshcBlwSSl/FHir7VcDq4Bra+t8DHgnsKi8lpXyNcDXbC8Cvsazj+Q+vRZ7flk/IiL6aNxrPpLeDVwAHCtpU23RS4FbJ6j7JGDY9rZS13VUp+/uq8UsBz5YpjcAl0uS7btqMZuBF0qaCbwMOMz2baXOTwFnUg37Xg78VlnnGuDrVL2z5cCnXD0v/DZJR0iaa/vhCdo/aU/89F95/4ZNEwdGRBykBo58Me9f9ss9385EAw4+Q/XF/j95ticB8C+2H5tg3XnAg7X5HcDJY8XY3itpNzCbqucz6izgTtt7JM0r9dTrnFemX15LKN8HXj5OO+YB+yQfSedT9Yx4xSteMcGudfbMM2bryJP7tW5ExMHgF6c1c+ObcZOP7d3AbqpTZr8BLLL9fyQdKWmB7e/1snGSjqc6Fbd0MuvZtiRPcp11wDqAVqs1qXVHHfGiGXzlD39zf1aNiHhe6fYOB39MdQrrwlI0A/i/E6y2Ezi6Nj+/lHWMkTQdOBzYVebnAzcA59reWoufP0adj0iaW9adC/xgEu2IiIgGddu/ehtwBuV/e2w/RHXdZzx3AIskLZA0A1gBDLbFDFINKAA4G7i59FqOAL4ErLH9s2tL5bTaE5JOKaPczgW+0KGuVW3l55ZRb6cAu3txvSciIrrXbfJ5qlywN4CkF0+0gu29wGrgRuA7wPW2N0taK+mMEnYVMFvSMPBenr2utBpYCFws6e7yOqosuwC4Ehim+n+j0XvMfQg4rdyD7k1lHuBvgG0l/pNl/YiI6CNVOWWCIOl9VEOVT6MafPAO4DO2/6K3zeuPVqvloaGhfjcjIuKQImmj7a5uvdbV7XVs/y9JpwFPAMdR/dPpTQfQxoiIeB7r+nk+JdncJOlIyqCAiIiI/THuNZ9yYf/rkj4v6bWS7gXupRpZtmy8dSMiIsYyUc/ncuC/Uw2Bvhk43fZtkn4Z+CzVTUYjIiImZaLRbtNtf8X254Dvj97WxvZ3e9+0iIh4rpoo+TxTm/5J27L9ugtARETERKfdXiPpCUBUN/d8opQLeEFPWxYREc9ZE93bbVpTDYmIiOePZm5fGhERUZPkExERjUvyiYiIxiX5RERE45J8IiKicUk+ERHRuCSfiIhoXJJPREQ0rqfJR9IySVskDUta02H5TEnry/LbJQ2U8tmSbpH0pKTL29Y5R9ImSZslXVIrv6z21NP7Jf2wtuzp2rL2R3lHRETDun6ez2RJmgZcQfX00x3AHZIGbd9XCzsPeNz2QkkrgEuAc4CfAh8AfrW8RuucDVwKnGh7RNI1kpbY/prtP6zF/RfgtbXt/MT2Cb3Z04iImKxe9nxOAoZtb7P9FHAdsLwtZjlwTZneACyRJNs/sv1NqiRUdyzwgO2RMv9V4KwO215J9ciHiIg4CPUy+cwDHqzN7yhlHWNs7wV2A7PHqXMYOE7SgKTpwJnA0fUASccAC6iePzTqBZKGJN0m6cxOFUs6v8QMjYyMdAqJiIgpckgNOLD9OPBuYD3w98B24Om2sBXABtv18mNst4D/APxvSa/sUPc62y3brTlz5vSk/RERUell8tnJvr2S+aWsY0zpyRwO7BqvUttftH2y7VOBLcD9bSEraDvlZntned8GfJ19rwdFRETDepl87gAWSVogaQZVUmgfaTYIrCrTZwM32x73IXWSjirvs4ALgCtry34ZmAX8Y61slqSZZfpI4NeB+qCHiIhoWM9Gu9neK2k1cCMwDbja9mZJa4Eh24PAVcC1koaBx6gSFACStgOHATPKdZqlZaTcRyS9poSttV3v+awArmtLYL8CfELSM1TJ9kNtI+4iIqJhmqCj8bzUarU8NDTU72ZERBxSJG0s19cndEgNOIiIiOeGJJ+IiGhckk9ERDQuySciIhqX5BMREY1L8omIiMYl+UREROOSfCIionFJPhER0bgkn4iIaFyST0RENC7JJyIiGpfkExERjUvyiYiIxiX5RERE43qafCQtk7RF0rCkNR2Wz5S0viy/XdJAKZ8t6RZJT0q6vG2dcyRtkrRZ0iW18rdLGpF0d3n959qyVZIeKK9VREREX/Us+UiaBlwBnA4sBlZKWtwWdh7wuO2FwGXAaDL5KfAB4H1tdc4GLgWW2D4e+CVJS2oh622fUF5XlnVeBvwxcDJwEvDH5RHcERHRJ73s+ZwEDNveZvsp4DpgeVvMcuCaMr0BWCJJtn9k+5tUSajuWOAB2yNl/qvAWRO0483ATbYfs/04cBOwbP92KSIipkIvk8884MHa/I5S1jHG9l5gNzB7nDqHgeMkDUiaDpwJHF1bflY5JbdB0mh5N+1A0vmShiQNjYyMtC+OiIgpdEgNOCg9l3cD64G/B7YDT5fFXwQGbP8aVe/mmk51jFP3Otst2605c+ZMXaMjIuLn9DL57GTfXsn8UtYxpvRkDgd2jVep7S/aPtn2qcAW4P5Svsv2nhJ2JXDiJNoREREN6mXyuQNYJGmBpBnACmCwLWYQGB19djZws22PV6mko8r7LOACqkSDpLm1sDOA75TpG4GlkmaVdZaWsoiI6JPpvarY9l5Jq6m+6KcBV9veLGktMGR7ELgKuFbSMPAYVYICQNJ24DBghqQzgaW27wM+Iuk1JWyt7fvL9H+VdAawt9T19tKOxyT9CVUyHF3nsV7td0RETEwTdDSel1qtloeGhvrdjIiIQ4qkjbZb3cQeUgMOIiLiuSHJJyIiGpfkExERjUvyiYiIxiX5RERE45J8IiKicUk+ERHRuCSfiIhoXJJPREQ0LsknIiIal+QTERGNS/KJiIjGJflERETjknwiIqJxST4REdG4JJ+IiGhcT5OPpGWStkgalrSmw/KZktaX5bdLGijlsyXdIulJSZe3rXOOpE2SNku6pFb+Xkn3lWVfk3RMbdnTku4ur/ZHeUdERMN6lnwkTQOuAE4HFgMrJS1uCzsPeNz2QuAyYDSZ/BT4APC+tjpnA5cCS2wfD/ySpCVl8V1Ay/avARuAD9dW/YntE8rrjCnbyYiI2C+97PmcBAzb3mb7KeA6YHlbzHLgmjK9AVgiSbZ/ZPubVEmo7ljgAdsjZf6rwFkAtm+x/eNSfhswf2p3JyIipkovk8884MHa/I5S1jHG9l5gNzB7nDqHgeMkDUiaDpwJHN0h7jzgy7X5F0gaknSbpDM7VSzp/BIzNDIy0ikkIiKmyPR+N2AybD8u6d3AeuAZ4B+AV9ZjJP1HoAX8Zq34GNs7JR0L3CzpHttb2+peB6wDaLVa7uFuREQ87/Wy57OTfXsl80tZx5jSkzkc2DVepba/aPtk26cCW4D7R5dJehNwEXCG7T21dXaW923A14HX7t8uRUTEVOhl8rkDWCRpgaQZwAqgfaTZILCqTJ8N3Gx73F6HpKPK+yzgAuDKMv9a4BNUiecHtfhZkmaW6SOBXwfuO8B9i4iIA9Cz026290paDdwITAOutr1Z0lpgyPYgcBVwraRh4DGqBAWApO3AYcCMcp1mqe37gI9Iek0JW2t7tOdzKfAS4HOSAP65jGz7FeATkp6hSrYfKvVERESfaIKOxvNSq9Xy0NBQv5sREXFIkbTRdqub2NzhICIiGpfkExERjUvyiYiIxiX5RERE45J8IiKicUk+ERHRuCSfiIhoXJJPREQ0LsknIiIal+QTERGNS/KJiIjGJflERETjknwiIqJxST4REdG4JJ+IiGhckk9ERDSup8lH0jJJWyQNS1rTYflMSevL8tslDZTy2ZJukfSkpMvb1jlH0iZJmyVdMlFdZdmFpXyLpDf3an8jIqI7PUs+kqYBVwCnA4uBlZIWt4WdBzxueyFwGTCaTH4KfAB4X1uds6kel73E9vHAL0laMl5dZZsrgOOBZcBflrZFRESf9LLncxIwbHub7aeA64DlbTHLgWvK9AZgiSTZ/pHtb1IlobpjgQdsj5T5rwJnjVdXKb/O9h7b3wOGS9siIqJPepl85gEP1uZ3lLKOMbb3AruB2ePUOQwcJ2lA0nTgTODoCerqph1IOl/SkKShkZGR9sURETGFDqkBB7YfB94NrAf+HtgOPD1Fda+z3bLdmjNnzlRUGRERY+hl8tnJs70SgPmlrGNM6ckcDuwar1LbX7R9su1TgS3A/RPU1U07IiKiQb1MPncAiyQtkDSD6qL/YFvMILCqTJ8N3Gzb41Uq6ajyPgu4ALhygroGgRVlNNwCYBHwrQPas4iIOCDTe1Wx7b2SVgM3AtOAq21vlrQWGLI9CFwFXCtpGHiMKkEBIGk7cBgwQ9KZwFLb9wEfkfSaErbW9mjPp2NdZZvXA/cBe4H32J6SU3UREbF/NEFH43mp1Wp5aGio382IiDikSNpou9VN7CE14CAiIp4bknwiIqJxST4REdG4JJ+IiGhcBhx0IGkE+KcDqOJI4NEpas5USrsmJ+2anLRrcp6L7TrGdlf/pZ/k0wOShrod8dGktGty0q7JSbsm5/nerpx2i4iIxiX5RERE45J8emNdvxswhrRrctKuyUm7Jud53a5c84mIiMal5xMREY1L8omIiObZzmuKXsAyqmcMDQNrerSNo4FbqO7SvRn4b6X8g1TPKbq7vH67ts6FpU1bgDdP1F5gAXB7KV8PzOiybduBe8r2h0rZy4CbgAfK+6xSLuCjZRubgNfV6llV4h8AVtXKTyz1D5d11UWbjqsdk7uBJ4A/6MfxAq4GfgDcWyvr+fEZaxsTtOtS4Ltl2zcAR5TyAeAnteP28f3d/nj7OE67ev5zA2aW+eGyfKCLdq2vtWk7cHcfjtdY3w19/4x1/H3oxRfk8/FF9diIrcCxwAzg28DiHmxn7uiHBHgp1cP0Fpdfyvd1iF9c2jKz/LJtLW0ds73A9cCKMv1x4N1dtm07cGRb2YdHf+GBNcAlZfq3gS+XX4BTgNtL+cuAbeV9Vpke/WX5VolVWff0/fgZfR84ph/HC3gD8Dr2/dLq+fEZaxsTtGspML1MX1Jr10A9rq2eSW1/rH2coF09/7lRPSfs42V6BbB+ona1Lf8z4OI+HK+xvhv6/hnruP+T/fLLa8wvtlOBG2vzFwIXNrDdLwCnjfNLuU87qJ6vdOpY7S0fqkd59otnn7gJ2rKdn08+W4C5ZXousKVMfwJY2R4HrAQ+USv/RCmbC3y3Vr5PXJftWwrcWqb7crxo+zJq4viMtY3x2tW27G3Ap8eL25/tj7WPExyvnv/cRtct09NLnMZrV61cwIPAon4cr7ZtjH43HBSfsfZXrvlMnXlUH7pRO0pZz0gaAF5LdWoAYLWkTZKuLk96Ha9dY5XPBn5oe29beTcMfEXSRknnl7KX2364TH8fePl+tmtemW4vn4wVwGdr8/0+XtDM8RlrG916B9VfuaMWSLpL0jckvb7W3sluf39/Z3r9c/vZOmX57hLfjdcDj9h+oFbW+PFq+244KD9jST6HKEkvAf4f8Ae2nwA+BrwSOAF4mKrr37TfsP064HTgPZLeUF/o6s8i96FdlEe5nwF8rhQdDMdrH00cn8luQ9JFVE8A/nQpehh4he3XAu8FPiPpsF5tv4OD7ufWZiX7/oHT+PHq8N1wQPVNVrfbSPKZOjupLviNml/KppykX6T6cH3a9ucBbD9i+2nbzwCfBE6aoF1jle8CjpA0va18QrZ3lvcfUF2kPgl4RNLc0u65VBdq96ddO8t0e3m3TgfutP1IaWPfj1fRxPEZaxvjkvR24C3A75UvFGzvsb2rTG+kup7yqv3c/qR/Zxr6uf1snbL88BI/rhL7O1SDD0bb2+jx6vTdsB/1NfIZS/KZOncAiyQtKH9lrwAGp3ojkgRcBXzH9p/XyufWwt4G3FumB4EVkmZKWgAsorpo2LG95UvmFuDssv4qqnPHE7XrxZJeOjpNdX3l3rL9VR3qGgTOVeUUYHfptt8ILJU0q5xSWUp1Lv5h4AlJp5RjcG437arZ5y/Sfh+vmiaOz1jbGJOkZcAfAWfY/nGtfI6kaWX62HJ8tu3n9sfax/Ha1cTPrd7es4GbR5PvBN5EdU3kZ6emmjxeY3037Ed9jXzGenox/Pn2oho9cj/VXzcX9Wgbv0HVpd1EbbgpcC3VEMhN5YMwt7bORaVNW6iNEBurvVQjg75FNZzyc8DMLtp1LNVIom9TDfO8qJTPBr5GNQTzq8DLSrmAK8q27wFatbreUbY9DPynWnmL6stmK3A5XQy1Luu9mOov18NrZY0fL6rk9zDwr1Tny89r4viMtY0J2jVMdd5/nyHCwFnl53s3cCfw1v3d/nj7OE67ev5zA15Q5ofL8mMnalcp/yvgXW2xTR6vsb4b+v4Z6/TK7XUiIqJxOe0WERGNS/KJiIjGJflERETjknwiIqJxST4REdG4JJ+IPpN0kaTN5ZYxd0s6WdIfSHpRv9sW0SsZah3RR5JOBf4c+C3beyQdSXX35X+g+r+LR/vawIgeSc8nor/mAo/a3gNQks3ZwL8BbpF0C4CkpZL+UdKdkj5X7t+FpO2SPizpHknfkrSwlP97SfdK+rakv+vPrkWMLT2fiD4qSeSbwIuo/jN8ve1vSNpO6fmU3tDnqf5r/0eS3k/13/hrS9wnbf+ppHOB37X9Fkn3AMts75R0hO0f9mUHI8aQnk9EH9l+kurpkOcDI8D6ckPPulOoHgp2q6S7qe6ddUxt+Wdr76eW6VuBv5L0TqoHqkUcVKZPHBIRvWT7aeDrwNdLj2VVW4iAm2yvHKuK9mnb75J0MvDvgI2STnS5u3LEwSA9n4g+knScpEW1ohOAfwL+hepRyAC3Ab9eu57zYkmvqq1zTu39H0vMK23fbvtiqh5V/Rb5EX2Xnk9Ef70E+AtJR1A9tG2Y6hTcSuBvJT1k+9+WU3GflTSzrPc/qO7UDDBL0iZgT1kP4NKS1ER1t+FvN7I3EV3KgIOIQ1h9YD4txH8AAAA2SURBVEK/2xIxGTntFhERjUvPJyIiGpeeT0RENC7JJyIiGpfkExERjUvyiYiIxiX5RERE4/4/WOSOocLGA3MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSGD_2imWDi"
      },
      "source": [
        "\n",
        "from tensorflow.keras.utils import Progbar\n",
        "progbar = Progbar(args.train_steps, verbose=1, interval=0.5)\n",
        "valid_inc = 20\n",
        "save_inc = 2000\n",
        "prev_grad_norm = np.float('inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTyriZrYowMJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "764ad610-7d66-4f68-a95e-b419ccd083f0"
      },
      "source": [
        "run_name = args.run_name\n",
        "model_path = str(STORAGE_PATH/'saved_models'/args.run_name)\n",
        "\n",
        "if args.resume:\n",
        "  # WandB reinit\n",
        "  with open(f'{model_path}/config.json', 'r') as f:\n",
        "      data = json.load(f)\n",
        "  # Comet ML reinit\n",
        "  exp = ExistingExperiment(api_key=\"C4vcCM57bnSYEsdncguxDW8pO\",  previous_experiment=data['experiment_key'])\n",
        "\n",
        "  wandb.init(project=\"learning-from-play_v2\", id=data['run_id'],  resume=\"must\")\n",
        "  t = wandb.run.step + valid_inc # Todo get this from comet to complete the transition\n",
        "\n",
        "  load_weights(model_path, actor, encoder, planner, with_optimizer=True)\n",
        "  print('Loaded model weights and optimiser state')\n",
        "  \n",
        "  prognar.add(t, []) # update the progbar to the most recent point\n",
        "else:\n",
        "  #Comet\n",
        "  experiment = Experiment(api_key=\"C4vcCM57bnSYEsdncguxDW8pO\",project_name=\"learning-from-play\",workspace=\"sholtodouglas\")\n",
        "  experiment.set_name(run_name)\n",
        "  # WandB\n",
        "  wandb.init(project=\"learning-from-play_v2\")\n",
        "  wandb.run.name = run_name\n",
        "  t = 0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/sholtodouglas/learning-from-play/d7a63e86757646d8933056f8ecb3cab5\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.21<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dark-microwave-233</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/2m0g2qgu\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/2m0g2qgu</a><br/>\n",
              "                Run data is saved locally in <code>/content/learning_from_play/wandb/run-20210309_233709-2m0g2qgu</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnc22FOGae1"
      },
      "source": [
        "from lfp.plotting import produce_cluster_fig, project_enc_and_plan, plot_to_image\n",
        "from lfp.metric import log # gets state and clears simultaneously"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjEkQ-OeXOVX"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3sybgPOU5Vv",
        "outputId": "38f4595b-cf51-49b6-f619-e4c15d590319"
      },
      "source": [
        "t = time.time()\r\n",
        "for i in range(0,10):\r\n",
        "  train_batch = next(train_dist_dataset)\r\n",
        "  trainer.distributed_train_step(train_batch, args.beta)\r\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.735045909881592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGGc3Uh-XI2-"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXF0Y8aKrsng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "546cd282-5919-4e81-dd4c-e6ac36cbd4ff"
      },
      "source": [
        "\n",
        "\n",
        "# Creating these autograph wrappers so that tf.data operations are executed in graph mode\n",
        "@tf.function\n",
        "def train(train_dataset, beta):\n",
        "    train_batch = next(train_dataset)\n",
        "    trainer.distributed_train_step(train_batch, beta)\n",
        "\n",
        "@tf.function\n",
        "def test(valid_dataset, beta):\n",
        "    valid_batch = next(valid_dataset)\n",
        "    trainer.distributed_test_step(valid_batch, beta)\n",
        "\n",
        "while t < args.train_steps:\n",
        "    start_time = time.time()\n",
        "    beta = beta_sched.scheduler(t)\n",
        "    train(train_dist_dataset, beta)\n",
        "\n",
        "    if t % valid_inc == 0:\n",
        "        test(valid_dist_dataset, beta)\n",
        "        step_time = round(time.time() - start_time, 1)\n",
        "\n",
        "        metrics = {metric_name: log(metric) for metric_name, metric in trainer.metrics.items()}\n",
        "        metrics['step_time'] = step_time\n",
        "\n",
        "        # validation plotting\n",
        "        progbar.add(valid_inc, [('Train Loss', metrics['train_loss']),\n",
        "                                ('Validation Loss', metrics['valid_loss']),\n",
        "                                ('Time (s)', step_time)])\n",
        "        #Plot on Comet\n",
        "        experiment.log_metrics(metrics,step=t)\n",
        "        # Plot on WandB\n",
        "        wandb.log(metrics, step=t)\n",
        "\n",
        "    if (t+1) % save_inc == 0:\n",
        "        trainer.save_weights(model_path, run_id=wandb.run.id, experiment_key=experiment.get_key())\n",
        "        if not args.gcbc and not args.images:\n",
        "          z_enc, z_plan = produce_cluster_fig(next(plotting_dataset), encoder, planner, TEST_DATA_PATHS[0], num_take=dl.batch_size//4)\n",
        "\n",
        "          #Comet\n",
        "          experiment.log_figure('z_enc', z_enc, step=t)\n",
        "          experiment.log_figure('z_plan', z_plan,step=t)\n",
        "\n",
        "          # WandB\n",
        "          wandb.log({'z_enc':z_enc, 'z_plan':z_plan}, step=t)\n",
        "\n",
        "          #latent_fig = project_enc_and_plan(ze, zp)\n",
        "          #latent_img = plot_to_image(latent_fig)\n",
        "\n",
        "    t += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    60/200000 [..............................] - ETA: 409:30:55 - Train Loss: 0.0339 - Validation Loss: 0.0255 - Time (s): 75.9667 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-86281f5d3dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_sched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dist_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalid_inc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw21h14BnX3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}