{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f27270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras import backend as Kb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(K.__version__)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcff2ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sholto/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: (60000, 28, 28, 1)\n",
      "Train labels: (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[:, :,:,tf.newaxis]\n",
    "x_test = x_test[:, :,:,tf.newaxis]\n",
    "print(\"Train images:\", x_train.shape)\n",
    "print(\"Train labels:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e1fbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(K.layers.Layer):  \n",
    "    def __init__(self, k, **kwargs):\n",
    "        super(VectorQuantizer, self).__init__(**kwargs)\n",
    "        self.k = k\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.d = int(input_shape[-1])\n",
    "        rand_init = K.initializers.VarianceScaling(distribution=\"uniform\")\n",
    "        self.codebook = self.add_weight(shape=(self.k, self.d), initializer=rand_init, trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Map z_e of shape (b, w,, h, d) to indices in the codebook\n",
    "        lookup_ = tf.reshape(self.codebook, shape=(1, 1, 1, self.k, self.d))\n",
    "        z_e = tf.expand_dims(inputs, -2)\n",
    "        dist = tf.norm(z_e - lookup_, axis=-1)\n",
    "        k_index = tf.argmin(dist, axis=-1)\n",
    "        return k_index\n",
    "    \n",
    "    def sample(self, k_index):\n",
    "        # Map indices array of shape (b, w, h) to actual codebook z_q\n",
    "        lookup_ = tf.reshape(self.codebook, shape=(1, 1, 1, self.k, self.d))\n",
    "        k_index_one_hot = tf.one_hot(k_index, self.k)\n",
    "        z_q = lookup_ * k_index_one_hot[..., None]\n",
    "        z_q = tf.reduce_sum(z_q, axis=-2)\n",
    "        return z_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e54878b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_LATENT_K = 10                 # Number of codebook entries\n",
    "NUM_LATENT_D = 64                 # Dimension of each codebook entries\n",
    "BETA = 1.0                        # Weight for the commitment loss\n",
    "\n",
    "INPUT_SHAPE = x_train.shape[1:]\n",
    "SIZE = None                       # Spatial size of latent embedding\n",
    "                                  # will be set dynamically in `build_vqvae\n",
    "\n",
    "VQVAE_BATCH_SIZE = 128            # Batch size for training the VQVAE\n",
    "VQVAE_NUM_EPOCHS = 20             # Number of epochs\n",
    "VQVAE_LEARNING_RATE = 3e-4        # Learning rate\n",
    "VQVAE_LAYERS = [16, 32]           # Number of filters for each layer in the encoder\n",
    "\n",
    "PIXELCNN_BATCH_SIZE = 128         # Batch size for training the PixelCNN prior\n",
    "PIXELCNN_NUM_EPOCHS = 10          # Number of epochs\n",
    "PIXELCNN_LEARNING_RATE = 3e-4     # Learning rate\n",
    "PIXELCNN_NUM_BLOCKS = 12          # Number of Gated PixelCNN blocks in the architecture\n",
    "PIXELCNN_NUM_FEATURE_MAPS = 32    # Width of each PixelCNN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8da6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_pass(inputs, d, num_layers=[16, 32]):\n",
    "    x = inputs\n",
    "    for i, filters in enumerate(num_layers):\n",
    "        x = K.layers.Conv2D(filters=filters, kernel_size=3, padding='SAME', activation='relu', \n",
    "                            strides=(2, 2), name=\"conv{}\".format(i + 1))(x)\n",
    "    z_e = K.layers.Conv2D(filters=d, kernel_size=3, padding='SAME', activation=None,\n",
    "                          strides=(1, 1), name='z_e')(x)\n",
    "    return z_e\n",
    "\n",
    "def decoder_pass(inputs, num_layers=[32, 16]):\n",
    "    y = inputs\n",
    "    for i, filters in enumerate(num_layers):\n",
    "        y = K.layers.Conv2DTranspose(filters=filters, kernel_size=4, strides=(2, 2), padding=\"SAME\", \n",
    "                                     activation='relu', name=\"convT{}\".format(i + 1))(y)\n",
    "    decoded = K.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), \n",
    "                                       padding=\"SAME\", activation='sigmoid', name='output')(y)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9c280c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vq-vae\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 14, 14, 16)   160         encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 7, 7, 32)     4640        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_e (Conv2D)                    (None, 7, 7, 64)     18496       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "vector_quantizer (VectorQuantiz (None, 7, 7)         640         z_e[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf.one_hot_8 (TFOpLambda)       (None, 7, 7, 10)     0           vector_quantizer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_10 (Sl (None, 7, 7, 10, 1)  0           tf.one_hot_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_8 (TFOpLambda) (None, 7, 7, 10, 64) 0           tf.__operators__.getitem_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_8 (TFOpLambd (None, 7, 7, 64)     0           tf.math.multiply_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "straight_through_estimator (Lam (None, 7, 7, 64)     0           tf.math.reduce_sum_8[0][0]       \n",
      "                                                                 z_e[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_4 (TFOpLambda)         (None, 7, 7, 64, 2)  0           z_e[0][0]                        \n",
      "                                                                 tf.math.reduce_sum_8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 28, 28, 1)    41153       straight_through_estimator[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "latent_codes (Lambda)           (None, 7, 7, 64, 2)  0           tf.stack_4[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_vqvae(k, d, input_shape=(28, 28, 1), num_layers=[16, 32]):\n",
    "    global SIZE\n",
    "    ## Encoder\n",
    "    encoder_inputs = K.layers.Input(shape=input_shape, name='encoder_inputs')\n",
    "    z_e = encoder_pass(encoder_inputs, d, num_layers=num_layers)\n",
    "    SIZE = int(z_e.get_shape()[1])\n",
    "\n",
    "    ## Vector Quantization\n",
    "    vector_quantizer = VectorQuantizer(k, name=\"vector_quantizer\")\n",
    "    codebook_indices = vector_quantizer(z_e)\n",
    "    encoder = K.Model(inputs=encoder_inputs, outputs=codebook_indices, name='encoder')\n",
    "\n",
    "    ## Decoder\n",
    "    decoder_inputs = K.layers.Input(shape=(SIZE, SIZE, d), name='decoder_inputs')\n",
    "    decoded = decoder_pass(decoder_inputs, num_layers=num_layers[::-1])\n",
    "    decoder = K.Model(inputs=decoder_inputs, outputs=decoded, name='decoder')\n",
    "    \n",
    "    ## VQVAE Model (training)\n",
    "#     sampling_layer = K.layers.Lambda(lambda x: vector_quantizer.sample(x), name=\"sample_from_codebook\")\n",
    "    z_q = vector_quantizer.sample(codebook_indices)\n",
    "    codes = tf.stack([z_e, z_q], axis=-1)\n",
    "    codes = K.layers.Lambda(lambda x: x, name='latent_codes')(codes)\n",
    "    straight_through = K.layers.Lambda(lambda x : x[1] + tf.stop_gradient(x[0] - x[1]), name=\"straight_through_estimator\")\n",
    "    straight_through_zq = straight_through([z_q, z_e])\n",
    "    reconstructed = decoder(straight_through_zq)\n",
    "    vq_vae = K.Model(inputs=encoder_inputs, outputs=[reconstructed, codes], name='vq-vae')\n",
    "    \n",
    "    ## VQVAE model (inference)\n",
    "    codebook_indices = K.layers.Input(shape=(SIZE, SIZE), name='discrete_codes', dtype=tf.int32)\n",
    "    z_q = vector_quantizer.sample(codebook_indices)\n",
    "    generated = decoder(z_q)\n",
    "    vq_vae_sampler = K.Model(inputs=codebook_indices, outputs=generated, name='vq-vae-sampler')\n",
    "    \n",
    "    ## Transition from codebook indices to model (for training the prior later)\n",
    "    indices = K.layers.Input(shape=(SIZE, SIZE), name='codes_sampler_inputs', dtype='int32')\n",
    "    z_q = vector_quantizer.sample(indices)\n",
    "    codes_sampler = K.Model(inputs=indices, outputs=z_q, name=\"codes_sampler\")\n",
    "    \n",
    "    ## Getter to easily access the codebook for vizualisation\n",
    "    indices = K.layers.Input(shape=(), dtype='int32')\n",
    "    vector_model = K.Model(inputs=indices, outputs=vector_quantizer.sample(indices[:, None, None]), name='get_codebook')\n",
    "    def get_vq_vae_codebook():\n",
    "        codebook = vector_model.predict(np.arange(k))\n",
    "        codebook = np.reshape(codebook, (k, d))\n",
    "        return codebook\n",
    "    \n",
    "    return vq_vae, vq_vae_sampler, encoder, decoder, codes_sampler, get_vq_vae_codebook\n",
    "\n",
    "vq_vae, vq_vae_sampler, encoder, decoder, codes_sampler, get_vq_vae_codebook = build_vqvae(\n",
    "    NUM_LATENT_K, NUM_LATENT_D, input_shape=INPUT_SHAPE, num_layers=VQVAE_LAYERS)\n",
    "vq_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08e99c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(ground_truth, predictions):\n",
    "    mse_loss = tf.reduce_mean((ground_truth - predictions)**2, name=\"mse_loss\")\n",
    "    return mse_loss\n",
    "\n",
    "def latent_loss(dummy_ground_truth, outputs):\n",
    "    global BETA\n",
    "    del dummy_ground_truth\n",
    "    z_e, z_q = tf.split(outputs, 2, axis=-1)\n",
    "    vq_loss = tf.reduce_mean((tf.stop_gradient(z_e) - z_q)**2)\n",
    "    commit_loss = tf.reduce_mean((z_e - tf.stop_gradient(z_q))**2)\n",
    "    latent_loss = tf.identity(vq_loss + BETA * commit_loss, name=\"latent_loss\")\n",
    "    return latent_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "685cf4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zq_norm(y_true, y_pred):\n",
    "    del y_true\n",
    "    _, z_q = tf.split(y_pred, 2, axis=-1)\n",
    "    return tf.reduce_mean(tf.norm(z_q, axis=-1))\n",
    "\n",
    "def ze_norm(y_true, y_pred):\n",
    "    del y_true\n",
    "    z_e, _ = tf.split(y_pred, 2, axis=-1)\n",
    "    return tf.reduce_mean(tf.norm(z_e, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76458c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-40-6f5cf717b114>:2 mse_loss  *\n        mse_loss = tf.reduce_mean((ground_truth - predictions)**2, name=\"mse_loss\")\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\n        raise e\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:548 subtract\n        return gen_math_ops.sub(x, y, name)\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10561 sub\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:555 _apply_op_helper\n        raise TypeError(\n\n    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type uint8 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-42d135781b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Compile and train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvq_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"latent_codes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mzq_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mze_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVQVAE_LEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvq_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVQVAE_NUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVQVAE_BATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-40-6f5cf717b114>:2 mse_loss  *\n        mse_loss = tf.reduce_mean((ground_truth - predictions)**2, name=\"mse_loss\")\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper\n        raise e\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:548 subtract\n        return gen_math_ops.sub(x, y, name)\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10561 sub\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/sholto/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:555 _apply_op_helper\n        raise TypeError(\n\n    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type uint8 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "## Compile and train\n",
    "vq_vae.compile(loss=[mse_loss, latent_loss], metrics={\"latent_codes\": [zq_norm, ze_norm]}, optimizer= K.optimizers.Adam(VQVAE_LEARNING_RATE))\n",
    "history = vq_vae.fit(x_train, x_train, epochs=VQVAE_NUM_EPOCHS, batch_size=VQVAE_BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3a975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
