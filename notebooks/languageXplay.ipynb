{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LMP Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G84fGXVwv9Fh",
        "-yC0L1P3v9GA",
        "8SHQGBjnv9GK",
        "b7CMny5dv9Gx",
        "njbQpQAGv9G2"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be74d16c8329407eb38e6f4e80ea6da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5f5ce3be06e64bd389df5c7260a7dec3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7461dd9f543d4d7abcbb69e48655f745",
              "IPY_MODEL_d0ef3b057ca94d72baaaa07849c50912"
            ]
          }
        },
        "5f5ce3be06e64bd389df5c7260a7dec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7461dd9f543d4d7abcbb69e48655f745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_5f13710b899a42cd9ec5ce8d394e30af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6895c85f86fc48baa96eafaa070c7265"
          }
        },
        "d0ef3b057ca94d72baaaa07849c50912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_046dec87dce043ef8978fcbb329c4148",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed4076ca6d904c3d9d17e22f3a3e0c6c"
          }
        },
        "5f13710b899a42cd9ec5ce8d394e30af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6895c85f86fc48baa96eafaa070c7265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "046dec87dce043ef8978fcbb329c4148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed4076ca6d904c3d9d17e22f3a3e0c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/languageXplay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xchjk_eKp26Q"
      },
      "source": [
        "#@title Install package dependencies (forces restart)\n",
        "import os\n",
        "\n",
        "def restart_runtime():\n",
        "    print('Runtime restarting...')\n",
        "    os.kill(os.getpid(), 9)\n",
        "    \n",
        "!git clone 'https://github.com/sholtodouglas/pandaRL' 'local_packages/pandaRL'\n",
        "!pip install -e 'local_packages/pandaRL/.'\n",
        "\n",
        "restart_runtime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUYgZwpGfav",
        "outputId": "deea0536-18b7-4b1f-fb52-8c782f8f6d30"
      },
      "source": [
        "!pip -q install pybullet wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76.6MB 92kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 61.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 11.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 60.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 11.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 60.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 8.9MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMJ___6ARZ4u",
        "outputId": "70d36ec5-e3d7-495d-d399-62c27f7f743e"
      },
      "source": [
        "#@title Workpace Setup (Local vs Colab)\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "COLAB = True #@param {type:\"boolean\"}\n",
        "AUTH_GCS = False #@param {type:\"boolean\"}\n",
        "DEVICE = \"TPU\" #@param [\"TPU\", \"GPU\", \"CPU\"]\n",
        "DATA_SOURCE = \"Google Drive\" #@param [\"Google Drive\", \"GCS\"]\n",
        "TEST_DATASET = \"UR5_slow_gripper_test\" #@param [\"UR5_slow_gripper_test\"]\n",
        "GCS_USER = \"sholto\" #@param [\"sholto\", \"tristan\"]\n",
        "\n",
        "if COLAB:\n",
        "    from google.colab import drive, auth\n",
        "    print('Using colab setup')\n",
        "    !git clone 'https://github.com/sholtodouglas/learning_from_play'\n",
        "    WORKING_PATH = Path('/content/learning_from_play')\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir(WORKING_PATH)\n",
        "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
        "    print(f'Storage path: {STORAGE_PATH}')\n",
        "    \n",
        "    TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in [\"UR5\",\"UR5_slow_gripper\",\"UR5_high_transition\"]]\n",
        "    TEST_DATA_PATH = STORAGE_PATH/'data'/TEST_DATASET\n",
        "\n",
        "else:\n",
        "    print('Using local setup')\n",
        "    WORKING_PATH = Path().absolute().parent\n",
        "    print(f'Working path: {WORKING_PATH}')\n",
        "    os.chdir(WORKING_PATH)\n",
        "    STORAGE_PATH = WORKING_PATH\n",
        "    print(f'Storage path: {STORAGE_PATH}')\n",
        "    \n",
        "    TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in [\"UR5\", \"UR5_high_transition\", \"UR5_slow_gripper\"]]\n",
        "    TEST_DATA_PATH = STORAGE_PATH/'data'/TEST_DATASET"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab setup\n",
            "Cloning into 'learning_from_play'...\n",
            "remote: Enumerating objects: 287, done.\u001b[K\n",
            "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
            "remote: Compressing objects: 100% (234/234), done.\u001b[K\n",
            "remote: Total 1203 (delta 177), reused 115 (delta 53), pack-reused 916\u001b[K\n",
            "Receiving objects: 100% (1203/1203), 52.41 MiB | 31.04 MiB/s, done.\n",
            "Resolving deltas: 100% (592/592), done.\n",
            "Mounted at /content/drive\n",
            "Storage path: /content/drive/My Drive/Robotic Learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EliqxOpPv9Dy"
      },
      "source": [
        "# Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zbmq324x2yv",
        "outputId": "715a8265-e588-47f8-a5b5-4546c60eeba9"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "if DEVICE == \"TPU\":\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
        "    print(\"REPLICAS: \", NUM_DEVICES)\n",
        "else:\n",
        "    physical_devices = tf.config.list_physical_devices()\n",
        "    if DEVICE == 'GPU':\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
        "    NUM_DEVICES = 1\n",
        "    print(physical_devices)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.31.128.106:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.31.128.106:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.31.128.106:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL0UZVa1v9D9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF1m_wf3v9D-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import lfp\n",
        "from natsort import natsorted"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HejtDH_Yx8h",
        "outputId": "2086d0b7-2d9d-4788-f834-c2a96964f9ae"
      },
      "source": [
        "# Use this to edit modules without needing to restart the kernel\n",
        "import importlib\n",
        "importlib.reload(lfp.data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'lfp.data' from '/content/learning_from_play/lfp/data.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI6JP06FdTv"
      },
      "source": [
        "### Config Flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt67o9mj6Hc7"
      },
      "source": [
        "LAYER_SIZE = 2048\n",
        "LATENT_DIM = LAYER_SIZE//8\n",
        "GRIPPER_WEIGHT = 1.0\n",
        "GCBC = False\n",
        "PROBABILISTIC = False\n",
        "INFO_VAE = False\n",
        "QUANTISED = False\n",
        "N_QUANTISATIONS = 256"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lBWIyOFdTv"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_DEVICES\n",
        "dataloader = lfp.data.PlayDataloader(batch_size=BATCH_SIZE*NUM_DEVICES)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiz4AXCnFdTv",
        "outputId": "0da944f0-c340-49ff-f5c9-06c159ba4c93"
      },
      "source": [
        "train_data = dataloader.extract(TRAIN_DATA_PATHS)\n",
        "valid_data = dataloader.extract([TEST_DATA_PATH])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "636298 frames, which is 7hrs 4m.\n",
            "15396 frames, which is 0hrs 10m.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ZDAVpLFdTw",
        "outputId": "1c2b4f81-ea35-4f12-c365-3163f8704388"
      },
      "source": [
        "train_dataset = dataloader.load(train_data)\n",
        "valid_dataset = dataloader.load(valid_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'obs': TensorSpec(shape=(4096, 50, 18), dtype=tf.float32, name=None), 'acts': TensorSpec(shape=(4096, 50, 7), dtype=tf.float32, name=None), 'goals': TensorSpec(shape=(4096, 50, 11), dtype=tf.float32, name=None), 'seq_lens': TensorSpec(shape=(4096,), dtype=tf.float32, name=None), 'masks': TensorSpec(shape=(4096, 50), dtype=tf.float32, name=None), 'dataset_path': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None), 'tstep_idxs': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None)}\n",
            "{'obs': TensorSpec(shape=(4096, 50, 18), dtype=tf.float32, name=None), 'acts': TensorSpec(shape=(4096, 50, 7), dtype=tf.float32, name=None), 'goals': TensorSpec(shape=(4096, 50, 11), dtype=tf.float32, name=None), 'seq_lens': TensorSpec(shape=(4096,), dtype=tf.float32, name=None), 'masks': TensorSpec(shape=(4096, 50), dtype=tf.float32, name=None), 'dataset_path': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None), 'tstep_idxs': TensorSpec(shape=(4096, None, 1), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN3YJSSLv9Ez",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWMloXYWv9Ez",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, ReLU, Input, LSTM, Concatenate, Masking, Reshape, Lambda, Bidirectional, GRU, LayerNormalization\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "tfpl = tfp.layers\n",
        "from lfp.custom_layers import LearnedInitLSTM, LearnedInitGRU\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyCTWom6v9E3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## LSTM Model\n",
        "Use this to map obs -> act"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaQklDgMGRhZ"
      },
      "source": [
        "#Scales the neurons to make them the appropriate magnitude for the quantised integer outputs, should mean massive weights aren't required\n",
        "scaling = find_quantisation_scaling(dataset, dataloader, num_quantiles=N_QUANTISATIONS) if QUANTISED else None\n",
        "\n",
        "def latent_normal(inputs):\n",
        "    mu, scale = inputs\n",
        "    dist = tfd.Normal(loc=mu, scale=scale)\n",
        "    return dist\n",
        "\n",
        "\n",
        "def logistic_mixture(inputs):\n",
        "    weightings, mu, scale = inputs\n",
        "    if QUANTISED:\n",
        "      mu = mu * np.expand_dims(scaling,1)\n",
        "      dist = tfd.Logistic(loc=mu, scale=scale)\n",
        "      dist = tfd.QuantizedDistribution(\n",
        "                distribution=tfd.TransformedDistribution(\n",
        "                    distribution=dist,\n",
        "                    bijector=tfb.Shift(shift=-0.5)),\n",
        "                low=-N_QUANTISATIONS/2.,\n",
        "                high=N_QUANTISATIONS/2.\n",
        "            )\n",
        "    else:\n",
        "      dist = tfd.Logistic(loc=mu, scale=scale)\n",
        "\n",
        "    mixture_dist = tfd.MixtureSameFamily(\n",
        "        mixture_distribution=tfd.Categorical(logits=weightings),\n",
        "        components_distribution=dist,\n",
        "        validate_args=True\n",
        "    )\n",
        "\n",
        "    if QUANTISED:\n",
        "      quantized_scale = 1/scaling # update this to being between the action range\n",
        "      mixture_dist = tfd.TransformedDistribution(\n",
        "          distribution=mixture_dist,\n",
        "          bijector=tfb.Scale(scale=quantized_scale)\n",
        "      )\n",
        "\n",
        "    return mixture_dist\n",
        "\n",
        "def create_actor(layer_size=1024, latent_dim = 256, epsilon=1e-4, num_distribs=None, GCBC=False, training=True, return_state=False):\n",
        "    # params #\n",
        "    batch_size = None if training else 1\n",
        "    stateful = not training\n",
        "\n",
        "    # Input #\n",
        "    o = Input(shape=(None, dataloader.obs_dim), batch_size=batch_size, dtype=tf.float32, name='input_obs')\n",
        "    z = Input(shape=(None, latent_dim), batch_size=batch_size, dtype=tf.float32, name='input_latent')\n",
        "    g = Input(shape=(None, dataloader.goal_dim), batch_size=batch_size, dtype=tf.float32, name='input_goals')\n",
        "\n",
        "    # RNN #\n",
        "    if GCBC:      \n",
        "      x =  Concatenate(axis=-1)([o,g])\n",
        "    else:\n",
        "      x =  Concatenate(axis=-1)([o,z,g])\n",
        "\n",
        "    x = Masking(mask_value=0.)(x)\n",
        "    if return_state:\n",
        "#         x, _, state1 = LearnedInitLSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_1', return_state=return_state)(x)\n",
        "#         x, _, state2= LearnedInitLSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_2', return_state=return_state)(x)\n",
        "        x, _, state1 = LSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_1', return_state=return_state)(x)\n",
        "        x, _, state2= LSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_2', return_state=return_state)(x)\n",
        "    else:\n",
        "#         x = LearnedInitLSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_1', return_state=return_state)(x)\n",
        "#         x = LearnedInitLSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_2', return_state=return_state)(x)\n",
        "        x = LSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_1', return_state=return_state)(x)\n",
        "        x = LSTM(layer_size, return_sequences=True, stateful=stateful, name='LSTM_in_2', return_state=return_state)(x)\n",
        "    # Probabilistic Mixture Model #\n",
        "    if num_distribs:\n",
        "        weightings = Dense(dataloader.act_dim*num_distribs, activation=None, name='alpha')(x)\n",
        "        mu = Dense(dataloader.act_dim*num_distribs, activation=None, name='mu')(x)\n",
        "        scale = Dense(dataloader.act_dim*num_distribs, activation=\"softplus\", name='sigma')(x + epsilon)\n",
        "\n",
        "        weightings = Reshape((-1, dataloader.act_dim, num_distribs))(weightings)\n",
        "        mu = Reshape((-1, dataloader.act_dim, num_distribs))(mu)\n",
        "        scale = Reshape((-1, dataloader.act_dim, num_distribs))(scale)\n",
        "        \n",
        "        actions = tfpl.DistributionLambda(logistic_mixture, name='logistic_mix')([weightings, mu, scale])\n",
        "    else:\n",
        "        actions = Dense(dataloader.act_dim, activation=None, name='acts')(x)\n",
        "    \n",
        "    if return_state:\n",
        "        if GCBC:\n",
        "          return Model([o, g], [actions, state1, state2])\n",
        "        else:\n",
        "          return Model([o, z, g], [actions, state1, state2])\n",
        "    else:\n",
        "        if GCBC:\n",
        "          return Model([o, g], actions)\n",
        "        else:\n",
        "          return Model([o, z, g], actions)\n",
        "\n",
        "    \n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "\n",
        "def create_encoder(layer_size=2048, latent_dim = 256, epsilon=1e-4, training=True):\n",
        "    # Input #\n",
        "    obs = Input(shape=(None, dataloader.obs_dim), dtype=tf.float32, name='obs')\n",
        "    acts = Input(shape=(None, dataloader.act_dim), dtype=tf.float32, name='acts') \n",
        "\n",
        "    # Layers #\n",
        "    x = Concatenate(axis=-1)([obs, acts])\n",
        "    x = Masking(mask_value=0.)(x)\n",
        "    x = Bidirectional(LSTM(layer_size//4, return_sequences=True), merge_mode='concat')(x)\n",
        "    x = Bidirectional(LSTM(layer_size//4, return_sequences=False), merge_mode='concat')(x)\n",
        "\n",
        "    # Latent Variable # \n",
        "    mu = Dense(latent_dim, activation=None, name='mu')(x)\n",
        "    scale = Dense(latent_dim, activation=\"softplus\", name='sigma')(x + epsilon)\n",
        "    \n",
        "    mixture = tfpl.DistributionLambda(latent_normal, name='latent_variable')((mu, scale))\n",
        "    return Model([obs, acts], mixture)\n",
        "\n",
        "\n",
        "def create_planner(layer_size=2048, latent_dim = 256, epsilon=1e-4, training=True):\n",
        "    # params #\n",
        "    batch_size = None\n",
        "\n",
        "    # Input #\n",
        "    o_i = Input(shape=(dataloader.obs_dim,), batch_size=batch_size, dtype=tf.float32, name='initial_obs') # has arm state\n",
        "    o_g = Input(shape=(dataloader.goal_dim,), batch_size=batch_size, dtype=tf.float32, name='goal_obs') # does not have arm state\n",
        "\n",
        "    # Layers #\n",
        "    x = Concatenate(axis=-1)([o_i, o_g])\n",
        "    x = Masking(mask_value=0.)(x)\n",
        "    x = Dense(layer_size//4, activation=\"relu\", name='layer_1')(x)\n",
        "    x = Dense(layer_size//4, activation=\"relu\", name='layer_2')(x)\n",
        "    x = Dense(layer_size//4, activation=\"relu\", name='layer_3')(x)\n",
        "    x = Dense(layer_size//4, activation=\"relu\", name='layer_4')(x)\n",
        "\n",
        "    # Latent Variable # \n",
        "    mu = Dense(latent_dim, activation=None, name='mu')(x)\n",
        "    scale = Dense(latent_dim, activation=\"softplus\", name='sigma')(x + epsilon)\n",
        "    \n",
        "    mixture = tfpl.DistributionLambda(latent_normal,  name='latent_variable')((mu, scale))\n",
        "    return Model([o_i, o_g], mixture)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpRPRuv9E6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "-3r_TDl7v9E7",
        "outputId": "4d1c4395-df80-4fe7-c24c-ea983bca6560"
      },
      "source": [
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import Progbar\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import time\n",
        "import io\n",
        "import wandb\n",
        "wandb.login()\n",
        "#%load_ext tensorboard"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqmqTTIrJgHc"
      },
      "source": [
        "class MaxMetric(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name='max_metric', **kwargs):\n",
        "    super(MaxMetric, self).__init__(name=name, **kwargs)\n",
        "    self.max = self.add_weight(name='max', initializer='zeros')\n",
        "    self.abs_err = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, mask=1.0):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    values = self.abs_err(y_true, y_pred) * mask\n",
        "    values = tf.cast(values, self.dtype)\n",
        "    max = tf.reduce_max(values)\n",
        "    if tf.math.greater(max, self.max):\n",
        "        self.max.assign(max)\n",
        "\n",
        "  def result(self):\n",
        "    return self.max"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWSGFva71ShC"
      },
      "source": [
        "\n",
        "#Info VAE stuff\n",
        "def compute_kernel(x, y):\n",
        "    x_size = tf.shape(x)[0]\n",
        "    y_size = tf.shape(y)[0]\n",
        "    dim = tf.shape(x)[1]\n",
        "    tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])), tf.stack([1, y_size, 1]))\n",
        "    tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])), tf.stack([x_size, 1, 1]))\n",
        "    return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))\n",
        "\n",
        "def compute_mmd(x, y):\n",
        "    x_kernel = compute_kernel(x, x)\n",
        "    y_kernel = compute_kernel(y, y)\n",
        "    xy_kernel = compute_kernel(x, y)\n",
        "    return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vDui_2XGhZW"
      },
      "source": [
        "\n",
        "\n",
        "with strategy.scope():\n",
        "  nll_action_loss = lambda y, p_y: tf.reduce_sum(-p_y.log_prob(y), axis=2)\n",
        "  mae_action_loss = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "  mse_action_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "  def compute_loss(labels, predictions, mask, seq_lens, weightings=None):\n",
        "      if PROBABILISTIC:\n",
        "        per_example_loss = nll_action_loss(labels, predictions) * mask\n",
        "      else:\n",
        "        per_example_loss = mae_action_loss(labels, predictions) * mask\n",
        "\n",
        "      per_example_loss = tf.reduce_sum(per_example_loss, axis = 1) / seq_lens # take mean along the timestep\n",
        "      return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "  def compute_MAE(labels, predictions, mask, seq_lens, weightings=None):\n",
        "      per_example_loss = mae_action_loss(labels, predictions) * mask\n",
        "      per_example_loss = tf.reduce_sum(per_example_loss, axis = 1) / seq_lens # take mean along the timestep\n",
        "      return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "  def compute_regularisation_loss(plan, encoding):\n",
        "      # Reverse KL(enc|plan): we want planner to map to encoder (weighted by encoder)\n",
        "      reg_loss = tfd.kl_divergence(encoding, plan) #+ KL(plan, encoding)\n",
        "      return tf.nn.compute_average_loss(reg_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "  actor_grad_norm =  tf.keras.metrics.Mean(name='actor_grad_norm')\n",
        "  encoder_grad_norm =  tf.keras.metrics.Mean(name='encoder_grad_norm')\n",
        "  planner_grad_norm =  tf.keras.metrics.Mean(name='planner_grad_norm')\n",
        "\n",
        "  actor_grad_norm_clipped =  tf.keras.metrics.Mean(name='actor_grad_norm_clipped')\n",
        "  encoder_grad_norm_clipped =  tf.keras.metrics.Mean(name='encoder_grad_norm_clipped')\n",
        "  planner_grad_norm_clipped =  tf.keras.metrics.Mean(name='planner_grad_norm_clipped')\n",
        "\n",
        "  global_grad_norm =  tf.keras.metrics.Mean(name='global_grad_norm')\n",
        "\n",
        "  test = tf.keras.metrics.Mean(name='test')\n",
        "  test2 = tf.keras.metrics.Mean(name='test2')\n",
        "\n",
        "  train_act_with_enc_loss = tf.keras.metrics.Mean(name='train_act_with_enc_loss')\n",
        "  train_act_with_plan_loss = tf.keras.metrics.Mean(name='train_act_with_plan_loss')\n",
        "  valid_act_with_enc_loss = tf.keras.metrics.Mean(name='valid_act_with_enc_loss')\n",
        "  valid_act_with_plan_loss = tf.keras.metrics.Mean(name='valid_act_with_plan_loss')\n",
        "\n",
        "  train_reg_loss = tf.keras.metrics.Mean(name='reg_loss')\n",
        "  valid_reg_loss = tf.keras.metrics.Mean(name='valid_reg_loss')\n",
        "  if INFO_VAE:\n",
        "    train_mmd_reg_loss = tf.keras.metrics.Mean(name='train_mmd_reg_loss')\n",
        "    valid_mmd_reg_loss = tf.keras.metrics.Mean(name='valid_mmd_reg_loss')\n",
        "\n",
        "\n",
        "  valid_position_loss = tf.keras.metrics.Mean(name='valid_position_loss')\n",
        "  valid_max_position_loss = MaxMetric(name='valid_max_position_loss')\n",
        "  valid_rotation_loss = tf.keras.metrics.Mean(name='valid_rotation_loss')\n",
        "  valid_max_rotation_loss = MaxMetric(name='valid_max_rotation_loss')\n",
        "  valid_gripper_loss = tf.keras.metrics.Mean(name='valid_rotation_loss')\n",
        "  \n",
        "  model_params = {'layer_size':LAYER_SIZE, 'latent_dim':LATENT_DIM}\n",
        "  if PROBABILISTIC:\n",
        "    actor = create_actor(**model_params, GCBC=GCBC, num_distribs=3)\n",
        "    \n",
        "  else:\n",
        "    actor = create_actor(**model_params, GCBC=GCBC)\n",
        "    \n",
        "  actor_grad_len  = len(actor.trainable_variables)\n",
        "  if GCBC:\n",
        "    encoder = None\n",
        "    planner = None\n",
        "  else:\n",
        "    encoder = create_encoder(**model_params)\n",
        "    planner = create_planner(**model_params)\n",
        "    encoder_grad_len = len(encoder.trainable_variables)\n",
        "    planner_grad_len = len(planner.trainable_variables)\n",
        "\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=3e-4)\n",
        "  trainable_variables = actor.trainable_variables+encoder.trainable_variables+planner.trainable_variables\n",
        "  checkpoint = tf.train.Checkpoint(encoder=encoder,\n",
        "                           planner=planner,\n",
        "                           actor=actor,\n",
        "                           optimizer = optimizer)\n",
        "\n",
        "# Now outside strategy .scope\n",
        "def train_step(inputs, beta, prev_global_grad_norm):\n",
        "  with tf.GradientTape() as tape, tf.GradientTape() as planner_tape: # separate planner tape for INFO VAE\n",
        "    # Todo: figure out mask and seq_lens for new dataset \n",
        "    states, actions, goals, seq_lens, mask = inputs['obs'], inputs['acts'], inputs['goals'], inputs['seq_lens'], inputs['masks']\n",
        "    action_weights = (dataloader.act_dim-1)*[1.0] + [GRIPPER_WEIGHT] # 1 for all but gripper\n",
        "    if GCBC:\n",
        "      distrib = actor([states, goals])\n",
        "      loss = compute_loss(actions, distrib, mask, seq_lens, weightings=action_weights)\n",
        "      gradients = tape.gradient(loss, actor.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, actor.trainable_variables))\n",
        "    else:\n",
        "      encoding = encoder([states, actions])\n",
        "      plan = planner([states[:, 0, :], goals[:, 0, :]])  # the final goals are tiled out over the entire non masked sequence, so the first timestep is the final goal. \n",
        "      z_enc = encoding.sample()\n",
        "      z_plan = plan.sample()\n",
        "      z_enc_tiled = tf.tile(tf.expand_dims(z_enc, 1), (1, dataloader.window_size, 1))\n",
        "      z_plan_tiled = tf.tile(tf.expand_dims(z_plan, 1), (1, dataloader.window_size, 1))\n",
        "\n",
        "      enc_policy = actor([states, z_enc_tiled, goals])\n",
        "      plan_policy = actor([states, z_plan_tiled, goals])\n",
        "\n",
        "      act_enc_loss = compute_loss(actions, enc_policy, mask, seq_lens, weightings=action_weights)\n",
        "      act_plan_loss = compute_loss(actions, plan_policy, mask, seq_lens, weightings=action_weights)\n",
        "      act_loss = act_enc_loss\n",
        "      \n",
        "      if INFO_VAE:\n",
        "        true_samples = tf.keras.backend.random_normal(tf.stack([z_enc.shape[0], LATENT_DIM]))\n",
        "        reg_loss = compute_mmd(true_samples, z_enc)\n",
        "        train_mmd_reg_loss.update_state(reg_loss)\n",
        "        plan_chase_enc = compute_regularisation_loss(plan, encoding)\n",
        "        train_reg_loss.update_state(plan_chase_enc)\n",
        "      else:\n",
        "        reg_loss = compute_regularisation_loss(plan, encoding)\n",
        "        train_reg_loss.update_state(reg_loss)\n",
        "      train_act_with_enc_loss.update_state(act_enc_loss)\n",
        "      train_act_with_plan_loss.update_state(act_plan_loss)\n",
        "      \n",
        "      loss = act_loss + reg_loss * beta\n",
        "\n",
        "      if INFO_VAE:\n",
        "        gradients = tape.gradient(loss, actor.trainable_variables+encoder.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, actor.trainable_variables+encoder.trainable_variables))\n",
        "        gradients = planner_tape.gradient(plan_chase_enc, planner.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, planner.trainable_variables))\n",
        "\n",
        "      else:\n",
        "\n",
        "          \n",
        "        gradients = tape.gradient(loss, trainable_variables)\n",
        "        #print(gradients)\n",
        "        actor_norm = tf.linalg.global_norm(gradients[:actor_grad_len])\n",
        "        encoder_norm = tf.linalg.global_norm(gradients[actor_grad_len:actor_grad_len+encoder_grad_len])\n",
        "        planner_norm = tf.linalg.global_norm(gradients[actor_grad_len+encoder_grad_len:actor_grad_len+encoder_grad_len+planner_grad_len])\n",
        "        actor_grad_norm.update_state(actor_norm)\n",
        "        encoder_grad_norm.update_state(encoder_norm)\n",
        "        planner_grad_norm.update_state(planner_norm)\n",
        "\n",
        "        \n",
        "        #scale planner gradients\n",
        "        \n",
        "\n",
        "        # if the gradient norm is more than 3x the previous one, clip it to the previous norm for stability\n",
        "        gradients = tf.cond(tf.linalg.global_norm(gradients) > 3*prev_global_grad_norm, lambda: tf.clip_by_global_norm(gradients, prev_global_grad_norm)[0], lambda: gradients) #must get[0] as it returns new norm as [1]\n",
        "        #gradients = tf.cond(sum_of_norms > 3*prev_global_grad_norm, lambda: [tf.clip_by_norm(g, prev_global_grad_norm) for g in gradients], lambda: gradients)\n",
        "        #test2.update_state(tf.linalg.global_norm(gradients))\n",
        "        #test.update_state(tf.linalg.global_norm(gradients[actor_grad_len+encoder_grad_len:actor_grad_len+encoder_grad_len+planner_grad_len]))\n",
        "        #make the planner converge more quickly\n",
        "        planner_grads = gradients[actor_grad_len+encoder_grad_len:actor_grad_len+encoder_grad_len+planner_grad_len]\n",
        "        \n",
        "        planner_grads = [g * 10 for g in planner_grads]\n",
        "        gradients = gradients[:actor_grad_len] + gradients[actor_grad_len:actor_grad_len+encoder_grad_len] + planner_grads\n",
        "        #test2.update_state(tf.linalg.global_norm(gradients[actor_grad_len+encoder_grad_len:actor_grad_len+encoder_grad_len+planner_grad_len]))\n",
        "\n",
        "        actor_norm_clipped = tf.linalg.global_norm(gradients[:actor_grad_len])\n",
        "        encoder_norm_clipped = tf.linalg.global_norm(gradients[actor_grad_len:actor_grad_len+encoder_grad_len])\n",
        "        planner_norm_clipped = tf.linalg.global_norm(gradients[actor_grad_len+encoder_grad_len:actor_grad_len+encoder_grad_len+planner_grad_len])\n",
        "        actor_grad_norm_clipped.update_state(actor_norm_clipped)\n",
        "        encoder_grad_norm_clipped.update_state(encoder_norm_clipped)\n",
        "        planner_grad_norm_clipped.update_state(planner_norm_clipped)\n",
        "\n",
        "        global_grad_norm.update_state(tf.linalg.global_norm(gradients))\n",
        "\n",
        "        optimizer.apply_gradients(zip(gradients, actor.trainable_variables+encoder.trainable_variables+planner.trainable_variables))\n",
        "\n",
        "  train_loss.update_state(loss)\n",
        "  \n",
        "  return loss\n",
        "\n",
        "def test_step(inputs, beta):\n",
        "  states, actions, goals, seq_lens, mask = inputs['obs'], inputs['acts'], inputs['goals'], inputs['seq_lens'], inputs['masks']\n",
        "  action_weights = (dataloader.act_dim-1)*[1.0] + [GRIPPER_WEIGHT] # 1 for all but gripper\n",
        "  if dataloader.quaternion_act:\n",
        "    # xyz, q1-4, grip\n",
        "    action_breakdown = [3,4,1]\n",
        "  else:\n",
        "    action_breakdown = [3,3,1]\n",
        "\n",
        "  if GCBC:\n",
        "    policy = actor([states, goals], training=False)\n",
        "    loss = compute_loss(actions, policy, mask, seq_lens, weightings=action_weights)\n",
        "    if PROBABILISTIC:\n",
        "      pos_acts, rot_acts, grip_act = tf.split(policy.sample(), action_breakdown, -1)\n",
        "    else:\n",
        "      pos_acts, rot_acts, grip_act = tf.split(policy, action_breakdown, -1)\n",
        "  else:  \n",
        "    encoding = encoder([states, actions])\n",
        "    plan = planner([states[:, 0, :], goals[:, 0, :]])  # the final goals are tiled out over the entire non masked sequence, so the first timestep is the final goal. \n",
        "    z_enc = encoding.sample()\n",
        "    z_plan = plan.sample()\n",
        "    z_enc_tiled = tf.tile(tf.expand_dims(z_enc, 1), (1, dataloader.window_size, 1))\n",
        "    z_plan_tiled = tf.tile(tf.expand_dims(z_plan, 1), (1, dataloader.window_size, 1))\n",
        "\n",
        "    enc_policy = actor([states, z_enc_tiled, goals])\n",
        "    plan_policy = actor([states, z_plan_tiled, goals])\n",
        "\n",
        "    act_enc_loss = compute_loss(actions, enc_policy, mask, seq_lens, weightings=action_weights)\n",
        "    act_plan_loss = compute_loss(actions, plan_policy, mask, seq_lens, weightings=action_weights)\n",
        "    act_loss = act_plan_loss \n",
        "    \n",
        "    if INFO_VAE:\n",
        "        true_samples = tf.keras.backend.random_normal(tf.stack([z_enc.shape[0], LATENT_DIM]))\n",
        "        reg_loss = compute_mmd(true_samples, z_enc)\n",
        "        valid_mmd_reg_loss.update_state(reg_loss)\n",
        "        plan_chase_enc = compute_regularisation_loss(plan, encoding)\n",
        "        valid_reg_loss.update_state(plan_chase_enc)\n",
        "    else:\n",
        "        reg_loss = compute_regularisation_loss(plan, encoding)\n",
        "        valid_reg_loss.update_state(reg_loss)\n",
        "\n",
        "    valid_act_with_enc_loss.update_state(act_enc_loss)\n",
        "    valid_act_with_plan_loss.update_state(act_plan_loss)\n",
        "\n",
        "    # pos, rot, gripper individual losses\n",
        "    if PROBABILISTIC:\n",
        "      pos_acts, rot_acts, grip_act = tf.split(plan_policy.sample(), action_breakdown, -1)\n",
        "    else:\n",
        "      pos_acts, rot_acts, grip_act = tf.split(plan_policy, action_breakdown, -1) \n",
        "    \n",
        "    loss = act_loss + reg_loss * beta\n",
        "\n",
        "  true_pos_acts, true_rot_acts, true_grip_act = tf.split(actions, action_breakdown, -1)\n",
        "  valid_position_loss.update_state(compute_MAE(true_pos_acts, pos_acts, mask, seq_lens))\n",
        "  valid_max_position_loss(true_pos_acts, pos_acts, mask)\n",
        "  valid_rotation_loss.update_state(compute_MAE(true_rot_acts, rot_acts, mask, seq_lens))\n",
        "  valid_max_rotation_loss(true_rot_acts, rot_acts, mask)\n",
        "  valid_gripper_loss.update_state(compute_MAE(true_grip_act, grip_act, mask, seq_lens))\n",
        "  valid_loss.update_state(loss)\n",
        "\n",
        "  if GCBC:\n",
        "    return loss\n",
        "  else:\n",
        "    return loss, z_enc, z_plan\n",
        "\n",
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs, beta, prev_global_grad_norm):\n",
        "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs, beta, prev_global_grad_norm))\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
        "\n",
        "@tf.function\n",
        "def distributed_test_step(dataset_inputs, beta):\n",
        "  if GCBC:\n",
        "    per_replica_losses = strategy.run(test_step, args=(dataset_inputs, beta))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
        "  else:\n",
        "    per_replica_losses, ze, zp = strategy.run(test_step, args=(dataset_inputs, beta))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None), ze.values[0], zp.values[0]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEXdfXGpaiZO",
        "outputId": "c8a17a00-a84d-49cb-cf49-65e474454035"
      },
      "source": [
        "actor.summary()\n",
        "encoder.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_obs (InputLayer)          [(None, None, 18)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_latent (InputLayer)       [(None, None, 256)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_goals (InputLayer)        [(None, None, 11)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, None, 285)    0           input_obs[0][0]                  \n",
            "                                                                 input_latent[0][0]               \n",
            "                                                                 input_goals[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, None, 285)    0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_in_1 (LSTM)                (None, None, 2048)   19120128    masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_in_2 (LSTM)                (None, None, 2048)   33562624    LSTM_in_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "acts (Dense)                    (None, None, 7)      14343       LSTM_in_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 52,697,095\n",
            "Trainable params: 52,697,095\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "obs (InputLayer)                [(None, None, 18)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "acts (InputLayer)               [(None, None, 7)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, 25)     0           obs[0][0]                        \n",
            "                                                                 acts[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, None, 25)     0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, None, 1024)   2203648     masking_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1024)         6295552     bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 1024)         0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 256)          262400      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "sigma (Dense)                   (None, 256)          262400      tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "latent_variable (DistributionLa multiple             0           mu[0][0]                         \n",
            "                                                                 sigma[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 9,024,000\n",
            "Trainable params: 9,024,000\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrN8p__13pNd"
      },
      "source": [
        "train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
        "valid_dist_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "xtSlIEoBlDyp",
        "outputId": "599a97a9-496d-4d59-f81f-f0946673db39"
      },
      "source": [
        "from lfp.train import BetaScheduler\n",
        "\n",
        "TRAIN_STEPS = 200000\n",
        "# 0.00001 so far works best for MAE - try lower - 0.00003 with a BETA accel of 10 so far works best, perfect encoder, nicely mapped planner\n",
        "# recall 0.01 worked okay for probabilistic - proba still too unstable!\n",
        "beta_sched = BetaScheduler('linear', \n",
        "                           beta=0.00003, \n",
        "                           beta_max=0.00003, \n",
        "                           max_steps=TRAIN_STEPS, \n",
        "                           cycles=90, \n",
        "                           duty_cycle=0.5\n",
        "                           )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzURHczfLSIK"
      },
      "source": [
        "if 5 < 3: print(4)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-GxHom207-M"
      },
      "source": [
        "def save_weights(path,actor, encoder=None, planner=None, step=\"\"):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    print('Saving model weights...')\n",
        "    # Save the standardisation params\n",
        "    np.savez(path + 'hyper_params', relative_obs = dataloader.relative_obs, relative_act=dataloader.relative_act, quaternion_act = dataloader.quaternion_act,\n",
        "             joints=dataloader.joints, LAYER_SIZE=LAYER_SIZE, LATENT_DIM = LATENT_DIM,GRIPPER_WEIGHT = GRIPPER_WEIGHT,\n",
        "             GCBC = GCBC,PROBABILISTIC = PROBABILISTIC,QUANTISED=QUANTISED, run_id = wandb.run.id, scaling=scaling, N_QUANTISATIONS=N_QUANTISATIONS)\n",
        "    # save timestepped version\n",
        "    if step != \"\": \n",
        "      actor.save_weights(path + 'model_'+str(step)+'.h5')\n",
        "      if planner is not None: planner.save_weights(path + 'planner_'+str(step)+'.h5')\n",
        "      if encoder is not None: encoder.save_weights(path + 'encoder_'+str(step)+'.h5')\n",
        "\n",
        "    #save the latest version\n",
        "    actor.save_weights(path + 'model.h5')\n",
        "    if planner is not None: planner.save_weights(path + 'planner.h5')\n",
        "    if encoder is not None: encoder.save_weights(path + 'encoder.h5')\n",
        "\n",
        "    #save the optimizer state\n",
        "    np.save(os.path.join(path, 'optimizer'), optimizer.get_weights())\n",
        "\n",
        "\n",
        "def load_weights(path, actor, encoder=None, planner = None, step=\"\"):\n",
        "    actor.load_weights(f'{path}/model'+step+'.h5')\n",
        "    if planner is not None: planner.load_weights(f'{path}/planner'+step+'.h5')\n",
        "    if encoder is not None: encoder.load_weights(f'{path}/encoder'+step+'.h5')\n",
        "\n",
        "\n",
        "\n",
        "def load_optimizer_state(optimizer, load_path):\n",
        "    # Load optimizer weights\n",
        "    opt_weights = np.load(load_path+'optimizer.npy', allow_pickle=True)\n",
        "\n",
        "    # init the optimiser\n",
        "    distributed_opt_step()\n",
        "    # Set the weights of the optimizer\n",
        "    optimizer.set_weights(opt_weights)\n",
        "\n",
        "\n",
        "def optimizer_step():\n",
        "  # need to do this to initialie the optimiser\n",
        "  model_train_vars = actor.trainable_variables+encoder.trainable_variables+planner.trainable_variables\n",
        "  # dummy zero gradients\n",
        "  zero_grads = [tf.zeros_like(w) for w in model_train_vars]\n",
        "  # save current state of variables\n",
        "  saved_vars = [tf.identity(w) for w in model_train_vars]\n",
        "\n",
        "  # Apply gradients which don't do anything\n",
        "  optimizer.apply_gradients(zip(zero_grads, model_train_vars))\n",
        "\n",
        "  # Reload variables\n",
        "  [x.assign(y) for x,y in zip(model_train_vars, saved_vars)]\n",
        "  return 0.0\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def distributed_opt_step():\n",
        "  '''\n",
        "  Only used for optimizer checkpointing - we need to run a pass to initialise all the optimizer weights. Can't use restore as colab TPUs don't have a local filesystem. \n",
        "  '''\n",
        "  per_replica_losses = strategy.run(optimizer_step, args=())\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSGD_2imWDi"
      },
      "source": [
        "progbar = Progbar(TRAIN_STEPS, verbose=1, interval=0.5)\n",
        "best_valid_loss = np.float('inf')\n",
        "\n",
        "valid_inc = 20\n",
        "save_inc = 1000\n",
        "\n",
        "prev_grad_norm = np.float('inf')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nmzjO2d_Hfm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f5cdf270-169e-4dd1-8dc5-0cc66551c75e"
      },
      "source": [
        "RESUME = True\n",
        "model_path"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Robotic Learning/LMP_test/Tests/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792,
          "referenced_widgets": [
            "be74d16c8329407eb38e6f4e80ea6da0",
            "5f5ce3be06e64bd389df5c7260a7dec3",
            "7461dd9f543d4d7abcbb69e48655f745",
            "d0ef3b057ca94d72baaaa07849c50912",
            "5f13710b899a42cd9ec5ce8d394e30af",
            "6895c85f86fc48baa96eafaa070c7265",
            "046dec87dce043ef8978fcbb329c4148",
            "ed4076ca6d904c3d9d17e22f3a3e0c6c"
          ]
        },
        "id": "oTyriZrYowMJ",
        "outputId": "901fdfbb-fe49-48b3-8b82-00ac7d3a5f03"
      },
      "source": [
        "run_name = \"Tests\"#\"ALLB0.00003\"\n",
        "model_path = f'/content/drive/My Drive/Robotic Learning/LMP_test/{run_name}/'\n",
        "\n",
        "if RESUME:\n",
        "  run_id = str(np.load(model_path+'hyper_params.npz')['run_id'])\n",
        "  wandb.init(project=\"learning-from-play_v2\", id='12621l2h',  resume=\"must\")\n",
        "  load_weights(model_path, actor, encoder, planner)\n",
        "  load_optimizer_state(optimizer, model_path)\n",
        "  print('Loaded model weights and optimiser state')\n",
        "  t = wandb.run.step + valid_inc\n",
        "else:\n",
        "  wandb.init(project=\"learning-from-play_v2\")\n",
        "  wandb.run.name = run_name\n",
        "  t = 0\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:12621l2h) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1778<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be74d16c8329407eb38e6f4e80ea6da0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/learning_from_play/wandb/run-20210130_024910-12621l2h/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/learning_from_play/wandb/run-20210130_024910-12621l2h/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>valid_act_with_enc_loss_result</td><td>0.00251</td></tr><tr><td>train_act_with_plan_loss_result</td><td>0.00267</td></tr><tr><td>_runtime</td><td>246875</td></tr><tr><td>_timestamp</td><td>1611486306</td></tr><tr><td>beta_result</td><td>3e-05</td></tr><tr><td>train_loss_result</td><td>0.00039</td></tr><tr><td>valid_reg_loss_result</td><td>4.08413</td></tr><tr><td>valid_max_rotation_loss_result</td><td>3.55939</td></tr><tr><td>actor_grad_norm</td><td>0.03141</td></tr><tr><td>encoder_grad_norm_clipped</td><td>0.0009</td></tr><tr><td>valid_gripper_loss_result</td><td>0.01561</td></tr><tr><td>valid_position_loss_result</td><td>0.0011</td></tr><tr><td>valid_max_position_loss_result</td><td>0.48305</td></tr><tr><td>valid_act_with_plan_loss_result</td><td>0.00455</td></tr><tr><td>_step</td><td>124520</td></tr><tr><td>planner_grad_norm</td><td>0.00033</td></tr><tr><td>valid_loss_result</td><td>0.00467</td></tr><tr><td>train_reg_loss_result</td><td>2.67333</td></tr><tr><td>actor_grad_norm_clipped</td><td>0.03141</td></tr><tr><td>valid_rotation_loss_result</td><td>0.00431</td></tr><tr><td>encoder_grad_norm</td><td>0.0009</td></tr><tr><td>planner_grad_norm_clipped</td><td>0.00326</td></tr><tr><td>train_act_with_enc_loss_result</td><td>0.00031</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">ALLB0.00003</strong>: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/12621l2h\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/12621l2h</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:12621l2h). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.15<br/>\n",
              "                Resuming run <strong style=\"color:#cdcd00\">ALLB0.00003</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/12621l2h\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/12621l2h</a><br/>\n",
              "                Run data is saved locally in <code>/content/learning_from_play/wandb/run-20210130_025045-12621l2h</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights and optimiser state\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ytVwQ0J6FTB"
      },
      "source": [
        "\n",
        "config = wandb.config\n",
        "\n",
        "# Hparams\n",
        "config.DEVICE = DEVICE\n",
        "config.WINDOW_SIZE = dataloader.window_size\n",
        "config.WINDOW_SHIFT = dataloader.window_shift\n",
        "config.LAYER_SIZE = LAYER_SIZE\n",
        "config.LATENT_DIM = LATENT_DIM\n",
        "config.GRIPPER_WEIGHT = GRIPPER_WEIGHT\n",
        "config.TRAIN_STEPS = TRAIN_STEPS\n",
        "config.beta_schedule = beta_sched.schedule\n",
        "config.beta_min = beta_sched.beta_min\n",
        "config.beta_max = beta_sched.beta_max\n",
        "config.PROBABILISTIC = PROBABILISTIC\n",
        "config.PROPRIOCEPTION = dataloader.proprioception"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnc22FOGae1"
      },
      "source": [
        "from lfp.plotting import produce_cluster_fig, project_enc_and_plan, plot_to_image\n",
        "v_it = iter(valid_dataset) #for the cluster fig, easier with a non distributed dataset\n",
        "\n",
        "def log(metric):\n",
        "  result = metric.result()\n",
        "  metric.reset_states()\n",
        "  return result"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXF0Y8aKrsng",
        "outputId": "cb2a84fd-f006-4218-c53e-1f2d843444dd"
      },
      "source": [
        "while t < TRAIN_STEPS:\n",
        "    start_time = time.time()\n",
        "    beta = beta_sched.scheduler(t)\n",
        "    x = next(train_dist_dataset)\n",
        "    total_train_loss = distributed_train_step(x, beta, prev_grad_norm)\n",
        "    \n",
        "    if t % valid_inc == 0:  \n",
        "        valid_x = next(valid_dist_dataset)\n",
        "        if GCBC:\n",
        "          total_val_loss = distributed_test_step(valid_x, beta)\n",
        "        else:\n",
        "          total_val_loss, ze, zp = distributed_test_step(valid_x, beta)\n",
        "\n",
        "        # validation plotting\n",
        "        progbar.add(valid_inc, [('Train Loss', train_loss.result()), ('Validation Loss', valid_loss.result()), ('Time (s)', round(time.time() - start_time, 1))])\n",
        "\n",
        "\n",
        "        wandb.log({'train_loss_result':log(train_loss),\n",
        "                    'valid_loss_result':log(valid_loss),\n",
        "                    'valid_position_loss_result':log(valid_position_loss),\n",
        "                    'valid_max_position_loss_result':log(valid_max_position_loss),\n",
        "                    'valid_rotation_loss_result':log(valid_rotation_loss),\n",
        "                    'valid_max_rotation_loss_result':log(valid_max_rotation_loss),\n",
        "                    'valid_gripper_loss_result':log(valid_gripper_loss),\n",
        "                    'actor_grad_norm': log(actor_grad_norm),\n",
        "                    'actor_grad_norm_clipped': log(actor_grad_norm_clipped),\n",
        "                  },\n",
        "                  step=t)\n",
        "          \n",
        "        if not GCBC:\n",
        "          wandb.log({\n",
        "                      'train_act_with_enc_loss_result':log(train_act_with_enc_loss),\n",
        "                      'train_act_with_plan_loss_result':log(train_act_with_plan_loss),\n",
        "                      'train_reg_loss_result':log(train_reg_loss),\n",
        "                      'valid_act_with_enc_loss_result':log(valid_act_with_enc_loss),\n",
        "                      'valid_act_with_plan_loss_result':valid_act_with_plan_loss.result(),\n",
        "                      'valid_reg_loss_result':log(valid_reg_loss),\n",
        "                      'beta_result':beta,\n",
        "                      'encoder_grad_norm': log(encoder_grad_norm),\n",
        "                      'planner_grad_norm': log(planner_grad_norm),\n",
        "                      'encoder_grad_norm_clipped': log(encoder_grad_norm_clipped),\n",
        "                      'planner_grad_norm_clipped': log(planner_grad_norm_clipped),\n",
        "                    },\n",
        "                    step=t)\n",
        "          \n",
        "\n",
        "        prev_grad_norm = log(global_grad_norm)\n",
        "          \n",
        "    if t % save_inc == 0:\n",
        "        save_weights(model_path, actor, encoder, planner)\n",
        "        if not GCBC:\n",
        "          z_enc, z_plan = produce_cluster_fig(next(v_it), encoder, planner, TEST_DATA_PATH, num_take=dataloader.batch_size)\n",
        "          wandb.log({'z_enc':z_enc, 'z_plan':z_plan}, step=t)\n",
        "          latent_fig = project_enc_and_plan(ze, zp)\n",
        "          latent_img = plot_to_image(latent_fig)\n",
        "\n",
        "    t += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   360/200000 [..............................] - ETA: 987:34:12 - Train Loss: 0.0099 - Validation Loss: 0.0132 - Time (s): 3.5722 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8pXuZiaPI1s",
        "outputId": "c19fba6d-5bde-4fce-913b-fea896402cda"
      },
      "source": [
        "valid_loss_result"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=0.018183153>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.014894525>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.012822507>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.012016779>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.011487661>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.011295487>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.01102834>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.010784242>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.010205653>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.010185119>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.010216749>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnsg9ZwI8RNR"
      },
      "source": [
        "\n",
        "# model_name =\"NB0.00001\"\n",
        "# model_path = f'/content/drive/My Drive/Robotic Learning/LMP_test/{model_name}/'\n",
        "load_weights(model_path, actor, encoder, planner)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cs00c5NE6VW"
      },
      "source": [
        "#@title Sample a batch for timeseries plotting\n",
        "# Lets plot pred actions vs true actions\n",
        "\n",
        "batch = v_it.next()\n",
        "states,acts,goals,seq_lens,masks = batch['obs'],batch['acts'],batch['goals'],batch['seq_lens'],batch['masks']\n",
        "if GCBC:\n",
        "  pred_acts = actor([states, goals])\n",
        "else:\n",
        "  encoding = encoder([states,acts])\n",
        "  plan = planner([states[:, 0, :], goals[:, 0, :]]) \n",
        "                                                  \n",
        "  # check if encoder is overfitting on validation\n",
        "  z_enc = z = tf.tile(tf.expand_dims(encoding.sample(), 1), (1, dataloader.window_size, 1))\n",
        "  enc_act_distrib = actor([states, z_enc, goals])\n",
        "\n",
        "  # true validation performance, w/ planner\n",
        "  z = tf.tile(tf.expand_dims(plan.sample(), 1), (1, dataloader.window_size, 1))\n",
        "  pred_acts = actor([states, z, goals]) "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERW0YID3FykT"
      },
      "source": [
        "#@title Plot timeseries of state/action tracking over time - xyz q1234 gripper\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "idx = 9\n",
        "seq_len = int(seq_lens[idx])\n",
        "x = np.arange(seq_len)\n",
        "labels = ['x','y','z','q1','q2','q3','q4','gripper']\n",
        "fig, axes = plt.subplots(dataloader.act_dim, 1, figsize=(10,12), squeeze=True)\n",
        "for i in range(dataloader.act_dim):\n",
        "    #sns.lineplot(x, acts[idx,:seq_len,i], color='r', ax=axes[i])\n",
        "    axes[i].plot(acts[idx,:seq_len,i])\n",
        "    axes[i].plot(pred_acts[idx, :seq_len,i])\n",
        "    #sns.lineplot(x, pred_acts[idx, :seq_len,i], color='g', ax=axes[i])\n",
        "    if not GCBC:\n",
        "      sns.lineplot(x, enc_act_distrib[idx, :seq_len,i], color='b', ax=axes[i])\n",
        "      axes[i].set_title(f'$\\\\bf{labels[i]}$')\n",
        "    \n",
        "fig.legend( ('true action', 'predicted action', 'encoder_action'))    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xQNWRGJQLZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}