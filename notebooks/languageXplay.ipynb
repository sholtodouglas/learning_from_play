{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/languageXplay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, colab=False, data_source='LOCAL', device='CPU', from_tfrecords=True, gcbc=False, latent_dim=32, layer_size=256, learning_rate=0.0003, num_distribs=None, qbits=None, resume=False, run_name='dummy_run', test_datasets=['UR5'], train_datasets=['UR5'], train_steps=5000)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='LFP training arguments')\n",
    "parser.add_argument('run_name')\n",
    "parser.add_argument('--train_datasets', nargs='+', help='Training dataset names')\n",
    "parser.add_argument('--test_datasets', nargs='+', help='Testing dataset names')\n",
    "parser.add_argument('-c', '--colab', default=False, action='store_true', help='Enable if using colab environment')\n",
    "parser.add_argument('-s', '--data_source', default='LOCAL', help='Source of training data')\n",
    "parser.add_argument('-tfr', '--from_tfrecords', default=False, action='store_true', help='Enable if using tfrecords format')\n",
    "parser.add_argument('-d', '--device', default='CPU', help='Hardware device to train on')\n",
    "parser.add_argument('-b', '--batch_size', default=32, type=int)\n",
    "parser.add_argument('-l', '--layer_size', default=256, type=int, help='Layer size of models, increases size of neural net')\n",
    "parser.add_argument('-z', '--latent_dim', default=32, type=int, help='Size of the VAE latent space')\n",
    "parser.add_argument('-g', '--gcbc', default=False, action='store_true', help='Enables GCBC, a simpler model with no encoder/planner')\n",
    "parser.add_argument('-n', '--num_distribs', default=None, type=int, help='Number of distributions to use in logistic mixture model')\n",
    "parser.add_argument('-q', '--qbits', default=None, type=int, help='Number of quantisation bits to discrete distributions into. Total quantisations = 2**qbits')\n",
    "parser.add_argument('-lr', '--learning_rate', type=float, default=3e-4)\n",
    "parser.add_argument('-t', '--train_steps', type=int, default=5000)\n",
    "parser.add_argument('-r', '--resume', default=False, action='store_true')\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "### Sample local config\n",
    "args = parser.parse_args('''\n",
    "dummy_run \n",
    "--train_dataset UR5\n",
    "--test_dataset UR5\n",
    "-tfr\n",
    "'''.split())\n",
    "\n",
    "### Sample colab config\n",
    "# args = parser.parse_args('''\n",
    "# dummy_run \n",
    "# --train_dataset UR5 UR5_slow_gripper UR5_high_transition\n",
    "# --test_dataset UR5_slow_gripper_test\n",
    "# -c\n",
    "# -tfr\n",
    "# -s GCS\n",
    "# -d TPU\n",
    "# -b 512\n",
    "# -l 1024\n",
    "# -z 256\n",
    "# -lr 3e-4\n",
    "# '''.split())\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     \"colab\":true,\n",
    "#     \"data_source\":\"GCS\",\n",
    "#     \"from_tfrecords\":true,\n",
    "#     \"device\":\"TPU\", \n",
    "#     \"train_datasets\":[\"UR5\", \"UR5_slow_gripper\",\"UR5_high_transition\"],\n",
    "#     \"test_datasets\":[\"UR5_slow_gripper_test\"],\n",
    "#     \"batch_size\":512,\n",
    "#     \"layer_size\":2048,\n",
    "#     \"latent_dim\":256,\n",
    "#     \"gcbc\":false,\n",
    "#     \"num_distribs\":null,\n",
    "#     \"qbits\":null,\n",
    "#     \"learning_rate\":3e-4\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pathy import Pathy\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import logging\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import io\n",
    "import wandb\n",
    "from natsort import natsorted\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Workpace Setup (Local vs Colab)\n",
    "\n",
    "# Set up working directory and libraries\n",
    "if args.colab:\n",
    "    from google.colab import drive, auth\n",
    "    print('Using colab setup')\n",
    "    WORKING_PATH = Path('/content/learning_from_play')\n",
    "    # Clone repo\n",
    "    try:\n",
    "        !git clone 'https://github.com/sholtodouglas/learning_from_play' {WORKING_PATH}\n",
    "    except: \n",
    "        pass\n",
    "    # Mount drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print('Using local setup')\n",
    "    WORKING_PATH = Path().absolute().parent\n",
    "    print(f'Working path: {WORKING_PATH}')\n",
    "\n",
    "# Change working directory to learning_from_play\n",
    "os.chdir(WORKING_PATH)\n",
    "import lfp\n",
    "        \n",
    "# Set up storage directory and datasets\n",
    "if args.data_source == 'DRIVE':\n",
    "    assert args.colab, \"Must be using Colab\"\n",
    "    print('Reading data from Google Drive')\n",
    "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
    "elif args.data_source == 'GCS':\n",
    "    assert args.colab, \"Must be using Colab\"\n",
    "    print('Reading data from Google Cloud Storage')\n",
    "    r = requests.get('https://ipinfo.io')\n",
    "    region = r.json()['region']\n",
    "    if region != 'Iowa':\n",
    "        logging.warning(f'You are accessing GCS data from {region}, outside of Iowa region')\n",
    "    project_id = 'learning-from-play-303306'\n",
    "    bucket_name = 'iowa_bucket_lfp'\n",
    "    auth.authenticate_user()\n",
    "    STORAGE_PATH = Pathy(f'gs://{bucket_name}')\n",
    "else:\n",
    "    print('Reading data from local filesystem')\n",
    "    STORAGE_PATH = WORKING_PATH\n",
    "\n",
    "print(f'Storage path: {STORAGE_PATH}')\n",
    "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.train_datasets]\n",
    "TEST_DATA_PATHS = [STORAGE_PATH/'data'/x for x in args.test_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EliqxOpPv9Dy"
   },
   "source": [
    "# Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zbmq324x2yv",
    "outputId": "fcbfeb52-faf1-479a-e4b6-f5d22d53ce71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "if args.device == 'TPU':\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "    except ValueError:\n",
    "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "\n",
    "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
    "    print(\"REPLICAS: \", NUM_DEVICES)\n",
    "else:\n",
    "    physical_devices = tf.config.list_physical_devices()\n",
    "    if args.device == 'GPU':\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
    "    NUM_DEVICES = 1\n",
    "    print(physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yL0UZVa1v9D9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1HejtDH_Yx8h"
   },
   "outputs": [],
   "source": [
    "# # Use this to edit modules without needing to restart the kernel\n",
    "# import importlib\n",
    "# importlib.reload(lfp.data)\n",
    "# importlib.reload(lfp.model)\n",
    "# importlib.reload(lfp.train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUI6JP06FdTv"
   },
   "source": [
    "### Config Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "n2lBWIyOFdTv"
   },
   "outputs": [],
   "source": [
    "GLOBAL_BATCH_SIZE = args.batch_size * NUM_DEVICES\n",
    "dl = lfp.data.PlayDataloader(batch_size=GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uiz4AXCnFdTv",
    "outputId": "ac74dea8-1bc9-4f19-de01-07c0626d3778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'acts': TensorSpec(shape=(32, 50, 7), dtype=tf.float32, name=None),\n",
      "    'dataset_path': TensorSpec(shape=(32, None), dtype=tf.int32, name=None),\n",
      "    'goals': TensorSpec(shape=(32, 50, 11), dtype=tf.float32, name=None),\n",
      "    'masks': TensorSpec(shape=(32, 50), dtype=tf.float32, name=None),\n",
      "    'obs': TensorSpec(shape=(32, 50, 18), dtype=tf.float32, name=None),\n",
      "    'seq_lens': TensorSpec(shape=(32,), dtype=tf.float32, name=None),\n",
      "    'tstep_idxs': TensorSpec(shape=(32, None), dtype=tf.int32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train_data = dl.extract(TRAIN_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
    "train_dataset = dl.load(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8ZDAVpLFdTw",
    "outputId": "005441b6-3a49-40f1-fa8d-daa17fd3b74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'acts': TensorSpec(shape=(32, 50, 7), dtype=tf.float32, name=None),\n",
      "    'dataset_path': TensorSpec(shape=(32, None), dtype=tf.int32, name=None),\n",
      "    'goals': TensorSpec(shape=(32, 50, 11), dtype=tf.float32, name=None),\n",
      "    'masks': TensorSpec(shape=(32, 50), dtype=tf.float32, name=None),\n",
      "    'obs': TensorSpec(shape=(32, 50, 18), dtype=tf.float32, name=None),\n",
      "    'seq_lens': TensorSpec(shape=(32,), dtype=tf.float32, name=None),\n",
      "    'tstep_idxs': TensorSpec(shape=(32, None), dtype=tf.int32, name=None)}\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "valid_data = dl.extract(TEST_DATA_PATHS, from_tfrecords=args.from_tfrecords)\n",
    "valid_dataset = dl.load(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN3YJSSLv9Ez",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWIpRPRuv9E6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2uMXBjGzgZCA"
   },
   "outputs": [],
   "source": [
    "def train_setup():\n",
    "    model_params = {'obs_dim':dl.obs_dim,\n",
    "                    'goal_dim':dl.goal_dim,\n",
    "                    'act_dim':dl.act_dim,\n",
    "                    'layer_size':args.layer_size, \n",
    "                    'latent_dim':args.latent_dim}\n",
    "    \n",
    "    actor = lfp.model.create_actor(**model_params, gcbc=args.gcbc, num_distribs=args.num_distribs)\n",
    "\n",
    "    if args.gcbc:\n",
    "        encoder = None\n",
    "        planner = None\n",
    "    else:\n",
    "        encoder = lfp.model.create_encoder(**model_params)\n",
    "        planner = lfp.model.create_planner(**model_params)\n",
    "        \n",
    "    trainer = lfp.train.LFPTrainer(dl, \n",
    "                                 actor,\n",
    "                                 encoder=encoder, \n",
    "                                 planner=planner, \n",
    "                                 probabilistic=args.num_distribs is not None,\n",
    "                                 distribute_strategy=strategy,\n",
    "                                 learning_rate=args.learning_rate,\n",
    "                                 clipnorm=1.0,\n",
    "                                 gcbc=args.gcbc)\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "if args.device=='CPU':\n",
    "    trainer = train_setup()\n",
    "    train_dataset = iter(train_dataset)\n",
    "    valid_dataset = iter(valid_dataset)\n",
    "else:\n",
    "    with strategy.scope():\n",
    "        trainer = train_setup()   \n",
    "    train_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
    "    valid_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "xtSlIEoBlDyp",
    "outputId": "e72adb3b-c02a-4406-f40d-88ab37f4b78e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.00001 so far works best for MAE - try lower - 0.00003 with a BETA accel of 10 so far works best, perfect encoder, nicely mapped planner\n",
    "# recall 0.01 worked okay for probabilistic - proba still too unstable!\n",
    "beta_sched = lfp.train.BetaScheduler('linear', \n",
    "                                   beta=0.00003, \n",
    "                                   beta_max=0.00003, \n",
    "                                   max_steps=args.train_steps, \n",
    "                                   cycles=90, \n",
    "                                   duty_cycle=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rhSGD_2imWDi"
   },
   "outputs": [],
   "source": [
    "progbar = tf.keras.utils.Progbar(args.train_steps, verbose=1, interval=0.5)\n",
    "best_valid_loss = np.float('inf')\n",
    "\n",
    "valid_inc = 20\n",
    "save_inc = 1000\n",
    "\n",
    "prev_grad_norm = np.float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6d6887969e5d484384667f5f4fe4a581",
      "652d0aef5d3144618a45c8012d9a0bc2",
      "4f578ba444034234a3387e791f5b7900",
      "74a5e0c5e3484748a96c6eca8a3ff07a",
      "12fbeb8587394eeebad5b8d7d90eee22",
      "894a73e08c184b908bd985a6927235d0",
      "024d2b0c4ea24adba0b66ce199f5260b",
      "02b4c8386f8e4fceb502e8c5b7aa29c6"
     ]
    },
    "id": "oTyriZrYowMJ",
    "outputId": "51f667db-bfc9-4313-ce3e-0d706c50cf13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3iq32kx8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5557<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/Tristan/Documents/Robotic Learning/learning_from_play/wandb/run-20210131_175300-3iq32kx8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/Tristan/Documents/Robotic Learning/learning_from_play/wandb/run-20210131_175300-3iq32kx8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">faithful-terrain-5</strong>: <a href=\"https://wandb.ai/tfrizza/learning-from-play_v2/runs/3iq32kx8\" target=\"_blank\">https://wandb.ai/tfrizza/learning-from-play_v2/runs/3iq32kx8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3iq32kx8). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.15<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eager-tree-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/tfrizza/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/tfrizza/learning-from-play_v2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/tfrizza/learning-from-play_v2/runs/1crwrdon\" target=\"_blank\">https://wandb.ai/tfrizza/learning-from-play_v2/runs/1crwrdon</a><br/>\n",
       "                Run data is saved locally in <code>/Users/Tristan/Documents/Robotic Learning/learning_from_play/wandb/run-20210131_175519-1crwrdon</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = f'/content/drive/My Drive/Robotic Learning/saved_models/{args.run_name}/'\n",
    "\n",
    "if args.resume:\n",
    "    # TODO: Fix resume id\n",
    "    # Fix `load_optimizer_state` given we now have 3 optimizers\n",
    "    wandb.init(project=\"learning-from-play_v2\", id='12621l2h', resume=\"must\")\n",
    "    trainer.load_weights(model_path, with_optimizer=True)\n",
    "    print('Loaded model weights and optimiser state')\n",
    "    t = wandb.run.step + valid_inc\n",
    "else:\n",
    "    wandb.init(project=\"learning-from-play_v2\", config=args)\n",
    "    wandb.run.name = args.run_name\n",
    "    t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xjnc22FOGae1"
   },
   "outputs": [],
   "source": [
    "# v_it = iter(valid_dataset) # for the cluster fig, easier with a non distributed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IXF0Y8aKrsng",
    "outputId": "31887155-68fc-4419-9eaf-8f1e802d5fe3"
   },
   "outputs": [],
   "source": [
    "while t < args.train_steps:\n",
    "    start_time = time.time()\n",
    "    beta = beta_sched.scheduler(t)\n",
    "    x = next(train_dataset)\n",
    "    total_train_loss = trainer.distributed_train_step(x, beta)\n",
    "    \n",
    "    if t % valid_inc == 0:  \n",
    "        valid_x = next(valid_dataset)\n",
    "        if args.gcbc:\n",
    "            total_val_loss, metrics = trainer.distributed_test_step(valid_x, beta)\n",
    "        else:\n",
    "            total_val_loss, metrics, ze, zp = trainer.distributed_test_step(valid_x, beta)\n",
    "\n",
    "        # validation plotting\n",
    "        progbar.add(valid_inc, [('Train Loss', metrics['train_loss']), \n",
    "                                ('Validation Loss', metrics['valid_loss']), \n",
    "                                ('Time (s)', round(time.time() - start_time, 1))])\n",
    "\n",
    "        wandb.log(metrics, step=t)\n",
    "          \n",
    "    if t % save_inc == 0:\n",
    "        trainer.save_weights(model_path, args)\n",
    "        if not args.gcbc:\n",
    "            # z_enc, z_plan = lfp.plotting.produce_cluster_fig(next(valid_dataset), trainer.encoder, trainer.planner, TEST_DATA_PATHS[0], num_take=dl.batch_size)\n",
    "            # wandb.log({'z_enc':z_enc, 'z_plan':z_plan}, step=t)\n",
    "            latent_fig = lfp.plotting.project_enc_and_plan(ze, zp)\n",
    "            #latent_img = plot_to_image(latent_fig)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "G84fGXVwv9Fh",
    "-yC0L1P3v9GA",
    "8SHQGBjnv9GK",
    "b7CMny5dv9Gx",
    "njbQpQAGv9G2"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "LMP Test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "lfp_venv",
   "language": "python",
   "name": "lfp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "024d2b0c4ea24adba0b66ce199f5260b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "02b4c8386f8e4fceb502e8c5b7aa29c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12fbeb8587394eeebad5b8d7d90eee22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f578ba444034234a3387e791f5b7900": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_894a73e08c184b908bd985a6927235d0",
      "placeholder": "​",
      "style": "IPY_MODEL_12fbeb8587394eeebad5b8d7d90eee22",
      "value": " 0.03MB of 0.03MB uploaded (0.00MB deduped)\r"
     }
    },
    "652d0aef5d3144618a45c8012d9a0bc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d6887969e5d484384667f5f4fe4a581": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f578ba444034234a3387e791f5b7900",
       "IPY_MODEL_74a5e0c5e3484748a96c6eca8a3ff07a"
      ],
      "layout": "IPY_MODEL_652d0aef5d3144618a45c8012d9a0bc2"
     }
    },
    "74a5e0c5e3484748a96c6eca8a3ff07a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02b4c8386f8e4fceb502e8c5b7aa29c6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_024d2b0c4ea24adba0b66ce199f5260b",
      "value": 1
     }
    },
    "894a73e08c184b908bd985a6927235d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
