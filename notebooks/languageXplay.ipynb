{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LMP Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G84fGXVwv9Fh",
        "-yC0L1P3v9GA",
        "8SHQGBjnv9GK",
        "b7CMny5dv9Gx",
        "njbQpQAGv9G2"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4fe301b9eeb54a08adff561eca80eeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edf66f27700d4894af4acf6a86a792f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd84636f0f914b09b7d49f37592a5d74",
              "IPY_MODEL_d8258aefd7874d9389bdf0ad1eeb4211"
            ]
          }
        },
        "edf66f27700d4894af4acf6a86a792f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd84636f0f914b09b7d49f37592a5d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_597f4e89ee5b4287b123be77bcd43e4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.12MB of 0.12MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00703b0de80a416f8690e823effcb080"
          }
        },
        "d8258aefd7874d9389bdf0ad1eeb4211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8197480baa0e4f1dadd003e71784772b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f5b839e937f4fc999233ff88ded9be9"
          }
        },
        "597f4e89ee5b4287b123be77bcd43e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00703b0de80a416f8690e823effcb080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8197480baa0e4f1dadd003e71784772b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f5b839e937f4fc999233ff88ded9be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sholtodouglas/learning_from_play/blob/master/notebooks/languageXplay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xchjk_eKp26Q"
      },
      "source": [
        "#@title Install package dependencies (forces restart)\n",
        "import os\n",
        "\n",
        "def restart_runtime():\n",
        "    print('Runtime restarting...')\n",
        "    os.kill(os.getpid(), 9)\n",
        "    \n",
        "!git clone 'https://github.com/sholtodouglas/pandaRL' 'local_packages/pandaRL'\n",
        "!pip install -e 'local_packages/pandaRL/.'\n",
        "\n",
        "restart_runtime()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jUYgZwpGfav",
        "outputId": "bf2ef286-e065-4bf5-820c-2000cc92f182"
      },
      "source": [
        "!pip -q install pybullet wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 76.6MB 86kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 64.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 64.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 59.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Tv7YJOgZB2"
      },
      "source": [
        "# Config\n",
        "config = {\n",
        "    'colab':True,\n",
        "    'gcs':False,\n",
        "    'device':'TPU', # 'CPU', 'GPU', 'TPU'\n",
        "    'train_datasets':[\"UR5\", \"UR5_slow_gripper\",\"UR5_high_transition\"],\n",
        "    'test_datasets':[\"UR5_slow_gripper_test\"],\n",
        "    # data\n",
        "    'batch_size':32,\n",
        "    # model\n",
        "    'layer_size':256,\n",
        "    'latent_dim':256,\n",
        "    'gcbc':False,\n",
        "    'num_distribs':None,\n",
        "    'qbits':None,\n",
        "    # training\n",
        "    'learning_rate':3e-4,\n",
        "}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMJ___6ARZ4u",
        "outputId": "ba6de71e-0355-4267-a4fc-a3b3011b36a5"
      },
      "source": [
        "#@title Workpace Setup (Local vs Colab)\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# COLAB = False #@param {type:\"boolean\"}\n",
        "AUTH_GCS = False #@param {type:\"boolean\"}\n",
        "# DEVICE = \"CPU\" #@param [\"TPU\", \"GPU\", \"CPU\"]\n",
        "DATA_SOURCE = \"Google Drive\" #@param [\"Google Drive\", \"GCS\"]\n",
        "# TRAIN_DATASETS = [\"UR5\"]#,\"UR5_slow_gripper\",\"UR5_high_transition\"]\n",
        "# TEST_DATASET = \"UR5_slow_gripper_test\" #@param [\"UR5_slow_gripper_test\"]\n",
        "GCS_USER = \"sholto\" #@param [\"sholto\", \"tristan\"]\n",
        "\n",
        "if config['colab']:\n",
        "    from google.colab import drive, auth\n",
        "    print('Using colab setup')\n",
        "    !git clone 'https://github.com/sholtodouglas/learning_from_play'\n",
        "    WORKING_PATH = Path('/content/learning_from_play')\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir(WORKING_PATH)\n",
        "    STORAGE_PATH = Path('/content/drive/My Drive/Robotic Learning')\n",
        "    print(f'Storage path: {STORAGE_PATH}')\n",
        "else:\n",
        "    print('Using local setup')\n",
        "    WORKING_PATH = Path().absolute().parent\n",
        "    print(f'Working path: {WORKING_PATH}')\n",
        "    os.chdir(WORKING_PATH)\n",
        "    STORAGE_PATH = WORKING_PATH\n",
        "    print(f'Storage path: {STORAGE_PATH}')\n",
        "\n",
        "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in config['train_datasets']]\n",
        "TEST_DATA_PATHS = [STORAGE_PATH/'data'/x for x in config['test_datasets']]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab setup\n",
            "fatal: destination path 'learning_from_play' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Storage path: /content/drive/My Drive/Robotic Learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EliqxOpPv9Dy"
      },
      "source": [
        "# Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zbmq324x2yv",
        "outputId": "156cc6b8-162e-436c-962b-1f427eed404b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "if config['device'] == \"TPU\":\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "    NUM_DEVICES = strategy.num_replicas_in_sync\n",
        "    print(\"REPLICAS: \", NUM_DEVICES)\n",
        "else:\n",
        "    physical_devices = tf.config.list_physical_devices()\n",
        "    if config['device'] == 'GPU':\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[3], enable=True)\n",
        "    NUM_DEVICES = 1\n",
        "    print(physical_devices)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.18.25.162:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.18.25.162:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.18.25.162:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL0UZVa1v9D9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF1m_wf3v9D-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "import lfp\n",
        "from natsort import natsorted"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HejtDH_Yx8h",
        "outputId": "60d00b26-6475-424b-f841-627bf26a607c"
      },
      "source": [
        "# Use this to edit modules without needing to restart the kernel\n",
        "import importlib\n",
        "importlib.reload(lfp.data)\n",
        "importlib.reload(lfp.model)\n",
        "importlib.reload(lfp.train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'lfp.train' from '/content/learning_from_play/lfp/train.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI6JP06FdTv"
      },
      "source": [
        "### Config Flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2lBWIyOFdTv"
      },
      "source": [
        "GLOBAL_BATCH_SIZE = config['batch_size'] * NUM_DEVICES\n",
        "dl = lfp.data.PlayDataloader(batch_size=GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uiz4AXCnFdTv",
        "outputId": "abd05109-0e4d-43c3-8690-b2991953f3f0"
      },
      "source": [
        "# Train data\n",
        "train_data = dl.extract(TRAIN_DATA_PATHS)\n",
        "train_dataset = dl.load(train_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UR5: 100%|██████████| 52/52 [00:00<00:00, 55.69it/s]\n",
            "UR5_slow_gripper: 100%|██████████| 23/23 [00:00<00:00, 52.04it/s]\n",
            "UR5_high_transition: 100%|██████████| 32/32 [00:00<00:00, 60.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(256, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(256, None, 1), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(256, 50, 11), dtype=tf.float32, name=None),\n",
            "    'masks': TensorSpec(shape=(256, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(256, 50, 18), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(256,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(256, None, 1), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ZDAVpLFdTw",
        "outputId": "0eae4608-c010-4c39-f838-4abde34e6a08"
      },
      "source": [
        "# Validation data\n",
        "valid_data = dl.extract(TEST_DATA_PATHS)\n",
        "valid_dataset = dl.load(valid_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UR5_slow_gripper_test: 100%|██████████| 2/2 [00:00<00:00, 46.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{   'acts': TensorSpec(shape=(256, 50, 7), dtype=tf.float32, name=None),\n",
            "    'dataset_path': TensorSpec(shape=(256, None, 1), dtype=tf.int32, name=None),\n",
            "    'goals': TensorSpec(shape=(256, 50, 11), dtype=tf.float32, name=None),\n",
            "    'masks': TensorSpec(shape=(256, 50), dtype=tf.float32, name=None),\n",
            "    'obs': TensorSpec(shape=(256, 50, 18), dtype=tf.float32, name=None),\n",
            "    'seq_lens': TensorSpec(shape=(256,), dtype=tf.float32, name=None),\n",
            "    'tstep_idxs': TensorSpec(shape=(256, None, 1), dtype=tf.int32, name=None)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN3YJSSLv9Ez",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIpRPRuv9E6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3r_TDl7v9E7",
        "outputId": "f79303d7-4ce1-4af2-9458-0dc8819f8d7f"
      },
      "source": [
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import Progbar\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "\n",
        "import time\n",
        "import io\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msholto\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqmqTTIrJgHc"
      },
      "source": [
        "from lfp.metric import MaxMetric, create_metrics, record\n",
        "from lfp.train import LFPTrainer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uMXBjGzgZCA"
      },
      "source": [
        "def train_setup():\n",
        "    model_params = {'obs_dim':dl.obs_dim,\n",
        "                'goal_dim':dl.goal_dim,\n",
        "                'act_dim':dl.act_dim,\n",
        "                'layer_size':config['layer_size'], \n",
        "                'latent_dim':config['latent_dim']}\n",
        "    \n",
        "    actor = lfp.model.create_actor(**model_params, gcbc=config['gcbc'], num_distribs=config['num_distribs'])\n",
        "\n",
        "    if config['gcbc']:\n",
        "        encoder = None\n",
        "        planner = None\n",
        "    else:\n",
        "        encoder = lfp.model.create_encoder(**model_params)\n",
        "        planner = lfp.model.create_planner(**model_params)\n",
        "\n",
        "    optimizer = tf.optimizers.Adam(learning_rate=config['learning_rate'])\n",
        "    trainable_variables = actor.trainable_variables + encoder.trainable_variables + planner.trainable_variables\n",
        "    return actor, encoder, planner, optimizer, trainable_variables\n",
        "\n",
        "if config['device']=='CPU':\n",
        "    actor, encoder, planner, optimizer, trainable_variables = train_setup()\n",
        "else:\n",
        "    with strategy.scope():\n",
        "        actor, encoder, planner, optimizer, trainable_variables = train_setup()\n",
        "        \n",
        "train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
        "valid_dist_dataset = iter(strategy.experimental_distribute_dataset(valid_dataset))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vDui_2XGhZW",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "with strategy.scope():\n",
        "    nll_action_loss = lambda y, p_y: tf.reduce_sum(-p_y.log_prob(y), axis=2)\n",
        "    mae_action_loss = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    mse_action_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def compute_loss(labels, predictions, mask, seq_lens, weightings=None):\n",
        "        if config['num_distribs'] is not None:\n",
        "            per_example_loss = nll_action_loss(labels, predictions) * mask\n",
        "        else:\n",
        "            per_example_loss = mae_action_loss(labels, predictions) * mask\n",
        "\n",
        "        per_example_loss = tf.reduce_sum(per_example_loss, axis=1) / seq_lens  # take mean along the timestep\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "\n",
        "    def compute_MAE(labels, predictions, mask, seq_lens, weightings=None):\n",
        "        per_example_loss = mae_action_loss(labels, predictions) * mask\n",
        "        per_example_loss = tf.reduce_sum(per_example_loss, axis=1) / seq_lens  # take mean along the timestep\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "\n",
        "    def compute_regularisation_loss(plan, encoding):\n",
        "        # Reverse KL(enc|plan): we want planner to map to encoder (weighted by encoder)\n",
        "        reg_loss = tfd.kl_divergence(encoding, plan)  # + KL(plan, encoding)\n",
        "        return tf.nn.compute_average_loss(reg_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "    train_loss, valid_loss, actor_grad_norm, encoder_grad_norm, planner_grad_norm, \\\n",
        "    actor_grad_norm_clipped, encoder_grad_norm_clipped, planner_grad_norm_clipped, global_grad_norm, \\\n",
        "    test, test2,  train_act_with_enc_loss, train_act_with_plan_loss, valid_act_with_enc_loss, valid_act_with_plan_loss,\\\n",
        "    train_reg_loss, valid_reg_loss, valid_position_loss,  valid_max_position_loss, valid_rotation_loss, valid_max_rotation_loss, valid_gripper_loss = create_metrics()\n",
        "\n",
        "\n",
        "# Now outside strategy .scope\n",
        "def train_step(inputs, beta, prev_global_grad_norm):\n",
        "    with tf.GradientTape() as actor_tape, tf.GradientTape() as encoder_tape, tf.GradientTape() as planner_tape:  # separate tapes to simplify grad_norm logging and clipping for stability\n",
        "        # Todo: figure out mask and seq_lens for new dataset \n",
        "        states, actions, goals, seq_lens, mask = inputs['obs'], inputs['acts'], inputs['goals'], inputs['seq_lens'], \\\n",
        "                                                 inputs['masks']\n",
        "\n",
        "        if config['gcbc']:\n",
        "            distrib = actor([states, goals])\n",
        "            loss = compute_loss(actions, distrib, mask, seq_lens)\n",
        "            gradients = tape.gradient(loss, actor.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, actor.trainable_variables))\n",
        "        else:\n",
        "            encoding = encoder([states, actions])\n",
        "            plan = planner([states[:, 0, :], goals[:, 0,:]])  # the final goals are tiled out over the entire non masked sequence, so the first timestep is the final goal. \n",
        "            z_enc = encoding.sample()\n",
        "            z_plan = plan.sample()\n",
        "            z_enc_tiled = tf.tile(tf.expand_dims(z_enc, 1), (1, dl.window_size, 1))\n",
        "            z_plan_tiled = tf.tile(tf.expand_dims(z_plan, 1), (1, dl.window_size, 1))\n",
        "\n",
        "            enc_policy = actor([states, z_enc_tiled, goals])\n",
        "            plan_policy = actor([states, z_plan_tiled, goals])\n",
        "\n",
        "            act_enc_loss = record(compute_loss(actions, enc_policy, mask, seq_lens), train_act_with_enc_loss)\n",
        "            act_plan_loss = record(compute_loss(actions, plan_policy, mask, seq_lens), train_act_with_plan_loss)\n",
        "            reg_loss = record(compute_regularisation_loss(plan, encoding), train_reg_loss)\n",
        "            loss = act_enc_loss + reg_loss * beta\n",
        "\n",
        "            actor_gradients = actor_tape.gradient(loss, actor.trainable_variables)\n",
        "            encoder_gradients = encoder_tape.gradient(loss, encoder.trainable_variables)\n",
        "            planner_gradients = planner_tape.gradient(loss, planner.trainable_variables)\n",
        "\n",
        "            actor_norm = record(tf.linalg.global_norm(actor_gradients), actor_grad_norm)\n",
        "            encoder_norm = record(tf.linalg.global_norm(encoder_gradients), encoder_grad_norm)\n",
        "            planner_norm = record(tf.linalg.global_norm(planner_gradients), planner_grad_norm)\n",
        "\n",
        "            gradients = actor_gradients + encoder_gradients+planner_gradients\n",
        "\n",
        "            # if the gradient norm is more than 3x the previous one, clip it to the previous norm for stability\n",
        "            gradients = tf.cond(tf.linalg.global_norm(gradients) > 3 * prev_global_grad_norm,\n",
        "                                lambda: tf.clip_by_global_norm(gradients, prev_global_grad_norm)[0],\n",
        "                                lambda: gradients)  # must get[0] as it returns new norm as [1]\n",
        "\n",
        "\n",
        "            actor_norm_clipped = record(tf.linalg.global_norm(actor_gradients), actor_grad_norm_clipped)\n",
        "            encoder_norm_clipped = record(tf.linalg.global_norm(encoder_gradients), encoder_grad_norm_clipped)\n",
        "            planner_norm_clipped = record(tf.linalg.global_norm(planner_gradients), planner_grad_norm_clipped)\n",
        "\n",
        "            record(tf.linalg.global_norm(gradients), global_grad_norm)\n",
        "\n",
        "            optimizer.apply_gradients(zip(gradients,\n",
        "                                          actor.trainable_variables + encoder.trainable_variables + planner.trainable_variables))\n",
        "\n",
        "\n",
        "    return record(loss, train_loss)\n",
        "\n",
        "\n",
        "def test_step(inputs, beta):\n",
        "    states, actions, goals, seq_lens, mask = inputs['obs'], inputs['acts'], inputs['goals'], inputs['seq_lens'], inputs['masks']\n",
        "\n",
        "    if  config['gcbc']:\n",
        "        policy = actor([states, goals], training=False)\n",
        "        loss = compute_loss(actions, policy, mask, seq_lens)\n",
        "        log_action_breakdown(policy, actions, mask, seq_lens, config, dl.quaternion_act, valid_position_loss, valid_max_position_loss, \\\n",
        "                             valid_rotation_loss, valid_max_rotation_loss, valid_gripper_loss, compute_MAE)\n",
        "    else:\n",
        "        encoding = encoder([states, actions])\n",
        "        plan = planner([states[:, 0, :], goals[:, 0,:]])  # the final goals are tiled out over the entire non masked sequence, so the first timestep is the final goal. \n",
        "        z_enc = encoding.sample()\n",
        "        z_plan = plan.sample()\n",
        "        z_enc_tiled = tf.tile(tf.expand_dims(z_enc, 1), (1, dl.window_size, 1))\n",
        "        z_plan_tiled = tf.tile(tf.expand_dims(z_plan, 1), (1, dl.window_size, 1))\n",
        "        enc_policy = actor([states, z_enc_tiled, goals])\n",
        "        plan_policy = actor([states, z_plan_tiled, goals])\n",
        "        act_enc_loss = record(compute_loss(actions, enc_policy, mask, seq_lens), valid_act_with_enc_loss)\n",
        "        act_plan_loss = record(compute_loss(actions, plan_policy, mask, seq_lens), valid_act_with_plan_loss)\n",
        "        reg_loss = record(compute_regularisation_loss(plan, encoding), valid_reg_loss)\n",
        "        loss = act_plan_loss + reg_loss * beta\n",
        "\n",
        "\n",
        "        log_action_breakdown(plan_policy, actions, mask, seq_lens, config, dl.quaternion_act, valid_position_loss, \\\n",
        "                             valid_max_position_loss, valid_rotation_loss, valid_max_rotation_loss, valid_gripper_loss, compute_MAE)\n",
        "\n",
        "\n",
        "    if config['gcbc']:\n",
        "        return record(loss, valid_loss)\n",
        "    else:\n",
        "        return record(loss,valid_loss), z_enc, z_plan\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs, beta, prev_global_grad_norm):\n",
        "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs, beta, prev_global_grad_norm))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def distributed_test_step(dataset_inputs, beta):\n",
        "    if config['gcbc']:\n",
        "        per_replica_losses = strategy.run(test_step, args=(dataset_inputs, beta))\n",
        "        return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
        "    else:\n",
        "        per_replica_losses, ze, zp = strategy.run(test_step, args=(dataset_inputs, beta))\n",
        "        return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None), ze.values[0], zp.values[0]"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "xtSlIEoBlDyp",
        "outputId": "5ec17d11-3385-4967-d6b8-3b422376e47d"
      },
      "source": [
        "from lfp.train import BetaScheduler\n",
        "\n",
        "TRAIN_STEPS = 200000\n",
        "# 0.00001 so far works best for MAE - try lower - 0.00003 with a BETA accel of 10 so far works best, perfect encoder, nicely mapped planner\n",
        "# recall 0.01 worked okay for probabilistic - proba still too unstable!\n",
        "beta_sched = BetaScheduler('linear', \n",
        "                           beta=0.00003, \n",
        "                           beta_max=0.00003, \n",
        "                           max_steps=TRAIN_STEPS, \n",
        "                           cycles=90, \n",
        "                           duty_cycle=0.5\n",
        "                           )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSGD_2imWDi"
      },
      "source": [
        "progbar = Progbar(TRAIN_STEPS, verbose=1, interval=0.5)\n",
        "best_valid_loss = np.float('inf')\n",
        "\n",
        "valid_inc = 20\n",
        "save_inc = 1000\n",
        "\n",
        "prev_grad_norm = np.float('inf')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0DCKjLXoDHv"
      },
      "source": [
        "\n",
        "from lfp.utils import save_weights, load_weights, load_optimizer_statE"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nmzjO2d_Hfm"
      },
      "source": [
        "RESUME = True"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4fe301b9eeb54a08adff561eca80eeb3",
            "edf66f27700d4894af4acf6a86a792f0",
            "dd84636f0f914b09b7d49f37592a5d74",
            "d8258aefd7874d9389bdf0ad1eeb4211",
            "597f4e89ee5b4287b123be77bcd43e4d",
            "00703b0de80a416f8690e823effcb080",
            "8197480baa0e4f1dadd003e71784772b",
            "1f5b839e937f4fc999233ff88ded9be9"
          ]
        },
        "id": "oTyriZrYowMJ",
        "outputId": "873b9cd7-5a4d-472b-a696-8be1ceef7483"
      },
      "source": [
        "run_name = \"Tests\"#\"ALLB0.00003\"\n",
        "model_path = f'/content/drive/My Drive/Robotic Learning/LMP_test/{run_name}/'\n",
        "\n",
        "if RESUME:\n",
        "  run_id = str(np.load(model_path+'hyper_params.npz')['run_id'])\n",
        "  wandb.init(project=\"learning-from-play_v2\", id='12621l2h',  resume=\"must\")\n",
        "  load_weights(model_path, actor, encoder, planner)\n",
        "  load_optimizer_state(optimizer, model_path, strategy)\n",
        "  print('Loaded model weights and optimiser state')\n",
        "  t = wandb.run.step + valid_inc\n",
        "else:\n",
        "  wandb.init(project=\"learning-from-play_v2\")\n",
        "  wandb.run.name = run_name\n",
        "  t = 0\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:9ytl7z50) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2025<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fe301b9eeb54a08adff561eca80eeb3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.10MB of 0.10MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/learning_from_play/wandb/run-20210130_140110-9ytl7z50/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/learning_from_play/wandb/run-20210130_140110-9ytl7z50/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train_loss_result</td><td>0.02554</td></tr><tr><td>valid_loss_result</td><td>0.03054</td></tr><tr><td>valid_position_loss_result</td><td>0.01659</td></tr><tr><td>valid_max_position_loss_result</td><td>2.65837</td></tr><tr><td>valid_rotation_loss_result</td><td>0.0357</td></tr><tr><td>valid_max_rotation_loss_result</td><td>5.64137</td></tr><tr><td>valid_gripper_loss_result</td><td>0.05667</td></tr><tr><td>actor_grad_norm</td><td>0.04579</td></tr><tr><td>actor_grad_norm_clipped</td><td>0.04579</td></tr><tr><td>train_act_with_enc_loss_result</td><td>0.02604</td></tr><tr><td>train_act_with_plan_loss_result</td><td>0.03214</td></tr><tr><td>train_reg_loss_result</td><td>1.07011</td></tr><tr><td>valid_act_with_enc_loss_result</td><td>0.02492</td></tr><tr><td>valid_act_with_plan_loss_result</td><td>0.03159</td></tr><tr><td>valid_reg_loss_result</td><td>1.07619</td></tr><tr><td>beta_result</td><td>3e-05</td></tr><tr><td>encoder_grad_norm</td><td>0.00723</td></tr><tr><td>planner_grad_norm</td><td>2e-05</td></tr><tr><td>encoder_grad_norm_clipped</td><td>0.00723</td></tr><tr><td>planner_grad_norm_clipped</td><td>0.00017</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>_runtime</td><td>4986</td></tr><tr><td>_timestamp</td><td>1612020256</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train_loss_result</td><td>██▅▄▄▂▁</td></tr><tr><td>valid_loss_result</td><td>█▃▂▂▃▁▃</td></tr><tr><td>valid_position_loss_result</td><td>▇█▁▅▆▁▅</td></tr><tr><td>valid_max_position_loss_result</td><td>▅▃▁▁▄█▅</td></tr><tr><td>valid_rotation_loss_result</td><td>█▁▂▁▄▃▄</td></tr><tr><td>valid_max_rotation_loss_result</td><td>█▁▁▆▂▂█</td></tr><tr><td>valid_gripper_loss_result</td><td>█▅▇▄▂▄▁</td></tr><tr><td>actor_grad_norm</td><td>▇█▇▅▂▂▁</td></tr><tr><td>actor_grad_norm_clipped</td><td>▇█▇▅▂▂▁</td></tr><tr><td>train_act_with_enc_loss_result</td><td>██▄▂▂▁</td></tr><tr><td>train_act_with_plan_loss_result</td><td>█▇▅▄▁▅</td></tr><tr><td>train_reg_loss_result</td><td>▁▃▅▆▆█</td></tr><tr><td>valid_act_with_enc_loss_result</td><td>█▅▃▂▂▁</td></tr><tr><td>valid_act_with_plan_loss_result</td><td>█▆▄▃▂▁</td></tr><tr><td>valid_reg_loss_result</td><td>▁▁▃▂██</td></tr><tr><td>beta_result</td><td>▁▁▁▁▁▁</td></tr><tr><td>encoder_grad_norm</td><td>▅█▄▃▁▄</td></tr><tr><td>planner_grad_norm</td><td>▁▄▄▆▅█</td></tr><tr><td>encoder_grad_norm_clipped</td><td>▅█▄▃▁▄</td></tr><tr><td>planner_grad_norm_clipped</td><td>▁▄▄▆▅█</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁█</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">fanciful-pine-107</strong>: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/9ytl7z50\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/9ytl7z50</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:9ytl7z50). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.15<br/>\n",
              "                Resuming run <strong style=\"color:#cdcd00\">ALLB0.00003</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/sholto/learning-from-play_v2/runs/12621l2h\" target=\"_blank\">https://wandb.ai/sholto/learning-from-play_v2/runs/12621l2h</a><br/>\n",
              "                Run data is saved locally in <code>/content/learning_from_play/wandb/run-20210130_152416-12621l2h</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded model weights and optimiser state\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ytVwQ0J6FTB"
      },
      "source": [
        "# config = wandb.config\n",
        "\n",
        "# # Hparams\n",
        "# config.DEVICE = DEVICE\n",
        "# config.WINDOW_SIZE = dl.window_size\n",
        "# config.WINDOW_SHIFT = dl.window_shift\n",
        "# config.LAYER_SIZE = LAYER_SIZE\n",
        "# config.LATENT_DIM = LATENT_DIM\n",
        "# config.GRIPPER_WEIGHT = GRIPPER_WEIGHT\n",
        "# config.TRAIN_STEPS = TRAIN_STEPS\n",
        "# config.beta_schedule = beta_sched.schedule\n",
        "# config.beta_min = beta_sched.beta_min\n",
        "# config.beta_max = beta_sched.beta_max\n",
        "# config.PROBABILISTIC = PROBABILISTIC\n",
        "# config.PROPRIOCEPTION = dl.proprioception"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnc22FOGae1"
      },
      "source": [
        "from lfp.plotting import produce_cluster_fig, project_enc_and_plan, plot_to_image\n",
        "v_it = iter(valid_dataset) #for the cluster fig, easier with a non distributed dataset\n",
        "\n",
        "def log(metric):\n",
        "  result = metric.result()\n",
        "  metric.reset_states()\n",
        "  return result"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IXF0Y8aKrsng",
        "outputId": "46782d1a-4cbc-4736-a14f-c86234f7864c"
      },
      "source": [
        "while t < TRAIN_STEPS:\n",
        "    start_time = time.time()\n",
        "    beta = beta_sched.scheduler(t)\n",
        "    x = next(train_dist_dataset)\n",
        "    total_train_loss = distributed_train_step(x, beta, prev_grad_norm)\n",
        "    \n",
        "    if t % 1 == 0:  \n",
        "        valid_x = next(valid_dist_dataset)\n",
        "        if config['gcbc']:\n",
        "          total_val_loss = distributed_test_step(valid_x, beta)\n",
        "        else:\n",
        "          total_val_loss, ze, zp = distributed_test_step(valid_x, beta)\n",
        "\n",
        "        # validation plotting\n",
        "        progbar.add(valid_inc, [('Train Loss', train_loss.result()), ('Validation Loss', valid_loss.result()), ('Time (s)', round(time.time() - start_time, 1))])\n",
        "\n",
        "\n",
        "        wandb.log({'train_loss_result':log(train_loss),\n",
        "                    'valid_loss_result':log(valid_loss),\n",
        "                    'valid_position_loss_result':log(valid_position_loss),\n",
        "                    'valid_max_position_loss_result':log(valid_max_position_loss),\n",
        "                    'valid_rotation_loss_result':log(valid_rotation_loss),\n",
        "                    'valid_max_rotation_loss_result':log(valid_max_rotation_loss),\n",
        "                    'valid_gripper_loss_result':log(valid_gripper_loss),\n",
        "                    'actor_grad_norm': log(actor_grad_norm),\n",
        "                    'actor_grad_norm_clipped': log(actor_grad_norm_clipped),\n",
        "                  },\n",
        "                  step=t)\n",
        "          \n",
        "        if not config['gcbc']:\n",
        "          wandb.log({\n",
        "                      'train_act_with_enc_loss_result':log(train_act_with_enc_loss),\n",
        "                      'train_act_with_plan_loss_result':log(train_act_with_plan_loss),\n",
        "                      'train_reg_loss_result':log(train_reg_loss),\n",
        "                      'valid_act_with_enc_loss_result':log(valid_act_with_enc_loss),\n",
        "                      'valid_act_with_plan_loss_result':valid_act_with_plan_loss.result(),\n",
        "                      'valid_reg_loss_result':log(valid_reg_loss),\n",
        "                      'beta_result':beta,\n",
        "                      'encoder_grad_norm': log(encoder_grad_norm),\n",
        "                      'planner_grad_norm': log(planner_grad_norm),\n",
        "                      'encoder_grad_norm_clipped': log(encoder_grad_norm_clipped),\n",
        "                      'planner_grad_norm_clipped': log(planner_grad_norm_clipped),\n",
        "                    },\n",
        "                    step=t)\n",
        "          \n",
        "\n",
        "        prev_grad_norm = log(global_grad_norm)\n",
        "          \n",
        "    if t % save_inc == 0:\n",
        "        save_weights(model_path, actor, configs, dl, run_id, encoder, planner)\n",
        "        if not config['gcbc']:\n",
        "          z_enc, z_plan = produce_cluster_fig(next(v_it), encoder, planner, TEST_DATA_PATHS[0], num_take=dl.batch_size)\n",
        "          wandb.log({'z_enc':z_enc, 'z_plan':z_plan}, step=t)\n",
        "          latent_fig = project_enc_and_plan(ze, zp)\n",
        "          #latent_img = plot_to_image(latent_fig)\n",
        "\n",
        "    t += 1"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   140/200000 [..............................] - ETA: 363:27:38 - Train Loss: 0.0293 - Validation Loss: 0.0324 - Time (s): 6.3857Saving model weights...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  c = np.array(c)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  c = np.array(c)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   160/200000 [..............................] - ETA: 321:50:58 - Train Loss: 0.0291 - Validation Loss: 0.0322 - Time (s): 5.6000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:410: UserWarning:\n",
            "\n",
            "Bummer! Plotly can currently only draw Line2D objects from matplotlib that are in 'data' coordinates!\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/plotly/matplotlylib/renderer.py:512: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   260/200000 [..............................] - ETA: 198:50:36 - Train Loss: 0.0280 - Validation Loss: 0.0315 - Time (s): 3.4462"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-266b25d48811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                       \u001b[0;34m'beta_result'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                       \u001b[0;34m'encoder_grad_norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                       \u001b[0;34m'planner_grad_norm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanner_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                       \u001b[0;34m'encoder_grad_norm_clipped'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_grad_norm_clipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                       \u001b[0;34m'planner_grad_norm_clipped'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanner_grad_norm_clipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-4e2c612cf163>\u001b[0m in \u001b[0;36mlog\u001b[0;34m(metric)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3704\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3706\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_values.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    310\u001b[0m               read_value=read_value)\n\u001b[1;32m    311\u001b[0m     return assign(self, value, use_locking=use_locking, name=name,\n\u001b[0;32m--> 312\u001b[0;31m                   read_value=read_value)\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscatter_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_values.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(var, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    412\u001b[0m       \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       read_value=read_value)\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, update_fn, value, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m           \u001b[0mreplica_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_replica_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplica_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_cross_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0mvalues_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m_update_cross_replica\u001b[0;34m(self, update_fn, value, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0mvalues_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_unsaveable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     return self.distribute_strategy.extended.update(\n\u001b[0;32m--> 894\u001b[0;31m         self, update_fn, args=(value,), kwargs=kwargs, group=True)\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2492\u001b[0m         fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2493\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1162\u001b[0m             fn(value, *distribute_utils.select_replica_mirrored(i, args),\n\u001b[1;32m   1163\u001b[0m                **distribute_utils.select_replica_mirrored(i, kwargs)))\n\u001b[0;32m-> 1164\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_regroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_utils.py\u001b[0m in \u001b[0;36mupdate_regroup\u001b[0;34m(extended, updates, group)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMirrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mregroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_make_grouped_mirrored\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_utils.py\u001b[0m in \u001b[0;36mregroup\u001b[0;34m(values, wrap_class, always_wrap)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrap_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_utils.py\u001b[0m in \u001b[0;36m_make_grouped_mirrored\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mwith_dep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMirrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3928\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3929\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3930\u001b[0;31m         _ctx, \"Identity\", name, input)\n\u001b[0m\u001b[1;32m   3931\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3932\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xQNWRGJQLZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}