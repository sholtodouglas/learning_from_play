{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import roboticsPlayroomPybullet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/home/sholto/Desktop/AI/RoboticsPlayroomPybullet/roboticsPlayroomPybullet/envs\n",
      "current_dir=/home/sholto/Desktop/AI/RoboticsPlayroomPybullet/roboticsPlayroomPybullet/envs\n",
      "current_dir=/home/sholto/Desktop/AI/RoboticsPlayroomPybullet/roboticsPlayroomPybullet/envs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sholto/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sholto/Desktop/AI/RoboticsPlayroomPybullet/roboticsPlayroomPybullet/envs\n"
     ]
    }
   ],
   "source": [
    "# Create an \n",
    "env = gym.make('UR5PlayAbsRPY1Obj-v0')\n",
    "# Launch a GUI\n",
    "env.render('human')\n",
    "# Reset the env\n",
    "_ = env.reset()\n",
    "# Activate img observations \n",
    "env.render('playback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local setup\n",
      "Working path: /home/sholto/Desktop/AI/learning_from_play\n",
      "Storage path: /home/sholto/Desktop/AI/learning_from_play\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "TEST_DATASET = \"UR5_slow_gripper_test\" \n",
    "print('Using local setup')\n",
    "WORKING_PATH = Path().absolute().parent\n",
    "print(f'Working path: {WORKING_PATH}')\n",
    "os.chdir(WORKING_PATH)\n",
    "STORAGE_PATH = WORKING_PATH\n",
    "print(f'Storage path: {STORAGE_PATH}')\n",
    "TRAIN_DATA_PATHS = [STORAGE_PATH/'data'/x for x in [\"UR5\", \"UR5_high_transition\", \"UR5_slow_gripper\"]]\n",
    "TEST_DATA_PATH = STORAGE_PATH/'data'/TEST_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sholto/Desktop/AI/learning_from_play/data/UR5/states_and_ims/0/ims\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "from IPython.display import display, clear_output\n",
    "from natsort import natsorted\n",
    "\n",
    "keys = ['obs', 'acts', 'achieved_goals']\n",
    "full_state_save_interval = 30 # How often we saved the determinstically resettable state\n",
    "# TRAIN_DATA_PATHS are the big folders which represent a few hours of teleop on different days\n",
    "# Within each of these folders are indiidual trajectories, which are occasionally reset for breaks \n",
    "# If the block goes out of reach\n",
    "# Strucure\n",
    "# DIR\n",
    " # DIR/obs_act_etc/  - this contains the npz files with obs/acts/ags at 25Hz, all info necessary to train models\n",
    "                # /1\n",
    "                # /2 etc\n",
    " # DIR/states_and_ims/ - this contains the states we can reset to (which contain info like precise contact points\\\n",
    "                        # which is better for deterministic reset and rollout, but large so we only saved these at 1Hz\n",
    "for DIR in TRAIN_DATA_PATHS:\n",
    "    DIR = str(DIR) # glob/natsorted prefer strings\n",
    "    \n",
    "    obs_act_path = DIR+'/obs_act_etc/'\n",
    "\n",
    "    for demo in natsorted(os.listdir(obs_act_path)):\n",
    "        # Gets the saved states (which we can reset to) \n",
    "        start_points = natsorted(glob.glob(DIR+'/states_and_ims/'+str(demo)+'/env_states/*.bullet'))\n",
    "        # The actual data\n",
    "        traj = np.load(obs_act_path+demo+'/data.npz')\n",
    "        d = {k:traj[k] for k in keys}\n",
    "        # The actions taken\n",
    "        acts = d['acts']\n",
    "        # The total length of this recorded trajectory\n",
    "        set_len = len(acts)\n",
    "    \n",
    "        start = 0 \n",
    "        # End is the steps till the next reset state, or the full length of the seq\n",
    "        end= min(start+full_state_save_interval, set_len)\n",
    "        print(DIR+'/states_and_ims/'+str(demo)+'/ims')\n",
    "\n",
    "        # Between each state we reset to - roll out the actions. \n",
    "        # A tiny amount of divergence is to be expected, which is why we reset whenever we have the information to do so\n",
    "        for start_point in start_points:\n",
    "            env.p.restoreState(fileName=start_point)\n",
    "            env.instance.updateToggles() # need to do it when when you restore from a state as colors are not saved\n",
    "            for i in range(start, end):\n",
    "                # Play out the teleoperated actions\n",
    "                o,r,_,_ = env.step(acts[i])\n",
    "\n",
    "            start += full_state_save_interval\n",
    "            end = min(start+full_state_save_interval, set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
